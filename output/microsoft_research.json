[
  {
    "title": "PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays ",
    "link": "https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/",
    "excerpt": "The world’s first multimodal, bilingual radiology dataset could reshape the way radiologists and AI systems make sense of X-rays. PadChest-GR, developed by the University of Alicante with Microsoft Research, has the potential to advance research across the field for years to come.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nPadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays\n\nPublished June 26, 2025\n\nBy Daniel Coelho de Castro , Senior Researcher  Javier Alvarez-Valle , Senior Director of Biomedical Imaging\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn our ever-evolving journey to enhance healthcare through technology, we’re announcing a unique new benchmark for grounded radiology report generation—PadChest-GR\n(opens in new tab)\n. The world’s first multimodal, bilingual sentence-level radiology report dataset, developed by the University of Alicante with Microsoft Research, University Hospital Sant Joan d’Alacant and MedBravo, is set to redefine how AI and radiologists interpret radiological images. Our work demonstrates how collaboration between humans and AI can create powerful feedback loops—where new datasets drive better AI models, and those models, in turn, inspire richer datasets. We’re excited to share this progress in NEJM AI, highlighting both the clinical relevance and research excellence of this initiative. \n\nA new frontier in radiology report generation \n\nIt is estimated that over half of people visiting hospitals have radiology scans that must be interpreted by a clinical professional. Traditional radiology reports often condense multiple findings into unstructured narratives. In contrast, grounded radiology reporting demands that each finding be described and localized individually.\n\nThis can mitigate the risk of AI fabrications and enable new interactive capabilities that enhance clinical and patient interpretability. PadChest-GR is the first bilingual dataset to address this need with 4,555 chest X-ray studies complete with Spanish and English sentence-level descriptions and precise spatial (bounding box) annotations for both positive and negative findings. It is the first public benchmark that enables us to evaluate generation of fully grounded radiology reports in chest X-rays. \n\nFigure 1. Example of a grounded report from PadChest-GR. The original free-text report in Spanish was ”Motivo de consulta: Preoperatorio. Rx PA tórax: Impresión diagnóstica: Ateromatosis aórtica calcificada. Engrosamiento pleural biapical. Atelectasia laminar basal izquierda. Elongación aórtica. Sin otros hallazgos radiológicos significativos.”\n\nMICROSOFT RESEARCH PODCAST\n\nWhat’s Your Story: Lex Story\n\nModel maker and fabricator Lex Story helps bring research to life through prototyping. He discusses his take on failure; the encouragement and advice that has supported his pursuit of art and science; and the sabbatical that might inspire his next career move.\n\nListen now\nOpens in a new tab\n\nThis benchmark isn’t standing alone—it plays a critical role in powering our state-of-the-art multimodal report generation model, MAIRA-2. Leveraging the detailed annotations of PadChest-GR, MAIRA-2 represents our commitment to building more interpretable and clinically useful AI systems. You can explore our work on MAIRA-2 on our project web page, including recent user research conducted with clinicians in healthcare settings.\n\nPadChest-GR is a testament to the power of collaboration. Aurelia Bustos at MedBravo and Antonio Pertusa at the University of Alicante published the original PadChest dataset\n(opens in new tab)\n in 2020, with the help of Jose María Salinas from Hospital San Juan de Alicante and María de la Iglesia Vayá from the Center of Excellence in Biomedical Imaging at the Ministry of Health in Valencia, Spain. We started to look at PadChest and were deeply impressed by the scale, depth, and diversity of the data.\n\nAs we worked more closely with the dataset, we realized the opportunity to develop this for grounded radiology reporting research and worked with the team at the University of Alicante to determine how to approach this together. Our complementary expertise was a nice fit. At Microsoft Research, our mission is to push the boundaries of medical AI through innovative, data-driven solutions. The University of Alicante, with its deep clinical expertise, provided critical insights that greatly enriched the dataset’s relevance and utility. The result of this collaboration is the PadChest-GR dataset.\n\nA significant enabler of our annotation process was Centaur Labs. The team of senior and junior radiologists from the University Hospital Sant Joan d’Alacant, coordinated by Joaquin Galant, used this HIPAA-compliant labeling platform to perform rigorous study-level quality control and bounding box annotations. The annotation protocol implemented ensured that each annotation was accurate and consistent, forming the backbone of a dataset designed for the next generation of grounded radiology report generation models. \n\nAccelerating PadChest-GR dataset annotation with AI \n\nOur approach integrates advanced large language models with comprehensive manual annotation: \n\nData Selection & Processing: Leveraging Microsoft Azure OpenAI Service\n(opens in new tab)\n with GPT-4, we extracted sentences describing individual positive and negative findings from raw radiology reports, translated them from Spanish to English, and linked each sentence to the existing expert labels from PadChest. This was done for a selected subset of the full PadChest dataset, carefully curated to reflect a realistic distribution of clinically relevant findings. \n\nManual Quality Control & Annotation: The processed studies underwent meticulous quality checks on the Centaur Labs platform by radiologist from Hospital San Juan de Alicante. Each positive finding was then annotated with bounding boxes to capture critical spatial information. \n\nStandardization & Integration: All annotations were harmonized into coherent grounded reports, preserving the structure and context of the original findings while enhancing interpretability. \n\nFigure 2. Overview of the data curation pipeline.\nImpact and future directions \n\nPadChest-GR not only sets a new benchmark for grounded radiology reporting, but also serves as the foundation for our MAIRA-2 model, which already showcases the potential of highly interpretable AI in clinical settings. While we developed PadChest-GR to help train and validate our own models, we believe the research community will greatly benefit from this dataset for many years to come. We look forward to seeing the broader research community build on this—improving grounded reporting AI models and using PadChest-GR as a standard for evaluation. We believe that by fostering open collaboration and sharing our resources, we can accelerate progress in medical imaging AI and ultimately improve patient care together with the community.\n\nThe collaboration between Microsoft Research and the University of Alicante highlights the transformative power of working together across disciplines. With our publication in NEJM-AI and the integral role of PadChest-GR in the development of MAIRA-2\n(opens in new tab)\n and RadFact\n(opens in new tab)\n, we are excited about the future of AI-empowered radiology. We invite researchers and industry experts to explore PadChest-GR and MAIRA-2, contribute innovative ideas, and join us in advancing the field of grounded radiology reporting. \n\nPapers already using PadChest-GR:\n\n[2406.04449] MAIRA-2: Grounded Radiology Report Generation\n(opens in new tab)\nRadVLM: A Multitask Conversational Vision-Language Model for Radiology\n(opens in new tab)\nEnhancing Abnormality Grounding for Vision Language Models with Knowledge Descriptions\n(opens in new tab)\nVisual Prompt Engineering for Vision Language Models in Radiology\n(opens in new tab)\n\nFor further details or to download PadChest-GR, please visit the BIMCV PadChest-GR Project\n(opens in new tab)\n. \n\nModels in the Azure Foundry that can do Grounded Reporting: \n\nHow to deploy and use CXRReportGen healthcare AI model with Azure AI Foundry – Azure AI Foundry | Microsoft Learn\n(opens in new tab)\nHealthcare Orchestrator – Healthcare agent service | Microsoft Learn\n(opens in new tab)\nAcknowledgement\nAuthors: Daniel C. Castro\n(opens in new tab)\n, Aurelia Bustos\n(opens in new tab)\n, Shruthi Bannur\n(opens in new tab)\n, Stephanie L. Hyland\n(opens in new tab)\n, Kenza Bouzid\n(opens in new tab)\n, Maria Teodora Wetscherek\n(opens in new tab)\n, Maria Dolores Sánchez-Valverde\n(opens in new tab)\n, Lara Jaques-Pérez\n(opens in new tab)\n, Lourdes Pérez-Rodríguez\n(opens in new tab)\n, Kenji Takeda\n(opens in new tab)\n, José María Salinas\n(opens in new tab)\n, Javier Alvarez-Valle\n(opens in new tab)\n, Joaquín Galant Herrero\n(opens in new tab)\n, Antonio Pertusa\n(opens in new tab)\n \nMSR Health Futures UK: Hannah Richardson, Valentina Salvatelli, Harshita Sharma, Sam Bond-Taylor, Max Ilse, Fernando Perez-Garcia, Anton Schwaighofer, Jonathan Carlson \nMSR Flow: Kenji Takeda, Evelyn Viegas, Ashley Llorens\nHLS: Matthew Lungren, Naiteek Sangani, Shrey Jain, Ivan Tarapov, Will Guyman, Mert Oez, Chris Burt, David Ardman\nOpens in a new tab\nRelated publications\nMultimodal Healthcare AI: Identifying and Designing Clinically Relevant Vision-Language Applications for Radiology\nMAIRA-2: Grounded Radiology Report Generation\nPadChest-GR: A Bilingual Chest X-ray Dataset for Grounded Radiology Report Generation\nMeet the authors\nDaniel Coelho de Castro\n\nSenior Researcher\n\nLearn more\nJavier Alvarez-Valle\n\nSenior Director of Biomedical Imaging\n\nLearn more\nContinue reading\nSeptember 30, 2024\nStress-testing biomedical vision models with RadEdit: A synthetic data approach for robust model deployment \nJune 26, 2024\nResearch Focus: Week of June 24, 2024 \nNovember 27, 2023\nGPT-4’s potential in shaping the future of radiology \nAugust 17, 2023\nCollaborators: Project InnerEye with Javier Alvarez and Raj Jena \nSee all blog posts\nResearch Areas\nArtificial intelligence\nMedical, health and genomics\nResearch Groups\nBiomedical Imaging\nRelated projects\nProject MAIRA\nRelated labs\nMicrosoft Health Futures\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Learning from other domains to advance AI evaluation and testing ",
    "link": "https://www.microsoft.com/en-us/research/blog/learning-from-other-domains-to-advance-ai-evaluation-and-testing/",
    "excerpt": "As generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements…",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nLearning from other domains to advance AI evaluation and testing\n\nPublished June 23, 2025\n\nBy Amanda Craig Deckard , Senior Director, Office of Responsible AI  Chad Atalla , Senior Applied Scientist\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nAs generative AI becomes more capable and widely deployed, familiar questions from the governance of other transformative technologies have resurfaced. Which opportunities, capabilities, risks, and impacts should be evaluated? Who should conduct evaluations, and at what stages of the technology lifecycle? What tests or measurements should be used? And how can we know if the results are reliable?  \n\nRecent research and reports from Microsoft\n(opens in new tab)\n, the UK AI Security Institute\n(opens in new tab)\n, The New York Times\n(opens in new tab)\n, and MIT Technology Review\n(opens in new tab)\n have highlighted gaps in how we evaluate AI models and systems. These gaps also form foundational context for recent international expert consensus reports: the inaugural International AI Safety Report\n(opens in new tab)\n (2025) and the Singapore Consensus\n(opens in new tab)\n (2025). Closing these gaps at a pace that matches AI innovation will lead to more reliable evaluations that can help guide deployment decisions, inform policy, and deepen trust. \n\nToday, we’re launching a limited-series podcast, AI Testing and Evaluation: Learnings from Science and Industry, to share insights from domains that have grappled with testing and measurement questions. Across four episodes, host Kathleen Sullivan speaks with academic experts in genome editing, cybersecurity, pharmaceuticals, and medical devices to find out which technical and regulatory steps have helped to close evaluation gaps and earn public trust.\n\nMICROSOFT RESEARCH BLOG\n\nResearch at Microsoft 2024: Meeting the challenge of a changing world\n\nIn this new AI era, technology is changing even faster than before, and the transition from research to reality, from concept to solution, now takes days or weeks rather than months or years.\n\nRead more\nOpens in a new tab\n\nWe’re also sharing written case studies from experts, along with top-level lessons we’re applying to AI. At the close of the podcast series, we’ll offer Microsoft’s deeper reflections on next steps toward more reliable and trustworthy approaches to AI evaluation. \n\nLessons from eight case studies \n\nOur research on risk evaluation, testing, and assurance models in other domains began in December 2024, when Microsoft’s Office of Responsible AI\n(opens in new tab)\n gathered independent experts from the fields of civil aviation, cybersecurity, financial services, genome editing, medical devices, nanoscience, nuclear energy, and pharmaceuticals. In bringing this group together, we drew on our own learnings and feedback received on our e-book, Global Governance: Goals and Lessons for AI\n(opens in new tab)\n, in which we studied the higher-level goals and institutional approaches that had been leveraged for cross-border governance in the past. \n\nWhile approaches to risk evaluation and testing vary significantly across the case studies, there was one consistent, top-level takeaway: evaluation frameworks always reflect trade-offs among different policy objectives, such as safety, efficiency, and innovation.  \n\nExperts across all eight fields noted that policymakers have had to weigh trade-offs in designing evaluation frameworks. These frameworks must account for both the limits of current science and the need for agility in the face of uncertainty. They likewise agreed that early design choices, often reflecting the “DNA” of the historical moment in which they’re made, as cybersecurity expert Stewart Baker described it, are important as they are difficult to scale down or undo later. \n\nStrict, pre-deployment testing regimes—such as those used in civil aviation, medical devices, nuclear energy, and pharmaceuticals—offer strong safety assurances but can be resource-intensive and slow to adapt. These regimes often emerged in response to well-documented failures and are backed by decades of regulatory infrastructure and detailed technical standards.  \n\nIn contrast, fields marked by dynamic and complex interdependencies between the tested system and its external environment—such as cybersecurity and bank stress testing—rely on more adaptive governance frameworks, where testing may be used to generate actionable insights about risk rather than primarily serve as a trigger for regulatory enforcement.  \n\nMoreover, in pharmaceuticals, where interdependencies are at play and there is emphasis on pre-deployment testing, experts highlighted a potential trade-off with post-market monitoring of downstream risks and efficacy evaluation. \n\nThese variations in approaches across domains—stemming from differences in risk profiles, types of technologies, maturity of the evaluation science, placement of expertise in the assessor ecosystem, and context in which technologies are deployed, among other factors—also inform takeaways for AI.\n\nApplying risk evaluation and governance lessons to AI \n\nWhile no analogy perfectly fits the AI context, the genome editing and nanoscience cases offer interesting insights for general-purpose technologies like AI, where risks vary widely depending on how the technology is applied.  \n\nExperts highlighted the benefits of governance frameworks that are more flexible and tailored to specific use cases and application contexts. In these fields, it is challenging to define risk thresholds and design evaluation frameworks in the abstract. Risks become more visible and assessable once the technology is applied to a particular use case and context-specific variables are known.  \n\nThese and other insights also helped us distill qualities essential to ensuring that testing is a reliable governance tool across domains, including: \n\nRigor in defining what is being examined and why it matters. This requires detailed specification of what is being measured and understanding how the deployment context may affect outcomes.\nStandardization of how tests should be conducted to achieve valid, reliable results. This requires establishing technical standards that provide methodological guidance and ensure quality and consistency. \nInterpretability of test results and how they inform risk decisions. This requires establishing expectations for evidence and improving literacy in how to understand, contextualize, and use test results—while remaining aware of their limitations. \nToward stronger foundations for AI testing \n\nEstablishing robust foundations for AI evaluation and testing requires effort to improve rigor, standardization, and interpretability—and to ensure that methods keep pace with rapid technological progress and evolving scientific understanding.  \n\nTaking lessons from other general-purpose technologies, this foundational work must also be pursued for both AI models and systems. While testing models will continue to be important, reliable evaluation tools that provide assurance for system performance will enable broad adoption of AI, including in high-risk scenarios. A strong feedback loop on evaluations of AI models and systems could not only accelerate progress on methodological challenges but also bring focus to which opportunities, capabilities, risks, and impacts are most appropriate and efficient to evaluate at what points along the AI development and deployment lifecycle.\n\nAcknowledgements \n\nWe would like to thank the following external experts who have contributed to our research program on lessons for AI testing and evaluation: Mateo Aboy, Paul Alp, Gerónimo Poletto Antonacci, Stewart Baker, Daniel Benamouzig, Pablo Cantero, Daniel Carpenter, Alta Charo, Jennifer Dionne, Andy Greenfield, Kathryn Judge, Ciaran Martin, and Timo Minssen.  \n\nCase studies \n\nCivil aviation: Testing in Aircraft Design and Manufacturing, by Paul Alp \n\nCybersecurity: Cybersecurity Standards and Testing—Lessons for AI Safety and Security, by Stewart Baker \n\nFinancial services (bank stress testing): The Evolving Use of Bank Stress Tests, by Kathryn Judge \n\nGenome editing: Governance of Genome Editing in Human Therapeutics and Agricultural Applications, by Alta Charo and Andy Greenfield \n\nMedical devices: Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance, by Mateo Aboy and Timo Minssen \n\nNanoscience: The regulatory landscape of nanoscience and nanotechnology, and applications to future AI regulation, by Jennifer Dionne \n\nNuclear energy: Testing in the Nuclear Industry, by Pablo Cantero and Gerónimo Poletto Antonacci \n\nPharmaceuticals: The History and Evolution of Testing in Pharmaceutical Regulation, by Daniel Benamouzig and Daniel Carpenter\n\nOpens in a new tab\nRelated publications\nEvaluating Generative AI Systems is a Social Science Measurement Challenge\nLearning from other Domains to Advance AI Evaluation and Testing: Testing in Aircraft Design and Manufacturing\nLearning from other Domains to Advance AI Evaluation and Testing: Governance of Genome Edition in Human Therapeutics and Agricultural Applications\nLearning from other Domains to Advance AI Evaluation and Testing: Testing in the Nuclear Industry\nLearning from other Domains to Advance AI Evaluation and Testing: The History and Evolution of Testing in Pharmaceutical Regulation\nLearning from other Domains to Advance AI Evaluation and Testing: The regulatory landscape of nanoscience and nanotechnology, and applications to future AI regulation\nLearning from other Domains to Advance AI Evaluation and Testing: Medical Device Testing: Regulatory Requirements, Evolution and Lessons for AI Governance\nLearning from other Domains to Advance AI Evaluation and Testing: The Evolving Use of Bank Stress Tests\nLearning from other Domains to Advance AI Evaluation and Testing: Cybersecurity Standards and Testing — Lessons for AI Safety and Security\nMeet the authors\nAmanda Craig Deckard\n\nSenior Director, Office of Responsible AI\n\nLearn more\nChad Atalla\n\nSenior Applied Scientist\n\nLearn more\nContinue reading\nJune 30, 2025\nAI Testing and Evaluation: Learnings from genome editing \nJune 23, 2025\nAI Testing and Evaluation: Learnings from Science and Industry \nMay 5, 2025\nSocietal AI: Building human-centered AI systems \nJune 5, 2024\nMicrosoft at FAccT 2024: Advancing responsible AI research and practice \nSee all blog posts\nResearch Areas\nArtificial intelligence\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Breaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning ",
    "link": "https://www.microsoft.com/en-us/research/blog/breaking-bonds-breaking-ground-advancing-the-accuracy-of-computational-chemistry-with-deep-learning/",
    "excerpt": "Microsoft researchers achieved a breakthrough in the accuracy of DFT, a method for predicting the properties of molecules and materials, by using deep learning. This work can lead to better batteries, green fertilizers, precision drug discovery, and more.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nBreaking bonds, breaking ground: Advancing the accuracy of computational chemistry with deep learning\n\nPublished June 18, 2025\n\nBy Rianne van den Berg , Principal Research Manager  Jan Hermann , Principal Research Manager  Christopher Bishop , Technical Fellow and Director, Microsoft Research AI for Science  Paola Gori Giorgi , Senior Principal Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nWe are excited to share our first big milestone in solving a grand challenge that has hampered the predictive power of computational chemistry, biochemistry, and materials science for decades. By using a scalable deep-learning approach and generating an unprecedented quantity of diverse, highly accurate data, we have achieved a breakthrough in the accuracy of density functional theory (DFT), the workhorse method that thousands of scientists use every year to simulate matter at the atomistic level. Within the region of chemical space represented in our large training dataset, our model reaches the accuracy required to reliably predict experimental outcomes, as assessed on the well-known benchmark dataset W4-17\n(opens in new tab)\n. This removes a fundamental barrier to shifting the balance of molecule and material design from being driven by laboratory experiments to being driven by computational simulations. The implications for accelerating scientific discovery are far reaching, spanning applications from drugs to batteries and green fertilizers.\n\nWhat is DFT?\n\nMolecules and materials are made of atoms, which are held together by their electrons. These electrons act as a glue, determining the stability and properties of the chemical structure. Accurately computing the strength and properties of the electron glue is essential for predicting whether a chemical reaction will proceed, whether a candidate drug molecule will bind to its target protein, whether a material is suitable for carbon capture, or if a flow battery can be optimized for renewable energy storage. Unfortunately, a brute-force approach amounts to solving the many-electron Schrödinger equation, which requires computation that scales exponentially with the number of electrons. Considering that an atom has dozens of electrons, and that molecules and materials have large numbers of atoms, we could easily end up waiting the age of the universe to complete our computation unless we restrict our attention to small systems with only a few atoms.\n\nDFT, introduced by Walter Kohn and collaborators in 1964-1965, was a true scientific breakthrough, earning Kohn the Nobel Prize in Chemistry in 1998. DFT provides an extraordinary reduction in the computational cost of calculating the electron glue in an exact manner, from exponential to cubic, making it possible to perform calculations of practical value within seconds to hours.\n\nDFT Timeline\nWhat is the grand challenge in DFT? \n\nBut there is a catch: the exact reformulation has a small but crucial term—the exchange-correlation (XC) functional—which Kohn proved is universal (i.e., the same for all molecules and materials), but for which no explicit expression is known. For 60 years, people have designed practical approximations for the XC functional. The magazine Science dubbed the gold rush to design better XC models the “pursuit of the Divine Functional\n(opens in new tab)\n”. With time, these approximations have grown into a zoo of hundreds of different XC functionals from which users must choose, often using experimental data as a guide. Owing to the uniquely favorable computational cost of DFT, existing functionals have enabled scientists to gain extremely useful insight into a huge variety of chemical problems. However, the limited accuracy and scope of current XC functionals mean that DFT is still mostly used to interpret experimental results rather than predict them.\n\nWhy is it important to increase the accuracy of DFT? \n\nWe can contrast the present state of computational chemistry with the state of aircraft engineering and design. Thanks to predictive simulations, aeronautical engineers no longer need to build and test thousands of prototypes to identify one viable design. However, this is exactly what we currently must do in molecular and materials sciences. We send thousands of potential candidates to the lab, because the accuracy of the computational methods is not sufficient to predict the experiments. To make a significant shift in the balance from laboratory to in silico experiments, we need to remove the fundamental bottleneck of the insufficient accuracy of present XC functionals. This amounts to bringing the error of DFT calculations with respect to experiments within chemical accuracy, which is around 1 kcal/mol for most chemical processes. Present approximations typically have errors that are 3 to 30 times larger.\n\nHow can AI make a difference? \n\nAI can transform how we model molecules and materials with DFT by learning the XC functional directly from highly accurate data. The goal is to learn how the XC functional captures the complex relationship between its input, the electron density, and its output, the XC energy. You can think of the density like a glue, with regions of space where there is a lot of it and other regions with less of it. Traditionally, researchers have built XC functional approximations using the concept of the so-called Jacob’s ladder: a hierarchy of increasingly complex, hand-designed descriptors of the electron density. Including density descriptors from higher rungs of this ladder aims to improve accuracy, but it comes at the price of increased computational cost. Even the few attempts that use machine learning have stayed within this traditional paradigm, thereby taking an approach that is akin to what people were doing in computer vision and speech recognition before the deep-learning era. Progress toward better accuracy has stagnated for at least two decades with this approach. \n\nOur project is driven by the intuition that a true deep learning approach—where relevant representations of the electron density are learned directly from data in a computationally scalable way—has the potential to revolutionize the accuracy of DFT, much like deep learning has transformed other fields. A significant challenge with going down this path, however, is that feature or representation learning is very data-hungry, and there is very little data around—too little to test this hypothesis reliably.\n\nWhat have we done in this milestone?\n\nThe first step was generating data—a lot of it. This posed a major challenge, since the data must come from accurate solutions of the many-electron Schrödinger equation, which is precisely the prohibitively expensive problem that DFT is designed to replace. Fortunately, decades of progress in the scientific community have led to smarter, more efficient variants of brute-force methods, making it possible to compute reference data for small molecules at experimental accuracy. While these high-accuracy methods, also referred to as wavefunction methods, are far too costly for routine use in applications, we made a deliberate investment in them for this project. The reason? The upfront cost of generating high-quality training data is offset by the long-term benefit of enabling vast numbers of industrially relevant applications with cost effective DFT using the trained XC functional. Crucially, we rely on the ability of DFT—and our learned XC functional—to generalize from high-accuracy data for small systems to larger, more complex molecules. \n\nThere are many different high-accuracy wavefunction methods, each tailored to different regions of chemical space. However, their use at scale is not well established, as they require extensive expertise—small methodological choices can significantly affect accuracy at the level that we target. We therefore joined forces with Prof. Amir Karton\n(opens in new tab)\n from the University of New England, Australia, a world-leading expert who developed widely recognized benchmark datasets for a fundamental thermochemical property: atomization energy—the energy required to break all bonds in a molecule and separate it into individual atoms. To create a training dataset of atomization energies at unprecedented scale, our team at Microsoft built a scalable pipeline to produce highly diverse molecular structures. Using these structures and substantial Azure compute resources via Microsoft’s Accelerating Foundation Models Research program\n(opens in new tab)\n, Prof. Karton applied a high-accuracy wavefunction method to compute the corresponding energy labels. The result is a dataset\n(opens in new tab)\n two orders of magnitude larger than previous efforts. We are releasing a large part of this dataset\n(opens in new tab)\n to the scientific community.\n\nData generation was only half of the challenge. We also needed to design a dedicated deep-learning architecture for the XC functional—one that is both computationally scalable and capable of learning meaningful representations from electron densities to accurately predict the XC energy. Our team of machine learning specialists, assisted by DFT experts, introduced a series of innovations that solve these and other challenges inherent to this complex learning problem. The result is Skala, an XC functional that generalizes to unseen molecules, reaching the accuracy needed to predict experiments. This demonstrates for the first time that deep learning can truly disrupt DFT: reaching experimental accuracy does not require the computationally expensive hand-designed features of Jacob’s ladder. Instead, we can retain the original computational complexity of DFT while allowing the XC functional to learn how to extract meaningful features and predict accurate energies.\n\nWe compare the accuracy of Skala against the best existing functionals of varying computational cost. The prediction errors are evaluated on two well-known public benchmark datasets: the W4-17 dataset for atomization energies (y axis, mean absolute error) and the GMTKN55 dataset for general main-group chemistry (x axis, weighted total mean absolute deviation, or WTMAD-2 for short). Skala achieves near “chemical accuracy” (1 kcal/mol) on atomization energies. This is the accuracy required for predictive modeling of laboratory experiments, which, to date, no existing functional has reached. Skala works especially well on the “single reference” subset of this dataset, reaching a groundbreaking 0.85 kcal/mol. On the GMTKN55 dataset, Skala shows competitive accuracy to the best-performing hybrid functionals, at a lower cost.\n\n“Skala is a new density functional for the exchange-correlation energy that employs meta-GGA ingredients plus D3 dispersion and machine-learned nonlocal features of the electron density. Some exact constraints were imposed, and some others “emerge” from the fitting to about 150,000 accurate energy differences for sp molecules and atoms. Skala achieves high, hybrid-like accuracy on a large and diverse data set of properties of main group molecules, which has no overlap with its training set. The computational cost of Skala is higher than that of the r2SCAN meta-GGA for small molecules, but about the same for systems with 1,000 or more occupied orbitals. Its cost seems to be only 10% of the cost of standard hybrids and 1% of the cost of local hybrids. Developed by a Microsoft team of density functional theorists and deep-learning experts, Skala could be the first machine-learned density functional to compete with existing functionals for wide use in computational chemistry, and a sign of things to come in that and related fields. Skala learned from big data and was taught by insightful human scientists.”\n\n— John P. Perdew, Professor of Physics, School of Science and Engineering, Tulane University\n\nThis first milestone was achieved for a challenging property in a specific region of chemical space—atomization energies of main group molecules—for which we generated our initial large batch of high-accuracy training data. Building on this foundation, we have started to expand our training dataset to cover a broader range of general chemistry, using our scalable in-house data generation pipeline. With the first small batch of training data beyond atomization energies, we have already extended the accuracy of our model, making it competitive with the best existing XC functionals across a wider spectrum of main group chemistry. This motivates us to continue growing our high-accuracy data generation campaign, engaging with external experts such as Prof. Amir Karton, who noted, “After years of benchmarking DFT methods against experimental accuracy, this is the first time I’ve witnessed such an unprecedented leap in the accuracy–cost trade-off. It is genuinely exciting to see how the creation of our new dataset has enabled these groundbreaking results — opening up a path for transformative advances across chemical, biochemical, and materials research.”\n\nAdvancing computational chemistry together\n\nWe are excited to work closely with the global computational chemistry community to accelerate progress for all and look forward to openly releasing our first XC functional in the near future. \n\n“Density Functional Theory (DFT) and related technologies are a core Digital Chemistry technology supporting advancements in Merck’s diverse Life Science, Healthcare and Electronics businesses. However, the limitations of traditional DFT methods, which have persisted for the last 50 years, have hindered its full potential. Microsoft Research’s innovative approach to integrating deep learning represents a substantial leap, enhancing its accuracy, robustness, and scalability. We are looking forward to exploring how this can advance Digital Chemistry workflows and unlock new possibilities for the future, aligning with our commitment to developing advanced algorithms and technologies that propel scientific innovation at Merck.”\n\n— Jan Gerit Brandenburg – Director for Digital Chemistry at Merck \n\n“We are entering a golden age for predictive and realistic simulations: very accurate electronic-structure calculations provide vast amounts of consistent data that can be used to train novel machine-learning architectures, delivering the holy grail of precision and computational efficiency.”\n\n— Professor Nicola Marzari, Chair of Theory and Simulation of Materials, EPFL and PSI\n\nWe believe that our new functional can help unlock new opportunities for businesses and are eager to work together on real-world applications. Today, we are delighted to launch the DFT Research Early Access Program (DFT REAP) and welcome Flagship Pioneering as the first participant. This program is for companies and research labs to collaborate with us to accelerate innovation across many industries. To find out more about how to join this program please visit: https://aka.ms/DFT-REAP\n(opens in new tab)\n \n\n“Microsoft’s effort to enhance the predictive power of computational chemistry reflects a bold but thoughtful step toward a simulation-first future. At Flagship, we believe that openly shared, foundational advances in science – like this leap forward in DFT accuracy – can serve as powerful enablers of innovation. These next-generation tools promise to accelerate discovery across a wide range of sectors, from therapeutics to materials science, by helping researchers navigate chemical and biological space with far greater precision and speed.”\n\n— Junaid Bajwa, M.D., Senior Partner at Flagship Pioneering and Science Partner at Pioneering Intelligence\n\nBy making our work available to the scientific community, we hope to enable widespread testing and gather valuable feedback that will guide future improvements. For the first time, deep learning offers a clear and computationally scalable path to building an accurate, efficient, and broadly applicable model of the universal XC functional—one that could transform the computational design of molecules and materials.\n\nSkala Paper\nDataset Paper\nDataset\nAcknowledgement\n\nThis work is the product of a highly collaborative and interdisciplinary effort led by Microsoft Research AI for Science, in partnership with colleagues from Microsoft Research Accelerator, Microsoft Quantum and the University of New England. The full author list includes Giulia Luise, Chin-Wei Huang, Thijs Vogels, Derk P. Kooi, Sebastian Ehlert, Stephanie Lanius, Klaas J. H. Giesbertz, Amir Karton, Deniz Gunceler, Megan Stanley, Wessel P. Bruinsma, Victor Garcia Satorras, Marwin Segler, Kenji Takeda, Lin Huang, Xinran Wei, José Garrido Torres, Albert Katbashev, Rodrigo Chavez Zavaleta, Bálint Máté, Sékou-Oumar Kaba, Roberto Sordillo, Yingrong Chen, David B. Williams-Young, Christopher M. Bishop, Jan Hermann, Rianne van den Berg and Paola Gori Giorgi. \n\nOpens in a new tab\nRelated publications\nAccurate and scalable exchange-correlation with deep learning\nAccurate Chemistry Collection: Coupled cluster atomization energies for broad chemical space\nMeet the authors\nRianne van den Berg\n\nPrincipal Research Manager\n\nLearn more\nJan Hermann\n\nPrincipal Research Manager\n\nLearn more\nChristopher Bishop\n\nTechnical Fellow and Director, Microsoft Research AI for Science\n\nLearn more\nPaola Gori Giorgi\n\nSenior Principal Research Manager\n\nLearn more\nContinue reading\nNovember 6, 2024\nFrom static prediction to dynamic characterization: AI2BMD advances protein dynamics with ab initio accuracy \nMarch 21, 2024\nAbstracts: March 21, 2024 \nFebruary 29, 2024\nViSNet: A general molecular geometry modeling framework for predicting molecular properties and simulating molecular dynamics \nJuly 7, 2023\nDistributional Graphormer: Toward equilibrium distribution prediction for molecular systems \nSee all blog posts\nResearch Areas\nArtificial intelligence\nResearch Groups\nAccelerating Foundation Models Research\nRelated tools\nMicrosoft Research Accurate Chemistry Collection (MSR-ACC)\nRelated labs\nMicrosoft Research AI for Science\nRelated videos\nWhat is Density Functional Theory (DFT)?\nDeep learning for DFT\nDFT for drug and material discovery\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "New methods boost reasoning in small and large language models ",
    "link": "https://www.microsoft.com/en-us/research/blog/new-methods-boost-reasoning-in-small-and-large-language-models/",
    "excerpt": "New techniques are reimagining how LLMs reason. By combining symbolic logic, mathematical rigor, and adaptive planning, these methods enable models to tackle complex, real-world problems across a variety of fields.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nNew methods boost reasoning in small and large language models\n\nPublished June 17, 2025\n\nBy Li Lyna Zhang , Principal Researcher  Xian Zhang , Senior Researcher  Xueting Han , PRINCIPAL RESEARCHER  Dongdong Zhang , Principal Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nArtificial intelligence is advancing across a wide range of fields, with one of the most important developments being its growing capacity for reasoning. This capability could help AI becomes a reliable partner in critical domains like scientific research and healthcare.\n\nTo support this progress, we’ve identified three primary strategies to strengthen reasoning capabilities in both small and large language models: improve architectural design to boost performance in smaller models; incorporate mathematical reasoning techniques to increase reliability; and build stronger generalization capabilities to enable reasoning across a variety of fields.\n\nSmarter reasoning in smaller models\n\nWhile language models trained on broad world knowledge hold great potential, they lack the ability to learn continuously and refine their understanding. This limitation becomes especially pronounced in smaller models, where limited capacity makes strong reasoning even harder.\n\nSPOTLIGHT: BLOG POST\n\nGraphRAG auto-tuning provides rapid adaptation to new domains\n\nGraphRAG uses LLM-generated knowledge graphs to substantially improve complex Q&A over retrieval-augmented generation (RAG). Discover automatic tuning of GraphRAG for new datasets, making it more accurate and relevant.\n\nRead more\nOpens in a new tab\n\nThe problem stems from how current language models operate. They rely on fast, pattern recognition-based responses that break down in complex scenarios. In contrast, people use deliberate, step-by-step reasoning, test different approaches, and evaluate outcomes. To address this gap, we’re building methods to enable stronger reasoning in smaller systems.\n\nrStar-Math is a method that uses Monte Carlo Tree Search (MCTS) to simulate deeper, more methodical reasoning in smaller models. It uses a three-step, self-improving cycle: \n\nProblem decomposition breaks down complex mathematical problems into manageable steps, creating a thorough and accurate course of reasoning.\nProcess preference model (PPM) trains small models to predict reward labels for each step, improving process-level supervision.\nIterative refinement applies a four-round, self-improvement cycle in which updated strategy models and PPMs guide MCTS to improve performance. \n\nWhen tested on four small language models ranging from 1.5 billion to 7 billion parameters, rStar-Math achieved an average accuracy of 53% on the American Invitational Mathematics Examination (AIME)—performance that places it among the top 20% of high school competitors in the US.\n\nFigure 1. The rStar-Math framework\n\nLogic-RL is a reinforcement learning framework that strengthens logical reasoning through a practical system prompt and a structured reward function. By training models on logic puzzles, Logic-RL grants rewards only when both the reasoning process and the final answer meet strict formatting requirements. This prevents shortcuts and promotes analytical rigor.\n\nLanguage models trained with Logic-RL demonstrate strong performance beyond logic puzzles, generalizing effectively to mathematical competition problems. On the AIME and AMC (American Mathematics Competitions) datasets, 7-billion-parameter models improved accuracy by 125% and 38%, respectively, compared with baseline models.\n\nBuilding reliable mathematical reasoning \n\nMathematics poses a unique challenge for language models, which often struggle to meet its precision and rigor using natural language. To address this, we’re creating formal and symbolic methods to enable language models to adopt structured mathematical tools. The goal is to convert language model outputs into code based on the fundamental rules of arithmetic, like 1 + 1 = 2, allowing us to systematically verify accuracy. \n\nLIPS (LLM-based Inequality Prover with Symbolic Reasoning) is a system that combines LLMs’ pattern recognition capabilities with symbolic reasoning. LIPS draws on the strategies participants in math competitions use in order to distinguish between tasks best suited to symbolic solvers (e.g., scaling) and those better handled by language models (e.g., rewriting). On 161 Olympiad-level problems, LIPS achieved state-of-the-art results without additional training data.\n\nFigure 2. An overview of LIPS\n\nHowever, translating natural-language math problems into precise, machine-readable formats is a challenge. Our goal is to bridge the gap between the one-pass success rate, where the top-ranked generated result is correct, and the k-pass success rate, where at least one of the top k generated results is correct.\n\nWe developed a new framework using two evaluation methods. Symbolic equivalence checks whether outputs are logically identical, while semantic consistency uses embedding similarity to detect subtle differences missed by symbolic checks.\n\nWhen we evaluated this approach on the MATH and miniF2F datasets, which include problems from various math competitions, it improved accuracy by up to 1.35 times over baseline methods.\n\nFigure 3. An overview of the auto-formalization framework\n\nTo address the shortage of high-quality training data, we developed a neuro-symbolic framework that automatically generates diverse, well-structured math problems. Symbolic solvers create the problems, while language models translate them into natural language. This approach not only broadens training resources but also supports more effective instruction and evaluation of mathematical reasoning in language models.\n\nFigure 4. An overview of the neuro-symbolic data generation framework\nBoosting generalization across domains \n\nA key indicator of advanced AI is its ability to generalize—the ability to transfer reasoning skills across different domains. We found that training language models on math data significantly improved performance in coding, science, and other areas, revealing unexpected cross-domain benefits. \n\nThis discovery motivated us to develop Chain-of-Reasoning (CoR), an approach that unifies reasoning across natural language, code, and symbolic forms. CoR lets models blend these formats using natural language to frame context, code for precise calculations, and symbolic representations for abstraction. By adjusting prompts, CoR adapts both reasoning depth and paradigm diversity to match specific problem requirements. \n\nTests of CoR across five math datasets showed its ability to tackle both computational and proof-based problems, demonstrating strong general mathematical problem-solving skills.\n\nFigure 5. CoR’s reasoning process under different types of methods\n\nCurrent language models often rely on domain-specific solutions, limiting their flexibility across different types of problems. To move beyond this constraint, we developed Critical Plan Step Learning (CPL), an approach focused on high-level abstract planning that teaches models to identify key knowledge, break down problems, and make strategic decisions. \n\nThe technique draws on how people solve problems, by breaking them down, identifying key information, and recalling relevant knowledge—strategies we want language models to learn. \n\nCPL combines two key components: plan-based MCTS, which searches multi-step solution paths and constructs planning trees, and step-APO, which learns preferences for strong intermediate steps while filtering out weak ones. This combination enhances reasoning and improves generalization across tasks, moving AI systems closer to the flexible thinking that characterizes human intelligence.\n\nFigure 6. Overview of the CPL framework\nLooking ahead: Next steps in AI reasoning\n\nFrom building reliable math solvers to unifying reasoning approaches, researchers are redefining how language models approach complex tasks. Their work sets the stage for more capable and versatile AI systems—applicable to education, science, healthcare, and beyond. Despite these advances, hallucinations and imprecise logic continue to pose risks in critical fields like medicine and scientific research, where accuracy is essential.\n\nThese challenges are driving the team’s exploration of additional tools and frameworks to improve language model reasoning. This includes AutoVerus for automated proof generation in Rust code, SAFE for addressing data scarcity in Rust formal verification, and Alchemy, which uses symbolic mutation to improve neural theorem proving.\n\nTogether, these technologies represent important progress toward building trustworthy, high-performing reasoning models and signal a broader shift toward addressing some of AI’s current limitations.\n\nOpens in a new tab\nRelated publications\nNeuro-Symbolic Data Generation for Math Reasoning\nAutomated Proof Generation for Rust Code via Self-Evolution\nAutoVerus: Automated Proof Generation for Rust Code\nProving Olympiad Inequalities by Synergizing LLMs and Symbolic Reasoning\nChain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective\nAutoformalizing Mathematical Statements by Symbolic Equivalence and Semantic Consistency\nAlchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation\nMeet the authors\nLi Lyna Zhang\n\nPrincipal Researcher\n\nLearn more\nXian Zhang\n\nSenior Researcher\n\nLearn more\nXueting Han\n\nPRINCIPAL RESEARCHER\n\nLearn more\nDongdong Zhang\n\nPrincipal Research Manager\n\nLearn more\nContinue reading\nMay 6, 2024\nAbstracts: May 6, 2024 \nMarch 5, 2024\nOrca-Math: Demonstrating the potential of SLMs with model specialization \nDecember 12, 2023\nPhi-2: The surprising power of small language models \nNovember 20, 2023\nOrca 2: Teaching Small Language Models How to Reason \nSee all blog posts\nResearch Areas\nArtificial intelligence\nRelated tools\nrStar\nAutoVerus\nChain of Reasoning (CoR)\nRelated labs\nMicrosoft Research Lab - Asia\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Rewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library  ",
    "link": "https://www.microsoft.com/en-us/research/blog/rewriting-symcrypt-in-rust-to-modernize-microsofts-cryptographic-library/",
    "excerpt": "We're rewriting parts of Microsoft's SymCrypt cryptographic library in Rust to improve memory safety and defend against side-channel attacks, enabling formal verification while maintaining backward compatibility via a Rust-to-C compiler.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nRewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library \n\nPublished June 10, 2025\n\nBy Jonathan Protzenko , Principal Researcher  Samuel Lee , Senior Software Engineer  Samreen Khadeer , Sr. Security Technical PM  Son Ho , Researcher  Oleksii Oleksenko , Senior Researcher  Michael Naehrig , Principal Researcher  Cédric Fournet , Senior Principal Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nOutdated coding practices and memory-unsafe languages like C are putting software, including cryptographic libraries, at risk. Fortunately, memory-safe languages like Rust, along with formal verification tools, are now mature enough to be used at scale, helping prevent issues like crashes, data corruption, flawed implementation, and side-channel attacks.\n\nTo address these vulnerabilities and improve memory safety, we’re rewriting SymCrypt\n(opens in new tab)\n—Microsoft’s open-source cryptographic library—in Rust. We’re also incorporating formal verification methods. SymCrypt is used in Windows, Azure Linux, Xbox, and other platforms.\n\nCurrently, SymCrypt is primarily written in cross-platform C, with limited use of hardware-specific optimizations through intrinsics (compiler-provided low-level functions) and assembly language (direct processor instructions). It provides a wide range of algorithms, including AES-GCM, SHA, ECDSA, and the more recent post-quantum algorithms ML-KEM and ML-DSA. \n\nFormal verification will confirm that implementations behave as intended and don’t deviate from algorithm specifications, critical for preventing attacks. We’ll also analyze compiled code to detect side-channel leaks caused by timing or hardware-level behavior.\n\nProving Rust program properties with Aeneas\n\nProgram verification is the process of proving that a piece of code will always satisfy a given property, no matter the input. Rust’s type system profoundly improves the prospects for program verification by providing strong ownership guarantees, by construction, using a discipline known as “aliasing xor mutability”.\n\nFor example, reasoning about C code often requires proving that two non-const pointers are live and non-overlapping, a property that can depend on external client code. In contrast, Rust’s type system guarantees this property for any two mutably borrowed references.\n\nAs a result, new tools have emerged specifically for verifying Rust code. We chose Aeneas\n(opens in new tab)\n because it helps provide a clean separation between code and proofs.\n\nDeveloped by Microsoft Azure Research in partnership with Inria, the French National Institute for Research in Digital Science and Technology, Aeneas connects to proof assistants like Lean\n(opens in new tab)\n, allowing us to draw on a large body of mathematical proofs—especially valuable given the mathematical nature of cryptographic algorithms—and benefit from Lean’s active user community.\n\nCompiling Rust to C supports backward compatibility  \n\nWe recognize that switching to Rust isn’t feasible for all use cases, so we’ll continue to support, extend, and certify C-based APIs as long as users need them. Users won’t see any changes, as Rust runs underneath the existing C APIs.\n\nSome users compile our C code directly and may rely on specific toolchains or compiler features that complicate the adoption of Rust code. To address this, we will use Eurydice\n(opens in new tab)\n, a Rust-to-C compiler developed by Microsoft Azure Research, to replace handwritten C code with C generated from formally verified Rust. Eurydice\n(opens in new tab)\n compiles directly from Rust’s MIR intermediate language, and the resulting C code will be checked into the SymCrypt repository alongside the original Rust source code.\n\nAs more users adopt Rust, we’ll continue supporting this compilation path for those who build SymCrypt from source code but aren’t ready to use the Rust compiler. In the long term, we hope to transition users to either use precompiled SymCrypt binaries (via C or Rust APIs), or compile from source code in Rust, at which point the Rust-to-C compilation path will no longer be needed.\n\nSPOTLIGHT: BLOG POST\n\nMedFuzz: Exploring the robustness of LLMs on medical challenge problems\n\nMedfuzz tests LLMs by breaking benchmark assumptions, exposing vulnerabilities to bolster real-world accuracy.\n\nRead more\nOpens in a new tab\nTiming analysis with Revizor \n\nEven software that has been verified for functional correctness can remain vulnerable to low-level security threats, such as side channels caused by timing leaks or speculative execution. These threats operate at the hardware level and can leak private information, such as memory load addresses, branch targets, or division operands, even when the source code is provably correct. \n\nTo address this, we’re extending Revizor\n(opens in new tab)\n, a tool developed by Microsoft Azure Research, to more effectively analyze SymCrypt binaries. Revizor models microarchitectural leakage and uses fuzzing techniques to systematically uncover instructions that may expose private information through known hardware-level effects.  \n\nEarlier cryptographic libraries relied on constant-time programming to avoid operations on secret data. However, recent research has shown that this alone is insufficient with today’s CPUs, where every new optimization may open a new side channel. \n\nBy analyzing binary code for specific compilers and platforms, our extended Revizor tool enables deeper scrutiny of vulnerabilities that aren’t visible in the source code.\n\nVerified Rust implementations begin with ML-KEM\n\nThis long-term effort is in alignment with the Microsoft Secure Future Initiative and brings together experts across Microsoft, building on decades of Microsoft Research investment in program verification and security tooling.\n\nA preliminary version of ML-KEM in Rust is now available on the preview feature/verifiedcrypto\n(opens in new tab)\n branch of the SymCrypt repository. We encourage users to try the Rust build and share feedback\n(opens in new tab)\n. Looking ahead, we plan to support direct use of the same cryptographic library in Rust without requiring C bindings. \n\nOver the coming months, we plan to rewrite, verify, and ship several algorithms in Rust as part of SymCrypt. As our investment in Rust deepens, we expect to gain new insights into how to best leverage the language for high-assurance cryptographic implementations with low-level optimizations. \n\nAs performance is key to scalability and sustainability, we’re holding new implementations to a high bar using our benchmarking tools to match or exceed existing systems.\n\nLooking forward \n\nThis is a pivotal moment for high-assurance software. Microsoft’s investment in Rust and formal verification presents a rare opportunity to advance one of our key libraries. We’re excited to scale this work and ultimately deliver an industrial-grade, Rust-based, FIPS-certified cryptographic library.\n\nOpens in a new tab\nMeet the authors\nJonathan Protzenko\n\nPrincipal Researcher\n\nLearn more\nSamuel Lee\n\nSenior Software Engineer\n\nLearn more\nSamreen Khadeer\n\nSr. Security Technical PM\n\nLearn more\nSon Ho\n\nResearcher\n\nLearn more\nOleksii Oleksenko\n\nSenior Researcher\n\nLearn more\nMichael Naehrig\n\nPrincipal Researcher\n\nLearn more\nCédric Fournet\n\nSenior Principal Research Manager\n\nLearn more\nContinue reading\nMay 27, 2025\nFrodoKEM: A conservative quantum-safe cryptographic algorithm \nSeptember 8, 2023\nIntern Insights: Dr. Josh Benaloh with Anunay Kulshrestha and Karan Newatia \nSeptember 5, 2023\nRethinking trust in direct messages in the AI era \nSee all blog posts\nResearch Areas\nSecurity, privacy, and cryptography\nRelated tools\nRevizor: a fuzzer to search for microarchitectural leaks in CPUs\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "BenchmarkQED: Automated benchmarking of RAG systems ",
    "link": "https://www.microsoft.com/en-us/research/blog/benchmarkqed-automated-benchmarking-of-rag-systems/",
    "excerpt": "BenchmarkQED is an open-source toolkit for benchmarking RAG systems using automated query generation, evaluation, and dataset prep. It shows that LazyGraphRAG outperforms standard methods, especially on complex, global queries.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nBenchmarkQED: Automated benchmarking of RAG systems\n\nPublished June 5, 2025\n\nBy Darren Edge , Senior Director  Ha Trinh , Senior Data Scientist  Andres Morales Esquivel , Senior Research Software Engineer  Jonathan Larson , Partner Data Architect\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nOne of the key use cases for generative AI involves answering questions over private datasets, with retrieval-augmented generation (RAG) as the go-to framework. As new RAG techniques emerge, there’s a growing need to benchmark their performance across diverse datasets and metrics. \n\nTo meet this need, we’re introducing BenchmarkQED, a new suite of tools that automates RAG benchmarking at scale, available on GitHub\n(opens in new tab)\n. It includes components for query generation, evaluation, and dataset preparation, each designed to support rigorous, reproducible testing.  \n\nBenchmarkQED complements the RAG methods in our open-source GraphRAG library, enabling users to run a GraphRAG-style evaluation across models, metrics, and datasets. GraphRAG uses a large language model (LLM) to generate and summarize entity-based knowledge graphs, producing more comprehensive and diverse answers than standard RAG for large-scale tasks. \n\nIn this post, we walk through the core components of BenchmarkQED that contribute to the overall benchmarking process. We also share some of the latest benchmark results comparing our LazyGraphRAG system to competing methods, including a vector-based RAG with a 1M-token context window, where the leading LazyGraphRAG configuration showed significant win rates across all combinations of quality metrics and query classes.\n\nIn the paper, we distinguish between local queries, where answers are found in a small number of text regions, and sometimes even a single region, and global queries, which require reasoning over large portions of or even the entire dataset. \n\nConventional vector-based RAG excels at local queries because the regions containing the answer to the query resemble the query itself and can be retrieved as the nearest neighbor in the vector space of text embeddings. However, it struggles with global questions, such as, “What are the main themes of the dataset?” which require understanding dataset qualities not explicitly stated in the text.  \n\nAutoQ: Automated query synthesis\n\nThis limitation motivated the development of GraphRAG a system designed to answer global queries. GraphRAG’s evaluation requirements subsequently led to the creation of AutoQ, a method for synthesizing these global queries for any dataset.\n\nAutoQ extends this approach by generating synthetic queries across the spectrum of queries, from local to global. It defines four distinct classes based on the source and scope of the query (Figure 1, top) forming a logical progression along the spectrum (Figure 1, bottom).\n\nFigure 1. Construction of a 2×2 design space for synthetic query generation with AutoQ, showing how the four resulting query classes map onto the local-global query spectrum. \n\nAutoQ can be configured to generate any number and distribution of synthetic queries along these classes, enabling consistent benchmarking across datasets without requiring user customization. Figure 2 shows the synthesis process and sample queries from each class, using an AP News dataset.\n\nFigure 2. Synthesis process and example query for each of the four AutoQ query classes. \nAbout Microsoft Research\n\nAdvancing science and technology to benefit humanity\n\nView our story\nOpens in a new tab\nAutoE: Automated evaluation framework \n\nOur evaluation of GraphRAG focused on analyzing key qualities of answers to global questions. The following qualities were used for the current evaluation:\n\nComprehensiveness: Does the answer address all relevant aspects of the question? \nDiversity: Does it present varied perspectives or insights? \nEmpowerment: Does it help the reader understand and make informed judgments? \nRelevance: Does it address what the question is specifically asking?  \n\nThe AutoE component scales evaluation of these qualities using the LLM-as-a-Judge method. It presents pairs of answers to an LLM, along with the query and target metric, in counterbalanced order. The model determines whether the first answer wins, loses, or ties with the second. Over a set of queries, whether from AutoQ or elsewhere, this produces win rates between competing methods. When ground truth is available, AutoE can also score answers on correctness, completeness, and related metrics.\n\nAn illustrative evaluation is shown in Figure 3. Using a dataset of 1,397 AP News articles on health and healthcare, AutoQ generated 50 queries per class (200 total). AutoE then compared LazyGraphRAG to a competing RAG method, running six trials per query across four metrics, using GPT-4.1 as a judge.\n\nThese trial-level results were aggregated using metric-based win rates, where each trial is scored 1 for a win, 0.5 for a tie, and 0 for a loss, and then averaged to calculate the overall win rate for each RAG method.\n\nFigure 3. Win rates of four LazyGraphRAG (LGR) configurations across methods, broken down by the AutoQ query class and averaged across AutoE’s four metrics: comprehensiveness, diversity, empowerment, and relevance. LazyGraphRAG outperforms comparison conditions where the bar is above 50%.\n\nThe four LazyGraphRAG conditions (LGR_b200_c200, LGR_b50_c200, LGR_b50_c600, LGR_b200_c200_mini) differ by query budget (b50, b200) and chunk size (c200, c600). All used GPT-4o mini for relevance tests and GPT-4o for query expansion (to five subqueries) and answer generation, except for LGR_b200_c200_mini, which used GPT-4o mini throughout.\n\nComparison systems were GraphRAG (Local, Global, and Drift Search), Vector RAG with 8k- and 120k-token windows, and three published methods: LightRAG\n(opens in new tab)\n, RAPTOR\n(opens in new tab)\n, and TREX\n(opens in new tab)\n. All methods were limited to the same 8k tokens for answer generation. GraphRAG Global Search used level 2 of the community hierarchy.\n\nLazyGraphRAG outperformed every comparison condition using the same generative model (GPT-4o), winning all 96 comparisons, with all but one reaching statistical significance. The best overall performance came from the larger budget, smaller chunk size configuration (LGR_b200_c200). For DataLocal queries, the smaller budget (LGR_b50_c200) performed slightly better, likely because fewer chunks were relevant. For ActivityLocal queries, the larger chunk size (LGR_b50_c600) had a slight edge, likely because longer chunks provide a more coherent context.\n\nCompeting methods performed relatively better on the query classes for which they were designed: GraphRAG Global for global queries, Vector RAG for local queries, and GraphRAG Drift Search, which combines both strategies, posed the strongest challenge overall.\n\nIncreasing Vector RAG’s context window from 8k to 120k tokens did not improve its performance compared to LazyGraphRAG. This raised the question of how LazyGraphRAG would perform against Vector RAG with 1-million token context window containing most of the dataset.\n\nFigure 4 shows the follow-up experiment comparing LazyGraphRAG to Vector RAG using GPT-4.1 that enabled this comparison. Even against the 1M-token window, LazyGraphRAG achieved higher win rates across all comparisons, failing to reach significance only for the relevance of answers to DataLocal queries. These queries tend to benefit most from Vector RAG’s ranking of directly relevant chunks, making it hard for LazyGraphRAG to generate answers that have greater relevance to the query, even though these answers may be dramatically more comprehensive, diverse, and empowering overall.\n\nFigure 4. Win rates of LazyGraphRAG (LGR) over Vector RAG across different context window sizes, broken down by the four AutoQ query classes and four AutoE metrics: comprehensiveness, diversity, empowerment, and relevance. Bars above 50% indicate that LazyGraphRAG outperformed the comparison condition. \nAutoD: Automated data sampling and summarization\n\nText datasets have an underlying topical structure, but the depth, breadth, and connectivity of that structure can vary widely. This variability makes it difficult to evaluate RAG systems consistently, as results may reflect the idiosyncrasies of the dataset rather than the system’s general capabilities.\n\nThe AutoD component addresses this by sampling datasets to meet a target specification, defined by the number of topic clusters (breadth) and the number of samples per cluster (depth). This creates consistency across datasets, enabling more meaningful comparisons, as structurally aligned datasets lead to comparable AutoQ queries, which in turn support consistent AutoE evaluations.\n\nAutoD also includes tools for summarizing input or output datasets in a way that reflects their topical coverage. These summaries play an important role in the AutoQ query synthesis process, but they can also be used more broadly, such as in prompts where context space is limited.\n\nSupporting the community with open data and tools \n\nSince the release of the GraphRAG paper, we’ve received many requests to share the dataset of the Behind the Tech\n(opens in new tab)\n podcast transcripts we used in our evaluation. An updated version of this dataset is now available in the BenchmarkQED repository\n(opens in new tab)\n, alongside the AP News dataset containing 1,397 health-related articles, licensed for open release.  \n\nWe hope these datasets, together with the BenchmarkQED tools\n(opens in new tab)\n, help accelerate benchmark-driven development of RAG systems and AI question-answering. We invite the community to try them on GitHub\n(opens in new tab)\n. \n\nOpens in a new tab\nRelated publications\nFrom Local to Global: A Graph RAG Approach to Query-Focused Summarization\nMeet the authors\nDarren Edge\n\nSenior Director\n\nLearn more\nHa Trinh\n\nSenior Data Scientist\n\nLearn more\nAndres Morales Esquivel\n\nSenior Research Software Engineer\n\nLearn more\nJonathan Larson\n\nPartner Data Architect\n\nLearn more\nContinue reading\nDecember 16, 2024\nMoving to GraphRAG 1.0 – Streamlining ergonomics for developers and users \nNovember 25, 2024\nLazyGraphRAG: Setting a new standard for quality and cost \nJuly 2, 2024\nGraphRAG: New tool for complex data discovery now on GitHub \nFebruary 13, 2024\nGraphRAG: Unlocking LLM discovery on narrative private data \nSee all blog posts\nResearch Areas\nArtificial intelligence\nRelated tools\nGraphRAG\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "FrodoKEM: A conservative quantum-safe cryptographic algorithm ",
    "link": "https://www.microsoft.com/en-us/research/blog/frodokem-a-conservative-quantum-safe-cryptographic-algorithm/",
    "excerpt": "The recent advances in quantum computing offer many advantages—but also challenge current cryptographic strategies. Learn how FrodoKEM could help strengthen security, even in a future with powerful quantum computers.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nFrodoKEM: A conservative quantum-safe cryptographic algorithm\n\nPublished May 27, 2025\n\nBy Patrick Longa , Principal Researcher\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn this post, we describe FrodoKEM, a key encapsulation protocol that offers a simple design and provides strong security guarantees even in a future with powerful quantum computers.\n\nThe quantum threat to cryptography\n\nFor decades, modern cryptography has relied on mathematical problems that are practically impossible for classical computers to solve without a secret key. Cryptosystems like RSA, Diffie-Hellman key-exchange, and elliptic curve-based schemes—which rely on the hardness of the integer factorization and (elliptic curve) discrete logarithm problems—secure communications on the internet, banking transactions, and even national security systems. However, the emergence of quantum computing poses a significant threat to these cryptographic schemes.\n\nQuantum computers leverage the principles of quantum mechanics to perform certain calculations exponentially faster than classical computers. Their ability to solve complex problems, such as simulating molecular interactions, optimizing large-scale systems, and accelerating machine learning, is expected to have profound and beneficial implications for fields ranging from chemistry and material science to artificial intelligence.\n\nAzure AI Foundry Labs\n\nGet a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.\n\nAzure AI Foundry\nOpens in a new tab\n\nAt the same time, quantum computing is poised to disrupt cryptography. In particular, Shor’s algorithm, a quantum algorithm developed in 1994, can efficiently factor large numbers and compute discrete logarithms—the very problems that underpin the security of RSA, Diffie-Hellman, and elliptic curve cryptography. This means that once large-scale, fault-tolerant quantum computers become available, public-key protocols based on RSA, ECC, and Diffie-Hellman will become insecure, breaking a sizable portion of the cryptographic backbone of today’s digital world. Recent advances in quantum computing, such as Microsoft’s Majorana 1\n(opens in new tab)\n, the first quantum processor powered by topological qubits, represent major steps toward practical quantum computing and underscore the urgency of transitioning to quantum-resistant cryptographic systems.\n\nTo address this looming security crisis, cryptographers and government agencies have been working on post-quantum cryptography (PQC)—new cryptographic algorithms that can resist attacks from both classical and quantum computers.\n\nThe NIST Post-Quantum Cryptography Standardization effort\n\nIn 2017, the U.S. National Institute of Standards and Technology (NIST) launched the Post-Quantum Cryptography Standardization project\n(opens in new tab)\n to evaluate and select cryptographic algorithms capable of withstanding quantum attacks. As part of this initiative, NIST sought proposals for two types of cryptographic primitives: key encapsulation mechanisms (KEMs)—which enable two parties to securely derive a shared key to establish an encrypted connection, similar to traditional key exchange schemes—and digital signature schemes.\n\nThis initiative attracted submissions from cryptographers worldwide, and after multiple evaluation rounds, NIST selected CRYSTALS-Kyber, a KEM based on structured lattices, and standardized it as ML-KEM\n(opens in new tab)\n. Additionally, NIST selected three digital signature schemes: CRYSTALS-Dilithium, now called ML-DSA; SPHINCS+, now called SLH-DSA; and Falcon, now called FN-DSA.\n\nWhile ML-KEM provides great overall security and efficiency, some governments and cryptographic researchers advocate for the inclusion and standardization of alternative algorithms that minimize reliance on algebraic structure. Reducing algebraic structure might prevent potential vulnerabilities and, hence, can be considered a more conservative design choice. One such algorithm is FrodoKEM.\n\nInternational standardization of post-quantum cryptography\n\nBeyond NIST, other international standardization bodies have been actively working on quantum-resistant cryptographic solutions. The International Organization for Standardization (ISO) is leading a global effort to standardize additional PQC algorithms. Notably, European government agencies—including Germany’s BSI\n(opens in new tab)\n, the Netherlands’ NLNCSA and AIVD\n(opens in new tab)\n, and France’s ANSSI\n(opens in new tab)\n—have shown strong support for FrodoKEM, recognizing it as a conservative alternative to structured lattice-based schemes.\n\nAs a result, FrodoKEM is undergoing standardization at ISO. Additionally, ISO is standardizing ML-KEM and a conservative code-based KEM called Classic McEliece. These three algorithms are planned for inclusion in ISO/IEC 18033-2:2006 as Amendment 2\n(opens in new tab)\n.\n\nWhat is FrodoKEM?\n\nFrodoKEM is a key encapsulation mechanism (KEM) based on the Learning with Errors (LWE) problem, a cornerstone of lattice-based cryptography. Unlike structured lattice-based schemes such as ML-KEM, FrodoKEM is built on generic, unstructured lattices, i.e., it is based on the plain LWE problem.\n\nWhy unstructured lattices?\n\nStructured lattice-based schemes introduce additional algebraic properties that could potentially be exploited in future cryptanalytic attacks. By using unstructured lattices, FrodoKEM eliminates these concerns, making it a safer choice in the long run, albeit at the cost of larger key sizes and lower efficiency.\n\nIt is important to emphasize that no particular cryptanalytic weaknesses are currently known for recommended parameterizations of structured lattice schemes in comparison to plain LWE. However, our current understanding of the security of these schemes could potentially change in the future with cryptanalytic advances.\n\nLattices and the Learning with Errors (LWE) problem\n\nLattice-based cryptography relies on the mathematical structure of lattices, which are regular arrangements of points in multidimensional space. A lattice is defined as the set of all integer linear combinations of a set of basis vectors. The difficulty of certain computational problems on lattices, such as the Shortest Vector Problem (SVP) and the Learning with Errors (LWE) problem, forms the basis of lattice-based schemes.\n\nThe Learning with Errors (LWE) problem\n\nThe LWE problem is a fundamental hard problem in lattice-based cryptography. It involves solving a system of linear equations where some small random error has been added to each equation, making it extremely difficult to recover the original secret values. This added error ensures that the problem remains computationally infeasible, even for quantum computers. Figure 1 below illustrates the LWE problem, specifically, the search version of the problem.\n\nAs can be seen in Figure 1, for the setup of the problem we need a dimension \n𝑛\n that defines the size of matrices, a modulus \n𝑞\n that defines the value range of the matrix coefficients, and a certain error distribution \n𝜒\n from which we sample \n“small”\n matrices. We sample two matrices from \n𝜒\n, a small matrix \ns\n and an error matrix \ne\n (for simplicity in the explanation, we assume that both have only one column); sample an \n𝑛\n×\n𝑛\n matrix \nA\n uniformly at random; and compute \nb\n=\nA\n×\ns\n+\ne\n. In the illustration, each matrix coefficient is represented by a colored square, and the “legend of coefficients” gives an idea of the size of the respective coefficients, e.g., orange squares represent the small coefficients of matrix \ns\n (small relative to the modulus \n𝑞\n). Finally, given \nA\n and \nb\n, the search LWE problem consists in finding \ns\n. This problem is believed to be hard for suitably chosen parameters (e.g., for dimension \n𝑛\n sufficiently large) and is used at the core of FrodoKEM.\n\nIn comparison, the LWE variant used in ML-KEM—called Module-LWE (M-LWE)—has additional symmetries, adding mathematical structure that helps improve efficiency. In a setting similar to that of the search LWE problem above, the matrix \nA\n can be represented by just a single row of coefficients.\n\nFIGURE 1: Visualization of the (search) LWE problem.\n\nLWE is conjectured to be quantum-resistant, and FrodoKEM’s security is directly tied to its hardness. In other words, cryptanalysts and quantum researchers have not been able to devise an efficient quantum algorithm capable of solving the LWE problem and, hence, FrodoKEM. In cryptography, absolute security can never be guaranteed; instead, confidence in a problem’s hardness comes from extensive scrutiny and its resilience against attacks over time.\n\nHow FrodoKEM Works\n\nFrodoKEM follows the standard paradigm of a KEM, which consists of three main operations—key generation, encapsulation, and decapsulation—performed interactively between a sender and a recipient with the goal of establishing a shared secret key:\n\nKey generation (KeyGen), computed by the recipient\nGenerates a public key and a secret key.\nThe public key is sent to the sender, while the private key remains secret.\nEncapsulation (Encapsulate), computed by the sender\nGenerates a random session key.\nEncrypts the session key using the recipient’s public key to produce a ciphertext.\nProduces a shared key using the session key and the ciphertext.\nThe ciphertext is sent to the recipient.\nDecapsulation (Decapsulate), computed by the recipient\nDecrypts the ciphertext using their secret key to recover the original session key.\nReproduces the shared key using the decrypted session key and the ciphertext.\n\nThe shared key generated by the sender and reconstructed by the recipient can then be used to establish secure symmetric-key encryption for further communication between the two parties.\n\nFigure 2 below shows a simplified view of the FrodoKEM protocol. As highlighted in red, FrodoKEM uses at its core LWE operations of the form “\nb\n=\nA\n×\ns\n+\ne\n”, which are directly applied within the KEM paradigm.\n\nFIGURE 2: Simplified overview of FrodoKEM.\nPerformance: Strong security has a cost\n\nNot relying on additional algebraic structure certainly comes at a cost for FrodoKEM in the form of increased protocol runtime and bandwidth. The table below compares the performance and key sizes corresponding to the FrodoKEM level 1 parameter set (variant called “FrodoKEM-640-AES”) and the respective parameter set of ML-KEM (variant called “ML-KEM-512”). These parameter sets are intended to match or exceed the brute force security of AES-128. As can be seen, the difference in speed and key sizes between FrodoKEM and ML-KEM is more than an order of magnitude. Nevertheless, the runtime of the FrodoKEM protocol remains reasonable for most applications. For example, on our benchmarking platform clocked at 3.2GHz, the measured runtimes are 0.97 ms, 1.9 ms, and 3.2 ms for security levels 1, 2, and 3, respectively.\n\nFor security-sensitive applications, a more relevant comparison is with Classic McEliece, a post-quantum code-based scheme also considered for standardization. In this case, FrodoKEM offers several efficiency advantages. Classic McEliece’s public keys are significantly larger—well over an order of magnitude greater than FrodoKEM’s—and its key generation is substantially more computationally expensive. Nonetheless, Classic McEliece provides an advantage in certain static key-exchange scenarios, where its high key generation cost can be amortized across multiple key encapsulation executions.\n\nTABLE 1: Comparison of key sizes and performance on an x86-64 processor for NIST level 1 parameter sets.\nA holistic design made with security in mind\n\nFrodoKEM’s design principles support security beyond its reliance on generic, unstructured lattices to minimize the attack surface of potential future cryptanalytic threats. Its parameters have been carefully chosen with additional security margins to withstand advancements in known attacks. Furthermore, FrodoKEM is designed with simplicity in mind—its internal operations are based on straightforward matrix-vector arithmetic using integer coefficients reduced modulo a power of two. These design decisions facilitate simple, compact and secure implementations that are also easier to maintain and to protect against side-channel attacks.\n\nConclusion\n\nAfter years of research and analysis, the next generation of post-quantum cryptographic algorithms has arrived. NIST has chosen strong PQC protocols that we believe will serve Microsoft and its customers well in many applications. For security-sensitive applications, FrodoKEM offers a secure yet practical approach for post-quantum cryptography. While its reliance on unstructured lattices results in larger key sizes and higher computational overhead compared to structured lattice-based alternatives, it provides strong security assurances against potential future attacks. Given the ongoing standardization efforts and its endorsement by multiple governmental agencies, FrodoKEM is well-positioned as a viable alternative for organizations seeking long-term cryptographic resilience in a post-quantum world.\n\nFurther Reading\n\nFor those interested in learning more about FrodoKEM, post-quantum cryptography, and lattice-based cryptography, the following resources provide valuable insights:\n\nThe official FrodoKEM website: https://frodokem.org/\n(opens in new tab)\n, which contains, among several other resources, FrodoKEM’s specification document.\nThe official FrodoKEM software library: https://github.com/Microsoft/PQCrypto-LWEKE\n(opens in new tab)\n, which contains reference and optimized implementations of FrodoKEM written in C and Python.\nNIST’s Post-Quantum Cryptography Project: https://csrc.nist.gov/projects/post-quantum-cryptography\n(opens in new tab)\n.\nMicrosoft’s blogpost on its transition plan for PQC: https://techcommunity.microsoft.com/blog/microsoft-security-blog/microsofts-quantum-resistant-cryptography-is-here/4238780\n(opens in new tab)\n.\nA comprehensive survey on lattice-based cryptography: Peikert, C. “A Decade of Lattice Cryptography.” Foundations and Trends in Theoretical Computer Science. (2016)\nA comprehensive tutorial on modern lattice-based schemes, including ML-KEM and ML-DSA: Lyubashevsky, V. “Basic Lattice Cryptography: The concepts behind Kyber (ML-KEM) and Dilithium (ML-DSA).” https://eprint.iacr.org/2024/1287\n(opens in new tab)\n. (2024)\nOpens in a new tab\nMeet the authors\nPatrick Longa\n\nPrincipal Researcher\n\nLearn more\nContinue reading\nJune 10, 2025\nRewriting SymCrypt in Rust to modernize Microsoft’s cryptographic library  \nFebruary 19, 2025\nIdeas: Quantum computing redefined with Chetan Nayak \nSeptember 8, 2023\nIntern Insights: Dr. Josh Benaloh with Anunay Kulshrestha and Karan Newatia \nSeptember 5, 2023\nRethinking trust in direct messages in the AI era \nSee all blog posts\nResearch Areas\nQuantum computing\nSecurity, privacy, and cryptography\nRelated projects\nFrodoKEM\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Magentic-UI, an experimental human-centered web agent ",
    "link": "https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/",
    "excerpt": "Magentic-UI, new from Microsoft Research, is an open-source research prototype of a human-centered AI agent, designed to work with people to complete complex, web-based tasks in real time over a web browser.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nMagentic-UI, an experimental human-centered web agent\n\nPublished May 19, 2025\n\nBy Hussein Mozannar , Senior Researcher  Gagan Bansal , Senior Researcher  Cheng Tan , Principal Software Development Engineer  Adam Fourney , Senior Principal Researcher  Victor Dibia , Principal Research Software Engineer  Friederike Niedtner , Principal Technical Research Program Manager  Jack Gerrits , Principal Software Development Engineer  Jacob Alber , Principal Software Engineer  Jingya Chen , UX Designer  Griffin Bassman , Software Engineer II  Erkang (Eric) Zhu , Principal Researcher  Peter Chang , Senior Software Development Engineer  Ricky Loynd , Senior Research Software Engineer  Maya Murad , Senior Technical PM, AI Frontiers  Rafah Hosn , Partner, Group Program Manager  Ece Kamar , VP and Lab Director of AI Frontiers  Saleema Amershi , Partner Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nModern productivity is rooted in the web—from searching for information and filling in forms to navigating dashboards. Yet, many of these tasks remain manual and repetitive. Today, we are introducing Magentic-UI, a new open-source research prototype of a human-centered agent that is meant to help researchers study open questions on human-in-the-loop approaches and oversight mechanisms for AI agents. This prototype collaborates with users on web-based tasks and operates in real time over a web browser. Unlike other computer use agents that aim for full autonomy, Magentic-UI offers a transparent and controllable experience for tasks that are action-oriented and require activities beyond just performing simple web searches.\n\nMagentic-UI builds on Magentic-One\n(opens in new tab)\n, a powerful multi-agent team we released last year, and is powered by AutoGen\n(opens in new tab)\n, our leading agent framework. It is available under MIT license at https://github.com/microsoft/Magentic-UI\n(opens in new tab)\n and on Azure AI Foundry Labs\n(opens in new tab)\n, the hub where developers, startups, and enterprises can explore groundbreaking innovations from Microsoft Research. Magentic-UI is integrated with Azure AI Foundry models and agents. Learn more about how to integrate Azure AI agents into the Magentic-UI multi-agent architecture by following this code sample\n(opens in new tab)\n. \n\nMagentic-UI can perform tasks that require browsing the web, writing and executing Python and shell code, and understanding files. Its key features include:\n\nCollaborative planning with users (co-planning). Magentic-UI allows users to directly modify its plan through a plan editor or by providing textual feedback before Magentic-UI executes any actions. \nCollaborative execution with users (co-tasking). Users can pause the system and give feedback in natural language or demonstrate it by directly taking control of the browser.\nSafety with human-in-the-loop (action guards). Magentic-UI seeks user approval before executing potentially irreversible actions, and the user can specify how often Magentic-UI needs approvals. Furthermore, Magentic-UI is sandboxed for the safe operation of tools such as browsers and code executors.\nSafety with human-in-the-loop. Magentic-UI seeks user approval before executing potentially irreversible actions, and the user can specify how often Magentic-UI needs approvals. Furthermore, Magentic-UI is sandboxed for the safe operation of tools such as browsers and code executors. \nLearning from experience (plan learning). Magentic-UI can learn and save plans from previous interactions to improve task completion for future tasks. \nFigure 1: Screenshot of Magentic-UI actively performing a task. The left side of the screen shows Magentic-UI stating its plan and progress to accomplish a user’s complex goal. The right side shows the browser Magentic-UI is controlling. \nHow is Magentic-UI human-centered?\n\nWhile many web agents promise full autonomy, in practice users can be left unsure of what the agent can do, what it is currently doing, and whether they have enough control to intervene when something goes wrong or doesn’t occur as expected. By contrast, Magentic-UI considers user needs at every stage of interaction. We followed a human-centered design methodology in building Magentic-UI by prototyping and obtaining feedback from pilot users during its design. \n\nFigure 2: Co-planning – Users can collaboratively plan with Magentic-UI.\n\nFor example, after a person specifies and before Magentic-UI even begins to execute, it creates a clear step-by-step plan that outlines what it would do to accomplish the task. People can collaborate with Magentic-UI to modify this plan and then give final approval for Magentic-UI to begin execution. This is crucial as users may have expectations of how the task should be completed; communicating that information could significantly improve agent performance. We call this feature co-planning.\n\nDuring execution, Magentic-UI shows in real time what specific actions it’s about to take. For example, whether it is about to click on a button or input a search query. It also shows in real time what it observed on the web pages it is visiting. Users can take control of the action at any point in time and give control back to the agent. We call this feature co-tasking.\n\nFigure 3: Co-tasking – Magentic-UI provides real-time updates about what it is about to do and what it already did, allowing users to collaboratively complete tasks with the agent.\nFigure 4: Action-guards – Magentic-UI will ask users for permission before executing actions that it deems consequential or important. \n\nAdditionally, Magentic-UI asks for user permission before performing actions that are deemed irreversible, such as closing a tab or clicking a button with side effects. We call these “action guards”. The user can also configure Magentic-UI’s action guards to always ask for permission before performing any action. If the user deems an action risky (e.g., paying for an item), they can reject it. \n\nFigure 5: Plan learning – Once a task is successfully completed, users can request Magentic-UI to learn a step-by-step plan from this experience.\n\nAfter execution, the user can ask Magentic-UI to reflect on the conversation and infer and save a step-by-step plan for future similar tasks. Users can view and modify saved plans for Magentic-UI to reuse in the future in a saved-plans gallery. In a future session, users can launch Magentic-UI with the saved plan to either execute the same task again, like checking the price of a specific flight, or use the plan as a guide to help complete similar tasks, such as checking the price of a different type of flight. \n\nCombined, these four features—co-planning, co-tasking, action guards, and plan learning—enable users to collaborate effectively with Magentic-UI.\n\nArchitecture\n\nMagentic-UI’s underlying system is a team of specialized agents adapted from AutoGen’s Magentic-One system. The agents work together to create a modular system:\n\nOrchestrator is the lead agent, powered by a large language model (LLM), that performs co-planning with the user, decides when to ask the user for feedback, and delegates sub-tasks to the remaining agents to complete.\nWebSurfer is an LLM agent equipped with a web browser that it can control. Given a request by the Orchestrator, it can click, type, scroll, and visit pages in multiple rounds to complete the request from the Orchestrator.\nCoder is an LLM agent equipped with a Docker code-execution container. It can write and execute Python and shell commands and provide a response back to the Orchestrator.\nFileSurfer is an LLM agent equipped with a Docker code-execution container and file-conversion tools from the MarkItDown\n(opens in new tab)\n package. It can locate files in the directory controlled by Magentic-UI, convert files to markdown, and answer questions about them.\nFigure 6: System architecture diagram of Magentic-UI\n\nTo interact with Magentic-UI, users can enter a text message and attach images. In response, Magentic-UI creates a natural-language step-by-step plan with which users can interact through a plan-editing interface. Users can add, delete, edit, regenerate steps, and write follow-up messages to iterate on the plan. While the user editing the plan adds an upfront cost to the interaction, it can potentially save a significant amount of time in the agent executing the plan and increase its chance at success.\n\nThe plan is stored inside the Orchestrator and is used to execute the task. For each step of the plan, the Orchestrator determines which of the agents (WebSurfer, Coder, FileSurfer) or the user should complete the step. Once that decision is made, the Orchestrator sends a request to one of the agents or the user and waits for a response. After the response is received, the Orchestrator decides whether that step is complete. If it is, the Orchestrator moves on to the following step.\n\nOnce all steps are completed, the Orchestrator generates a final answer that is presented to the user. If, while executing any of the steps, the Orchestrator decides that the plan is inadequate (for example, because a certain website is unreachable), the Orchestrator can replan with user permission and start executing a new plan.\n\nAll intermediate progress steps are clearly displayed to the user. Furthermore, the user can pause the execution of the plan and send additional requests or feedback. The user can also configure through the interface whether agent actions (e.g., clicking a button) require approval.\n\nEvaluating Magentic-UI\n\nMagentic-UI innovates through its ability to integrate human feedback in its planning and execution of tasks. We performed a preliminary automated evaluation to showcase this ability on the GAIA benchmark\n(opens in new tab)\n for agents with a user-simulation experiment.\n\nEvaluation with simulated users\nFigure 7: Comparison on the GAIA validation set of the accuracy of Magentic-One, Magentic-UI in autonomous mode, Magentic-UI with a simulated user powered by a smarter LLM than the MAGUI agents, Magentic-UI with a simulated user that has a\\access to side information about the tasks, and human performance. This shows that human-in-the-loop can improve the accuracy of autonomous agents, bridging the gap to human performance at a fraction of the cost.\n\nGAIA is a benchmark for general AI assistants, with multimodal question-answer pairs that are challenging, requiring the agents to navigate the web, process files, and execute code. The traditional evaluation setup with GAIA assumes the system will autonomously complete the task and return an answer, which is compared to the ground-truth answer. \n\nTo evaluate the human-in-the-loop capabilities of Magentic-UI, we transform GAIA into an interactive benchmark by introducing the concept of a simulated user. Simulated users provide value in two ways: by having specific expertise that the agent may not possess, and by providing guidance on how the task should be performed.\n\nWe experiment with two types of simulated users to show the value of human-in-the-loop: (1) a simulated user that is more intelligent than the Magentic-UI agents and (2) a simulated user with the same intelligence as Magentic-UI agents but with additional information about the task. During co-planning, Magentic-UI takes feedback from this simulated user to improve its plan. During co-tasking, Magentic-UI can ask the (simulated) user for help when it gets stuck. Finally, if Magentic-UI does not provide a final answer, then the simulated user provides an answer instead. These experiments reflect a lower bound on the value of human feedback, since real users can step in at any time and offer any kind of input—not just when the system explicitly asks for help.\n\nThe simulated user is an LLM without any tools, instructed to interact with Magentic-UI the way we expect a human would act. The first type of simulated user relies on OpenAI’s o4-mini, more performant at many tasks than the one powering the Magentic-UI agents (GPT-4o). For the second type of simulated user, we use GPT-4o for both the simulated user and the rest of the agents, but the user has access to side information about each task. Each task in GAIA has side information, which includes a human-written plan to solve the task. While this plan is not used as input in the traditional benchmark, in our interactive setting we provide this information to the second type of simulated user,which is powered by an LLM so that it can mimic a knowledgeable user. Importantly, we tuned our simulated user so as not to reveal the ground-truth answer directly as the answer is usually found inside the human written plan. Instead, it is prompted to guide Magentic-UI indirectly. We found that this tuning prevented the simulated user from inadvertently revealing the answer in all but 6% of tasks when Magentic-UI provides a final answer. \n\nOn the validation subset of GAIA (162 tasks), we show the results of Magentic-One operating in autonomous mode, Magentic-UI operating in autonomous mode (without the simulated user), Magentic-UI with simulated user (1) (smarter model), Magentic-UI with simulated user (2) (side-information), and human performance. We first note that Magentic-UI in autonomous mode is within a margin of error of the performance of Magentic-One. Note that the same LLM (GPT-4o) is used for Magentic-UI and Magentic-One.\n\nMagentic-UI with the simulated user that has access to side information improves the accuracy of autonomous Magentic-UI by 71%, from a 30.3% task-completion rate to a 51.9% task-completion rate. Moreover, Magentic-UI only asks for help from the simulated user in 10% of tasks and relies on the simulated user for the final answer in 18% of tasks. And in those tasks where it does ask for help, it asks for help on average 1.1 times. Magentic-UI with the simulated user powered by a smarter model improves to 42.6% where Magentic-UI asks for help in only 4.3% of tasks, asking for help an average of 1.7 times in those tasks. This demonstrates the potential of even lightweight human feedback for improving performance (e.g., task completion) over autonomous agents working alone, especially at a fraction of the cost compared to people completing tasks entirely manually. \n\nLearning and reusing plans\n\nAs described above, once Magentic-UI completes a task, users have the option for Magentic-UI to learn a plan based on the execution of the task. These plans are saved in a plan gallery, which users and Magentic-UI can access in the future.\n\nThe user can select a plan from the plan gallery, which is displayed by clicking on the Saved Plans button. Alternatively, as a user enters a task that closely matches a previous task, the saved plan will be displayed even before the user is done typing. If no identical task is found, Magentic-UI can use AutoGen’s Task-Centric Memory\n(opens in new tab)\n to retrieve plans for any similar tasks. Our preliminary evaluations show that this retrieval is highly accurate, and when recalling a saved plan can be around 3x faster than generating a new plan. Once a plan is recalled or generated, the user can always accept it, modify it, or ask Magentic-UI to modify it for the specific task at hand. \n\nSafety and control\n\nMagentic-UI can surf the live internet and execute code. With such capabilities, we need to ensure that Magentic-UI acts in a safe and secure manner. The following features, design decisions, and evaluations were made to ensure this:\n\nAllow-list: Users can set a list of websites that Magentic-UI is allowed to access. If Magentic-UI needs to access a website outside of the allow-list, users must explicitly approve it through the interface\nAnytime interruptions: At any point of Magentic-UI completing the task, the user can interrupt Magentic-UI and stop any pending code execution or web browsing.\nDocker sandboxing: Magentic-UI controls a browser that is launched inside a Docker container with no credentials, which avoids risks with logged-in accounts and credentials. Moreover, any code execution is also performed inside a separate Docker container to avoid affecting the host environment in which Magentic-UI is running. This is illustrated in the system architecture of Magentic-UI (Figure 3).\nDetection and approval of irreversible agent actions: Users can configure an action-approval policy (action guards) to determine which actions Magentic-UI can perform without user approval. In the extreme, users can specify that any action (e.g., any button click) needs explicit user approval. Users must press an “Accept” or “Deny” button for each action.\n\nIn addition to the above design decisions, we performed a red-team evaluation of Magentic-UI on a set of internal scenarios, which we developed to challenge the security and safety of Magentic-UI. Such scenarios include cross-site prompt injection attacks, where web pages contain malicious instructions distinct from the user’s original intent (e.g., to execute risky code, access sensitive files, or perform actions on other websites). It also contains scenarios comparable to phishing, which try to trick Magentic-UI into entering sensitive information, or granting permissions on impostor sites (e.g., a synthetic website that asks Magentic-UI to log in and enter Google credentials to read an article). In our preliminary evaluations, we found that Magentic-UI either refuses to complete the requests, stops to ask the user, or, as a final safety measure, is eventually unable to complete the request due to Docker sandboxing. We have found that this layered approach is effective for thwarting these attacks.\n\nWe have also released transparency notes, which can be found at: https://github.com/microsoft/magentic-ui/blob/main/TRANSPARENCY_NOTE.md\n(opens in new tab)\n\nOpen research questions \n\nMagentic-UI provides a tool for researchers to study critical questions in agentic systems and particularly on human-agent interaction. In a previous report\n(opens in new tab)\n, we outlined 12 questions for human-agent communication, and Magentic-UI provides a vehicle to study these questions in a realistic setting. A key question among these is how we enable humans to efficiently intervene and provide feedback to the agent while executing a task. Humans should not have to constantly watch the agent. Ideally, the agent should know when to reach out for help and provide the necessary context for the human to assist it. A second question is about safety. As agents interact with the live web, they may become prone to attacks from malicious actors. We need to study what necessary safeguards are needed to protect the human from side effects without adding a heavy burden on the human to verify every agent action. There are also many other questions surrounding security, personalization, and learning that Magentic-UI can help with studying. \n\nConclusion\n\nMagentic-UI is an open-source agent prototype that works with people to complete complex tasks that require multi-step planning and browser use. As agentic systems expand in the scope of tasks they can complete, Magentic-UI’s design enables better transparency into agent actions and enables human control to ensure safety and reliability. Moreover, by facilitating human intervention, we can improve performance while still reducing human cost in completing tasks on aggregate. Today we have released the first version of Magentic-UI. Looking ahead, we plan to continue developing it in the open with the goal of improving its capabilities and answering research questions on human-agent collaboration. We invite the research community to extend and reuse Magentic-UI for their scientific explorations and domains. \n\nOpens in a new tab\nRelated publications\nMagentic-One: A Generalist Multi-Agent System for Solving Complex Tasks\nChallenges in Human-Agent Communication\nNavigating Rifts in Human-LLM Grounding: Study and Benchmark\nMeet the authors\nHussein Mozannar\n\nSenior Researcher\n\nLearn more\nGagan Bansal\n\nSenior Researcher\n\nLearn more\nCheng Tan\n\nPrincipal Software Development Engineer\n\nLearn more\nAdam Fourney\n\nSenior Principal Researcher\n\nLearn more\nVictor Dibia\n\nPrincipal Research Software Engineer\n\nLearn more\nFriederike Niedtner\n\nPrincipal Technical Research Program Manager\n\nLearn more\nJack Gerrits\n\nPrincipal Software Development Engineer\n\nLearn more\nJacob Alber\n\nPrincipal Software Engineer\n\nLearn more\nJingya Chen\n\nUX Designer\n\nMicrosoft\n\nLearn more\nGriffin Bassman\n\nSoftware Engineer II\n\nLearn more\nErkang (Eric) Zhu\n\nPrincipal Researcher\n\nLearn more\nPeter Chang\n\nSenior Software Development Engineer\n\nLearn more\nRicky Loynd\n\nSenior Research Software Engineer\n\nLearn more\nMaya Murad\n\nSenior Technical PM, AI Frontiers\n\nLearn more\nRafah Hosn\n\nPartner, Group Program Manager\n\nLearn more\nEce Kamar\n\nVP and Lab Director of AI Frontiers\n\nLearn more\nSaleema Amershi\n\nPartner Research Manager\n\nLearn more\nContinue reading\nFebruary 25, 2025\nMagma: A foundation model for multimodal AI agents across digital and physical worlds \nJanuary 14, 2025\nAutoGen v0.4: Reimagining the foundation of agentic AI for scale, extensibility, and robustness \nJune 17, 2024\nIntroducing AutoGen Studio: A low-code interface for building multi-agent workflows \nJanuary 11, 2024\nTaskWeaver: A code-first agent framework for efficient data analytics and domain adaptation \nSee all blog posts\nResearch Areas\nArtificial intelligence\nRelated tools\nAutoGen\nMagentic-UI\nMarkItDown\nRelated projects\nAutoGen\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Predicting and explaining AI model performance: A new approach to evaluation ",
    "link": "https://www.microsoft.com/en-us/research/blog/predicting-and-explaining-ai-model-performance-a-new-approach-to-evaluation/",
    "excerpt": "ADeLe, a new evaluation method, explains what AI systems are good at—and where they’re likely to fail. By breaking tasks into ability-based requirements, it has the potential to provide a clearer way to evaluate and predict AI model performance.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nPredicting and explaining AI model performance: A new approach to evaluation\n\nPublished May 12, 2025\n\nBy Lexin Zhou , Research Assistant  Xing Xie , Partner Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nWith support from the Accelerating Foundation Models Research (AFMR) grant program, a team of researchers from Microsoft and collaborating institutions has developed an approach to evaluate AI models that predicts how they will perform on unfamiliar tasks and explain why, something current benchmarks struggle to do.\n\nIn the paper, “General Scales Unlock AI Evaluation with Explanatory and Predictive Power,” they introduce a methodology that goes beyond measuring overall accuracy. It assesses the knowledge and cognitive abilities a task requires and evaluates them against the model’s capabilities.\n\nADeLe: An ability-based approach to task evaluation\n\nThe framework uses ADeLe (annotated-demand-levels), a technique that assesses how demanding a task is for an AI model by applying measurement scales for 18 types of cognitive and knowledge-based abilities. This difficulty rating is based on a detailed rubric, originally developed for human tasks and shown to work reliably when applied by AI models.\n\nMICROSOFT RESEARCH BLOG\n\nResearch at Microsoft 2024: Meeting the challenge of a changing world\n\nIn this new AI era, technology is changing even faster than before, and the transition from research to reality, from concept to solution, now takes days or weeks rather than months or years.\n\nRead more\nOpens in a new tab\n\nBy comparing what a task requires with what a model can do, ADeLe generates an ability profile that not only predicts performance but also explains why a model is likely to succeed or fail—linking outcomes to specific strengths or limitations.\n\nThe 18 scales reflect core cognitive abilities (e.g., attention, reasoning), knowledge areas (e.g., natural or social sciences), and other task-related factors (e.g., prevalence of the task on the internet). Each task is rated from 0 to 5 based on how much it draws on a given ability. For example, a simple math question might score 1 on formal knowledge, while one requiring advanced expertise could score 5. Figure 1 illustrates how the full process works—from rating task requirements to generating ability profiles.\n\nFigure 1. Top: For each AI model, (1) run the new system on the ADeLe benchmark, and (2) extract its ability profile. Bottom: For each new task or benchmark, (A) apply 18 rubrics and (B) get demand histograms and profiles that explain what abilities the tasks require. Optionally, predict performance on the new tasks for any system based on the demand and ability profiles, or past performance data, of the systems.\n\nTo develop this system, the team analyzed 16,000 examples spanning 63 tasks drawn from 20 AI benchmarks, creating a unified measurement approach that works across a wide range of tasks. The paper details how ratings across 18 general scales explain model success or failure and predict performance on new tasks in both familiar and unfamiliar settings.\n\nEvaluation results \n\nUsing ADeLe, the team evaluated 20 popular AI benchmarks and uncovered three key findings: 1) Current AI benchmarks have measurement limitations; 2) AI models show distinct patterns of strengths and weaknesses across different capabilities; and 3) ADeLe provides accurate predictions of whether AI systems will succeed or fail on a new task. \n\n1. Revealing hidden flaws in AI testing methods \n\nMany popular AI tests either don’t measure what they claim or only cover a limited range of difficulty levels. For example, the Civil Service Examination benchmark is meant to test logical reasoning, but it also requires other abilities, like specialized knowledge and metacognition. Similarly, TimeQA, designed to test temporal reasoning, only includes medium-difficulty questions—missing both simple and complex challenges. \n\n2. Creating detailed AI ability profiles \n\nUsing the 0–5 rating for each ability, the team created comprehensive ability profiles of 15 LLMs. For each of the 18 abilities measured, they plotted “subject characteristic curves” to show how a model’s success rate changes with task difficulty.  \n\nThey then calculated a score for each ability—the difficulty level at which a model has a 50% chance of success—and used these results to generate radial plots showing each model’s strengths and weaknesses across the different scales and levels, illustrated in Figure 2.\n\nFigure 2. Ability profiles for the 15 LLMs evaluated.\n\nThis analysis revealed the following: \n\nWhen measured against human performance, AI systems show different strengths and weaknesses across the 18 ability scales. \nNewer LLMs generally outperform older ones, though not consistently across all abilities. \nKnowledge-related performance depends heavily on model size and training methods. \nReasoning models show clear gains over non-reasoning models in logical thinking, learning and abstraction, and social capabilities, such as inferring the mental states of their users. \nIncreasing the size of general-purpose models after a given threshold only leads to small performance gains. \n\n3. Predicting AI success and failure \n\nIn addition to evaluation, the team created a practical prediction system based on demand-level measurements that forecasts whether a model will succeed on specific tasks, even unfamiliar ones.  \n\nThe system achieved approximately 88% accuracy in predicting the performance of popular models like GPT-4o and LLaMA-3.1-405B, outperforming traditional methods. This makes it possible to anticipate potential failures before deployment, adding the important step of reliability assessment for AI models.\n\nLooking ahead\n\nADeLe can be extended to multimodal and embodied AI systems, and it has the potential to serve as a standardized framework for AI research, policymaking, and security auditing.\n\nThis technology marks a major step toward a science of AI evaluation, one that offers both clear explanations of system behavior and reliable predictions about performance. It aligns with the vision laid out in a previous Microsoft position paper on the promise of applying psychometrics to AI evaluation and a recent Societal AI white paper emphasizing the importance of AI evaluation.\n\nAs general-purpose AI advances faster than traditional evaluation methods, this work lays a timely foundation for making AI assessments more rigorous, transparent, and ready for real-world deployment. The research team is working toward building a collaborative community to strengthen and expand this emerging field.\n\nOpens in a new tab\nRelated publications\nEvaluating General-Purpose AI with Psychometrics\nGeneral Scales Unlock AI Evaluation with Explanatory and Predictive Power\nMeet the authors\nLexin Zhou\n\nResearch Assistant\n\nLearn more\nXing Xie\n\nPartner Research Manager\n\nLearn more\nContinue reading\nNovember 25, 2024\nAccelerating drug discovery with TamGen: A generative AI approach to target-aware molecule generation \nSeptember 26, 2024\nMicrosoft Research Forum Episode 4: The future of multimodal models, a new “small” language model, and other AI updates \nSeptember 17, 2024\nEureka: Evaluating and understanding progress in AI \nSeptember 6, 2023\nFrontiers of multimodal learning: A responsible AI approach \nSee all blog posts\nResearch Areas\nArtificial intelligence\nResearch Groups\nSocial Computing (Asia)\nAccelerating Foundation Models Research\nRelated projects\nSocietal AI\nRelated labs\nMicrosoft Research Lab - Asia\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Research Focus: Week of May 7, 2025 ",
    "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-may-7-2025/",
    "excerpt": "In this issue: New research on compound AI systems and causal verification of the Confidential Consortium Framework; release of Phi-4-reasoning; enriching tabular data with semantic structure, and more.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nResearch Focus: Week of May 7, 2025\n\nPublished May 7, 2025\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn this issue:\n\nNew research on compound AI systems and causal verification of the Confidential Consortium Framework; release of Phi-4-reasoning; enriching tabular data with semantic structure, and more.\n\nNEW RESEARCH\nTowards Resource-Efficient Compound AI Systems\n\nThis research introduces Murakkab, a prototype system built on a declarative workflow that reimagines how compound AI systems are built and managed to significantly improve resource efficiency. Compound AI systems integrate multiple interacting components like language models, retrieval engines, and external tools. They are essential for addressing complex AI tasks. However, current implementations could benefit from greater efficiencies in resource utilization, with improvements to tight coupling between application logic and execution details, better connections between orchestration and resource management layers, and bridging gaps between efficiency and quality.\n\nMurakkab addresses critical inefficiencies in current AI architectures and offers a new approach that unifies workflow orchestration and cluster resource management for better performance and sustainability. In preliminary evaluations, it demonstrates speedups up to ∼ 3.4× in workflow completion times while delivering ∼ 4.5× higher energy efficiency, showing promise in optimizing resources and advancing AI system design.\n\nNEW RESEARCH\nSmart Casual Verification of the Confidential Consortium Framework\n\nThis work presents a new, pragmatic verification technique that improves the trustworthiness of distributed systems like the Confidential Consortium Framework (CCF) and proves its effectiveness by catching critical bugs before deployment. Smart casual verification is a novel hybrid verification approach to validating CCF, an open-source platform for developing trustworthy and reliable cloud applications which underpins Microsoft’s Azure Confidential Ledger service. \n\nThe researchers apply smart casual verification to validate the correctness of CCF’s novel distributed protocols, focusing on its unique distributed consensus protocol and its custom client consistency model. This hybrid approach combines the rigor of formal specification and model checking with the pragmatism of automated testing, specifically binding the formal specification in TLA+ to the C++ implementation. While traditional formal methods are often one-off efforts by domain experts, the researchers have integrated smart casual verification into CCF’s continuous integration pipeline, allowing contributors to continuously validate CCF as it evolves. \n\nNEW RESEARCH\nPhi-4-reasoning Technical Report\n\nThis report introduces Phi-4-reasoning\n(opens in new tab)\n, a 14-billion parameter model optimized for complex reasoning tasks. It is trained via supervised fine-tuning of Phi-4 using a carefully curated dataset of high-quality prompts and reasoning demonstrations generated by o3-mini. These prompts span diverse domains—including math, science, coding, and spatial reasoning—and are selected to challenge the base model near its capability boundaries.\n\nBuilding on recent findings that reinforcement learning (RL) can further improve smaller models, the team developed Phi-4-reasoning-plus, which incorporates an additional outcome-based RL phase using verifiable math problems. This enhances the model’s ability to generate longer, more effective reasoning chains. \n\nDespite its smaller size, the Phi-4-reasoning family outperforms significantly larger open-weight models such as DeepSeekR1-Distill-Llama-70B and approaches the performance of full-scale frontier models like DeepSeek R1. It excels in tasks requiring multi-step problem solving, logical inference, and goal-directed planning.\n\nThe work highlights the combined value of supervised fine-tuning and reinforcement learning for building efficient, high-performing reasoning models. It also offers insights into training data design, methodology, and evaluation strategies. Phi-4-reasoning contributes to the growing class of reasoning-specialized language models and points toward more accessible, scalable AI for science, education, and technical domains.\n\nNEW RESEARCH\nTeCoFeS: Text Column Featurization using Semantic Analysis\n\nThis research introduces a practical, cost-effective solution for enriching tabular data with semantic structure, making it more useful for downstream analysis and insights—which is especially valuable in business intelligence, data cleaning, and automated analytics workflows. This approach outperforms baseline models and naive LLM applications on converted text classification benchmarks.\n\nExtracting structured insights from free-text columns in tables—such as product reviews or user feedback—can be time-consuming and error-prone, especially when relying on traditional syntactic methods that often miss semantic meaning. This research introduces the semantic text column featurization problem, which aims to assign meaningful, context-aware labels to each entry in a text column.\n\nThe authors propose a scalable, efficient method that combines the power of LLMs with text embeddings. Instead of labeling an entire column manually or applying LLMs to every cell—an expensive process—this new method intelligently samples a diverse subset of entries, uses an LLM to generate semantic labels for just that subset, and then propagates those labels to the rest of the column using embedding similarity.\n\nNEW RESEARCH\nAgentic Reasoning and Tool Integration for LLMs via Reinforcement Learning\n\nThis work introduces ARTIST (Agentic Reasoning and Tool Integration in Self-improving Transformers), a new paradigm for LLM reasoning that expands beyond traditional language-only inference. \n\nWhile LLMs have made considerable strides in complex reasoning tasks, they remain limited by their reliance on static internal knowledge and text-only reasoning. Real-world problem solving often demands dynamic, multi-step reasoning, adaptive decision making, and the ability to interact with external tools and environments. In this research, ARTIST brings together agentic reasoning, reinforcement learning (RL), and tool integration, designed to enable LLMs to autonomously decide when and how to invoke internal tools within multi-turn reasoning chains. ARTIST leverages outcome-based reinforcement learning to learn robust strategies for tool use and environment interaction without requiring step-level supervision.\n\nExtensive experiments on mathematical reasoning and multi-turn function calling benchmarks show that ARTIST consistently outperforms state-of-the-art baselines, with up to 22% absolute improvement over base models and strong gains on the most challenging tasks. Detailed studies show that agentic RL training leads to deeper reasoning, more effective tool use, and higher-quality solutions.\n\nPODCAST\nMaterialism Podcast: MatterGen\n(opens in new tab)\n\nWhat if you could find materials with tailored properties without ever entering the lab? The Materialism Podcast, which is dedicated to exploring materials science and engineering, talks with Tian Xie from Microsoft Research to discuss MatterGen, an AI tool which accelerates materials science discovery. Tune in to hear a discussion of the new Azure AI Foundry, where MatterGen will interact with and support MatterSim, an advanced deep learning model designed to simulate the properties of materials across a wide range of elements, temperatures, and pressures.\n\nIN THE NEWS: Highlights of recent media coverage of Microsoft Research\nWhen ChatGPT Broke an Entire Field: An Oral History \n\nQuanta Magazine | April 30, 2025\n\nLarge language models are everywhere, igniting discovery, disruption and debate in whatever scientific community they touch. But the one they touched first — for better, worse and everything in between — was natural language processing. What did that impact feel like to the people experiencing it firsthand?\n\nTo tell that story, Quanta interviewed 19 NLP experts, including Kalika Bali, senior principal researcher at Microsoft Research. From researchers to students, tenured academics to startup founders, they describe a series of moments — dawning realizations, elated encounters and at least one “existential crisis” — that changed their world. And ours.\n\nView more news and awards\nOpens in a new tab\nRelated publications\nSmart Casual Verification of the Confidential Consortium Framework\nTowards Resource-Efficient Compound AI Systems\nAgentic Reasoning and Tool Integration for LLMs via Reinforcement Learning\nTeCoFeS: Text Column Featurization using Semantic Analysis\nPhi-4-reasoning Technical Report\nContinue reading\nApril 23, 2025\nResearch Focus: Week of April 21, 2025 \nApril 9, 2025\nResearch Focus: Week of April 7, 2025 \nJanuary 17, 2025\nResearch Focus: Week of January 13, 2025 \nMay 15, 2024\nResearch Focus: Week of May 13, 2024 \nSee all blog posts\nResearch Areas\nArtificial intelligence\nData platforms and analytics\nProgramming languages and software engineering\nSecurity, privacy, and cryptography\nSystems and networking\nTechnology for emerging markets\nResearch Groups\nAzure Research – Systems\nMSR Redmond Security Research Group\nAzure Research - Security and Privacy\nPROSE\nRelated tools\nConfidential Consortium Framework (CCF)\nRelated projects\nEfficient AI\nConfidential Consortium Framework\nRelated labs\nMicrosoft Research Lab - Cambridge\nMicrosoft Research Lab - India\nMicrosoft Research Lab - Redmond\nAI Frontiers\nMicrosoft Research Lab - Africa, Nairobi\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Microsoft Fusion Summit explores how AI can accelerate fusion research ",
    "link": "https://www.microsoft.com/en-us/research/blog/microsoft-fusion-summit-explores-how-ai-can-accelerate-fusion-research/",
    "excerpt": "The first Microsoft Research Fusion Summit brought together global experts to explore how AI can help unlock the potential of fusion energy. Discover how collaborations with leading institutions can help speed progress toward clean, scalable energy.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nMicrosoft Fusion Summit explores how AI can accelerate fusion research\n\nPublished May 7, 2025\n\nBy Kenji Takeda , Director, Research Incubations  Shruti Rajurkar , Senior Research Technical Program Manager Research Incubations  Ade Famoti , Senior Director, Research Incubations\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nThe pursuit of nuclear fusion as a limitless, clean energy source has long been one of humanity’s most ambitious scientific goals. Research labs and companies worldwide are working to replicate the fusion process that occurs at the sun’s core, where isotopes of hydrogen combine to form helium, releasing vast amounts of energy. While scalable fusion energy is still years away, researchers are now exploring how AI can help accelerate fusion research and bring this energy to the grid sooner. \n\nIn March 2025, Microsoft Research held its inaugural Fusion Summit, a landmark event that brought together distinguished speakers and panelists from within and outside Microsoft Research to explore this question. \n\nAshley Llorens, Corporate Vice President and Managing Director of Microsoft Research Accelerator, opened the Summit by outlining his vision for a self-reinforcing system that uses AI to drive sustainability. Steven Cowley, laboratory director of the U.S. Department of Energy’s Princeton Plasma Physics Laboratory\n(opens in new tab)\n, professor at Princeton University, and former head of the UK Atomic Energy Authority, followed with a keynote explaining the intricate science and engineering behind fusion reactors. His message was clear: advancing fusion will require international collaboration and the combined power of AI and high-performance computing to model potential fusion reactor designs. \n\nApplying AI to fusion research\n\nNorth America’s largest fusion facility, DIII-D\n(opens in new tab)\n, operated by General Atomics and owned by the US Department of Energy (DOE), provides a unique platform for developing and testing AI applications for fusion research, thanks to its pioneering data and digital twin platform. \n\nRichard Buttery\n(opens in new tab)\n from DIII-D and Dave Humphreys\n(opens in new tab)\n from General Atomics demonstrated how the US DIII-D National Fusion Program\n(opens in new tab)\n is already applying AI to advance reactor design and operations, highlighting promising directions for future development. They provided examples of how to apply AI to active plasma control to avoid disruptive instabilities, using AI-controlled trajectories to avoid tearing modes, and implementing feedback control using machine learning-derived density limits for safer high-density operations. \n\nOne persistent challenge in reactor design involves building the interior “first wall,” which must withstand extreme heat and particle bombardment. Zulfi Alam, corporate vice president of Microsoft Quantum\n(opens in new tab)\n, discussed the potential of using quantum computing in fusion, particularly for addressing material challenges like hydrogen diffusion in reactors.\n\nHe noted that silicon nitride shows promise as a barrier to hydrogen and vapor and explained the challenge of binding it to the reaction chamber. He emphasized the potential of quantum computing to improve material prediction and synthesis, enabling more efficient processes. He shared that his team is also investigating advanced silicon nitride materials to protect this critical component from neutron and alpha particle damage—an innovation that could make fusion commercially viable.\n\nSPOTLIGHT: BLOG POST\n\nGraphRAG auto-tuning provides rapid adaptation to new domains\n\nGraphRAG uses LLM-generated knowledge graphs to substantially improve complex Q&A over retrieval-augmented generation (RAG). Discover automatic tuning of GraphRAG for new datasets, making it more accurate and relevant.\n\nRead more\nOpens in a new tab\nExploring AI’s broader impact on fusion engineering\n\nLightning talks from Microsoft Research labs addressed the central question of AI’s potential to accelerate fusion research and engineering. Speakers covered a wide range of applications—from using gaming AI for plasma control and robotics for remote maintenance to physics-informed AI for simulating materials and plasma behavior. Closing the session, Archie Manoharan, Microsoft’s director of nuclear engineering for Cloud Operations and Infrastructure, emphasized the need for a comprehensive energy strategy, one that incorporates renewables, efficiency improvements, storage solutions, and carbon-free sources like fusion.\n\nThe Summit culminated in a thought-provoking panel discussion moderated by Ade Famoti, featuring Archie Manoharan, Richard Buttery, Steven Cowley, and Chris Bishop, Microsoft Technical Fellow and director of Microsoft Research AI for Science. Their wide-ranging conversation explored the key challenges and opportunities shaping the field of fusion. \n\nThe panel highlighted several themes: the role of new regulatory frameworks that balance innovation with safety and public trust; the importance of materials discovery in developing durable fusion reactor walls; and the game-changing role AI could play in plasma optimization and surrogate modelling of fusion’s underlying physics.\n\nThey also examined the importance of global research collaboration, citing projects like the International Thermonuclear Experimental Reactor\n(opens in new tab)\n (ITER), the world’s largest experimental fusion device under construction in southern France, as testbeds for shared progress. One persistent challenge, however, is data scarcity. This prompted a discussion of using physics-informed neural networks as a potential approach to supplement limited experimental data. \n\nGlobal collaboration and next steps\n\nMicrosoft is collaborating with ITER\n(opens in new tab)\n to help advance the technologies and infrastructure needed to achieve fusion ignition—the critical point where a self-sustaining fusion reaction begins, using Microsoft 365 Copilot, Azure OpenAI Service, Visual Studio, and GitHub\n(opens in new tab)\n. Microsoft Research is now cooperating with ITER to identify where AI can be leveraged to model future experiments to optimize its design and operations. \n\nNow Microsoft Research has signed a Memorandum of Understanding with the Princeton Plasma Physics Laboratory (PPPL)\n(opens in new tab)\n to foster collaboration through knowledge exchange, workshops, and joint research projects. This effort aims to address key challenges in fusion, materials, plasma control, digital twins, and experiment optimization. Together, Microsoft Research and PPPL will work to drive innovation and advances in these critical areas.\n\nFusion is a scientific challenge unlike any other and could be key to sustainable energy in the future. We’re excited about the role AI can play in helping make that vision a reality. To learn more, visit the Fusion Summit event page, or connect with us by email at FusionResearch@microsoft.com.\n\nOpens in a new tab\nRelated publications\nMatterSim: A Deep Learning Atomistic Model Across Elements, Temperatures and Pressures\nA generative model for inorganic materials design\nWorld and Human Action Models towards gameplay ideation\nMeet the authors\nKenji Takeda\n\nDirector, Research Incubations\n\nLearn more\nShruti Rajurkar\n\nSenior Research Technical Program Manager Research Incubations\n\nLearn more\nAde Famoti\n\nSenior Director, Research Incubations\n\nLearn more\nContinue reading\nJune 5, 2024\nMicrosoft Research Forum Episode 3: Globally inclusive and equitable AI, new use cases for AI, and more \nJanuary 31, 2024\nMicrosoft Research Forum: New series explores bold ideas in technology research in the era of AI \nDecember 22, 2023\nResearch at Microsoft 2023: A year of groundbreaking AI advances and discoveries \nOctober 3, 2023\nAccelerate Foundation Models Research: Supporting a global academic research ecosystem for AI \nSee all blog posts\nResearch Areas\nArtificial intelligence\nResearch Groups\nGame Intelligence\nMSR Asia Theory Center\nEmbodied AI\nRelated projects\nFast Neural PDE Solver\nRelated events\n1st Annual Fusion Summit\nRelated labs\nMicrosoft Research Lab - Asia\nMicrosoft Research Lab - Redmond\nMicrosoft Research AI for Science\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Societal AI: Building human-centered AI systems ",
    "link": "https://www.microsoft.com/en-us/research/blog/societal-ai-building-human-centered-ai-systems/",
    "excerpt": "Learn about a new white paper on Societal AI, an interdisciplinary framework for guiding AI development that reflects shared human values. It presents key research challenges and emphasizes collaboration across disciplines.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nSocietal AI: Building human-centered AI systems\n\nPublished May 5, 2025\n\nBy Beibei Shi , Principal Research PM  Haotian Li , Researcher  Xing Xie , Partner Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn October 2022, Microsoft Research Asia hosted a workshop that brought together experts in computer science, psychology, sociology, and law as part of Microsoft’s commitment to responsible AI\n(opens in new tab)\n. The event led to ongoing collaborations exploring AI’s societal implications, including the Value Compass\n(opens in new tab)\n project.\n\nAs these efforts grew, researchers focused on how AI systems could be designed to meet the needs of people and institutions in areas like healthcare, education, and public services. This work culminated in Societal AI: Research Challenges and Opportunities, a white paper that explores how AI can better align with societal needs. \n\nWhat is Societal AI?\n\nSocietal AI is an emerging interdisciplinary area of study that examines how AI intersects with social systems and public life. It focuses on two main areas: (1) the impact of AI technologies on fields like education, labor, and governance; and (2) the challenges posed by these systems, such as evaluation, accountability, and alignment with human values. The goal is to guide AI development in ways that respond to real-world needs.\n\nSPOTLIGHT: MICROSOFT RESEARCH NEWSLETTER\n\nMicrosoft Research Newsletter\n\nStay connected to the research community at Microsoft.\n\nSubscribe today\nOpens in a new tab\n\nThe white paper offers a framework for understanding these dynamics and provides recommendations for integrating AI responsibly into society. This post highlights the paper’s key insights and what they mean for future research.\n\nTracing the development of Societal AI\n\nSocietal AI began nearly a decade ago at Microsoft Research Asia, where early work on personalized recommendation systems uncovered risks like echo chambers, where users are repeatedly exposed to similar viewpoints, and polarization, which can deepen divisions between groups. Those findings led to deeper investigations into privacy, fairness, and transparency, helping inform Microsoft’s broader approach to responsible AI.\n\nThe rapid rise of large-scale AI models in recent years has made these concerns more urgent. Today, researchers across disciplines are working to define shared priorities and guide AI development in ways that reflect social needs and values.\n\nKey insights\n\nThe white paper outlines several important considerations for the field:\n\nInterdisciplinary framework: Bridges technical AI research with the social sciences, humanities, policy studies, and ethics to address AI’s far-reaching societal effects.\n\nActionable research agenda: Identifies ten research questions that offer a roadmap for researchers, policymakers, and industry leaders.\n\nGlobal perspective: Highlights the importance of different cultural perspectives and international cooperation in shaping responsible AI development dialogue.\n\nPractical insights: Balances theory with real-world applications, drawing from collaborative research projects.\n\n“AI’s impact extends beyond algorithms and computation—it challenges us to rethink fundamental concepts like trust, creativity, agency, and value systems,” says Lidong Zhou, managing director of Microsoft Research Asia. “It recognizes that developing more powerful AI models is not enough; we must examine how AI interacts with human values, institutions, and diverse cultural contexts.”\n\nFigure 1. Societal AI research agenda\nGuiding principles for responsible integration\n\n The research agenda is grounded in three key principles: \n\nHarmony: AI should minimize conflict and build trust to support acceptance. \nSynergy: AI should complement human capabilities, enabling outcomes that neither humans nor machines could achieve alone.  \nResilience: AI should be robust and adaptable as social and technological conditions evolve.  \nTen critical questions\n\nThese questions span both technical and societal concerns:  \n\nHow can AI be aligned with diverse human values and ethical principles?\nHow can AI systems be designed to ensure fairness and inclusivity across different cultures, regions, and demographic groups?\nHow can we ensure AI systems are safe, reliable, and controllable, especially as they become more autonomous?\nHow can human-AI collaboration be optimized to enhance human abilities?\nHow can we effectively evaluate AI’s capabilities and performance in new, unforeseen tasks and environments?\nHow can we enhance AI interpretability to ensure transparency in its decision-making processes?\nHow will AI reshape human cognition, learning, and creativity, and what new capabilities might it unlock?\nHow will AI redefine the nature of work, collaboration, and the future of global business models?\nHow will AI transform research methodologies in the social sciences, and what new insights might it enable?\nHow should regulatory frameworks evolve to govern AI development responsibly and foster global cooperation?\n\nThis list will evolve alongside AI’s developing societal impact, ensuring the agenda remains relevant over time. Building on these questions, the white paper underscores the importance of sustained, cross-disciplinary collaboration to guide AI development in ways that reflect societal priorities and public interest.\n\n“This thoughtful and comprehensive white paper from Microsoft Research Asia represents an important early step forward in anticipating and addressing the societal implications of AI, particularly large language models (LLMs), as they enter the world in greater numbers and for a widening range of purposes,” says research collaborator James A. Evans\n(opens in new tab)\n, professor of sociology at the University of Chicago.\n\nLooking ahead\n\nMicrosoft is committed to fostering collaboration and invites others to take part in developing governance systems. As new challenges arise, the responsible use of AI for the public good will remain central to our research.\n\nWe hope the white paper serves as both a guide and a call to action, emphasizing the need for engagement across research, policy, industry, and the public.\n\nFor more information, and to access the full white paper, visit the Microsoft Research Societal AI page. Listen to the author discuss more about the research in this podcast.\n\nAcknowledgments\n\nWe are grateful for the contributions of the researchers, collaborators, and reviewers who helped shape this white paper.\n\nOpens in a new tab\nRelated publications\nSocietal AI: Research Challenges and Opportunities\nMeet the authors\nBeibei Shi\n\nPrincipal Research PM\n\nLearn more\nHaotian Li\n\nResearcher\n\nLearn more\nXing Xie\n\nPartner Research Manager\n\nLearn more\nContinue reading\nMay 5, 2025\nAbstracts: Societal AI with Xing Xie \nNovember 18, 2024\nIntroducing Yasuyuki Matsushita: Tackling societal challenges with AI at Microsoft Research Asia – Tokyo  \nJuly 15, 2024\nRUBICON: Evaluating conversations between humans and AI systems \nDecember 22, 2023\nResearch at Microsoft 2023: A year of groundbreaking AI advances and discoveries \nSee all blog posts\nResearch Areas\nArtificial intelligence\nRelated projects\nSocietal AI\nRelated labs\nMicrosoft Research Lab - Asia\n微软亚洲研究院\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Research Focus: Week of April 21, 2025 ",
    "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-21-2025/",
    "excerpt": "In this issue: our CHI 2025 & ICLR 2025 contributions, plus research on causal reasoning & LLMs; countering LLM jailbreak attacks; and how people use AI vs. AI-alone. Also, SVP of Microsoft Health Jim Weinstein talks rural healthcare innovation.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nResearch Focus: Week of April 21, 2025\n\nPublished April 23, 2025\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn this issue:\n\nCatch a preview of our presentations and papers at CHI 2025 and ICLR 2025. We also introduce new research on causal reasoning and LLMs; enhancing LLM jailbreak capabilities to bolster safety and robustness; understanding how people using AI compared to AI-alone, and Distill-MOS, a compact and efficient model that delivers state-of-the-art speech quality assessment. You’ll also find a replay of a podcast discussion on rural healthcare innovation with Senior Vice President of Microsoft Health Jim Weinstein.\n\nCONFERENCE\nMicrosoft at CHI 2025\n\nMicrosoft Research is proud to be a sponsor of the ACM Computer Human Interaction (CHI) 2025 Conference on Human Factors in Computing Systems\n(opens in new tab)\n. CHI brings together researchers and practitioners from all over the world and from diverse cultures, backgrounds, and positionalities, who share an overarching goal to make the world a better place with interactive digital technologies.\n\nOur researchers will host more than 30 sessions and workshops at this year’s conference in Yokohama, Japan. We invite you to preview our presentations and our two dozen accepted papers.\n\nMicrosoft @CHI 2025\nCONFERENCE\nMicrosoft at ICLR 2025\n\nMicrosoft is proud to be a sponsor of the thirteenth International Conference on Learning Representations (ICLR). This gathering is dedicated to the advancement of representation learning, which is a branch of AI. We are pleased to share that Microsoft has more than 30 accepted papers at this year’s conference, which we invite you to preview.\n\nICLR is globally renowned for presenting and publishing cutting-edge research on all aspects of deep learning used in the fields of artificial intelligence, statistics and data science, as well as important application areas such as machine vision, computational biology, speech recognition, text understanding, gaming, and robotics.\n\nMicrosoft @ICLR 2025\nNEW RESEARCH\nCausal Reasoning and Large Language Models: Opening a New Frontier for Causality\n\nWhat kinds of causal arguments can large language models (LLMs) generate, how valid are these arguments, and what causal reasoning workflows can this generation support or automate? This paper, which was selected for ICLR 2025, clarifies this debate. It advances our understanding of LLMs and their causal implications, and proposes a framework for future research at the intersection of LLMs and causality.\n\nThis discussion has critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. In capturing common sense and domain knowledge about causal mechanisms and supporting translation between natural language and formal methods, LLMs open new frontiers for advancing the research, practice, and adoption of causality.\n\nRead the paper\nNEW RESEARCH\nThe Future of AI in Knowledge Work: Tools for Thought at CHI 2025\n\nCan AI tools do more than streamline workflows—can they actually help us think better? That’s the driving question behind the Microsoft Research Tools for Thought initiative. At this year’s CHI conference, this group is presenting four new research papers and cohosting a workshop that dives deep into this intersection of AI and human cognition.\n\nThe team provides an overview of their latest research, starting with a study on how AI is changing the way people think and work. They introduce three prototype systems designed to support different cognitive tasks. Finally, through their Tools for Thought workshop, they invite the CHI community to help define AI’s role in supporting human thinking.\n\nRead the blog\nNEW RESEARCH\nBuilding LLMs with enhanced jailbreaking capabilities to bolster safety and robustness\n\nRecent research shows that LLMs are vulnerable to automated jailbreak attacks, where algorithm-generated adversarial suffixes bypass safety alignment and trigger harmful responses. This paper introduces ADV-LLM, an iterative self-tuning process for crafting adversarial LLMs with enhanced jailbreak capabilities—which could provide valuable insights for future safety alignment research.\n\nADV-LLM is less computationally expensive than prior mechanisms and achieves higher attack success rates (ASR), especially against well-aligned models like Llama2 and Llama3.\n\nIt reaches nearly 100% ASR on various open-source LLMs and demonstrates strong transferability to closed-source models—achieving 99% ASR on GPT-3.5 and 49% ASR on GPT-4—despite being optimized solely on Llama3. Beyond improving jailbreak performance, ADV-LLM offers valuable insights for future alignment research by enabling large-scale generation of safety-relevant datasets.\n\nRead the paper\nNEW RESEARCH\nChatBench: From Static Benchmarks to Human-AI Evaluation\n\nThe rapid adoption of LLM-based chatbots raises the need to understand what people and LLMs can achieve together. However, standard benchmarks like MMLU\n(opens in new tab)\n assess LLM capabilities in isolation (i.e., “AI alone”). This paper presents the results of a user study that transforms MMLU questions into interactive user-AI conversations. The researchers seeded the participants with the question and then had them engage in a conversation with the LLM to arrive at an answer. The result is ChatBench, a new dataset comprising AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144,000 answers and 7,336 user-AI conversations.\n\nThe researchers’ analysis reveals that AI-alone accuracy does not predict user-AI accuracy, with notable differences across subjects such as math, physics, and moral reasoning. Examining user-AI conversations yields insights into how these interactions differ from AI-alone benchmarks. Finally, the researchers demonstrate that finetuning a user simulator on a subset of ChatBench improves its ability to predict user-AI accuracy, boosting correlation on held-out questions by more than 20 points, thereby enabling scalable interactive evaluation.\n\nRead the paper\nNEW RESEARCH\nDistill-MOS: A compact speech-quality assessment model \n\nDistill-MOS is a compact and efficient speech quality assessment model with dramatically reduced size—over 100x smaller than the reference model—enabling efficient, non-intrusive evaluation in real-world, low-resource settings. \n\nThis paper investigates the distillation and pruning methods to reduce model size for non-intrusive speech quality assessment based on self-supervised representations. The researchers’ experiments build on XLS-R-SQA, a speech quality assessment model using wav2vec 2.0 XLS-R embeddings. They retrain this model on a large compilation of mean opinion score datasets, encompassing over 100,000 labeled clips. \n\nRead the paper\nView GitHub\nPODCAST\nCollaborating to Affect Change for Rural Health Care with Innovation and Technology\n\nSenior Vice President of Microsoft Health Jim Weinstein joins Dan Liljenquist, Chief Strategy Officer from Intermountain Health, on the NEJM Catalyst podcast for a discussion of their combined expertise and resources and their collaboration to address healthcare challenges in the rural United States. These challenges include limited access to care, rising mortality rates, and severe staffing shortages. Working together, they aim to create a scalable model that can benefit both rural and urban health care systems. Key goals include expanding access through telemedicine and increasing cybersecurity, ultimately improving the quality of care delivered and financial stability for rural communities.\n\nListen to the podcast\nPODCAST\nEmpowering patients and healthcare consumers in the age of generative AI\n\nTwo champions of patient-centered digital health join Microsoft Research President Peter Lee to talk about how AI is reshaping healthcare in terms of patient empowerment and emerging digital health business models. Dave deBronkart, a cancer survivor and longtime advocate for patient empowerment, discusses how AI tools like ChatGPT can help patients better understand their conditions, navigate the healthcare system, and communicate more effectively with clinicians. Christina Farr, a healthcare investor and former journalist, talks about the evolving digital health–startup ecosystem, highlighting where AI is having the most meaningful impact—particularly in women’s health, pediatrics, and elder care. She also explores consumer trends, like the rise of cash-pay healthcare. \n\nListen to the podcast\nPODCAST\nBeyond the Image: AI’s Expanding Role in Healthcare\n\nJonathan Carlson, Managing Director of Microsoft Research Health Futures, joins the Healthcare Unfiltered show to explore the evolution of AI in medicine, from the early days to cutting-edge innovations like ambient clinical intelligence. This podcast explores how pre-trained models and machine learning are transforming care delivery, as well as the future of biomedicine and healthcare, including important ethical and practical questions.\n\nListen to the podcast\nOpens in a new tab\nRelated publications\nCausal Reasoning and Large Language Models: Opening a New Frontier for Causality\nIterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities\nDistillation and Pruning for Scalable Self-Supervised Representation-Based Speech Quality Assessment\nChatBench: From Static Benchmarks to Human-AI Evaluation\nContinue reading\nMay 7, 2025\nResearch Focus: Week of May 7, 2025 \nJanuary 31, 2025\nResearch Focus: Week of January 27, 2025 \nApril 17, 2024\nResearch Focus: Week of April 15, 2024 \nApril 3, 2024\nResearch Focus: Week of April 1, 2024 \nSee all blog posts\nResearch Areas\nArtificial intelligence\nAudio and Acoustics\nHuman-computer interaction\nSecurity, privacy, and cryptography\nResearch Groups\nComputational Social Science\nAudio and Acoustics Research Group\nDeep Learning Group\nMachine Learning and AI | India\nCausality and Machine Learning\nMicrosoft Research Special Projects\nRelated projects\nTools for Thought\nDoWhy: Causal Reasoning for Designing and Evaluating Interventions\nRelated events\nMicrosoft at CHI 2025\nMicrosoft at ICLR 2025\nRelated labs\nMicrosoft Research Lab - India\nMicrosoft Research Lab - Redmond\nMicrosoft Research Lab - New York City\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "The Future of AI in Knowledge Work: Tools for Thought at CHI 2025 ",
    "link": "https://www.microsoft.com/en-us/research/blog/the-future-of-ai-in-knowledge-work-tools-for-thought-at-chi-2025/",
    "excerpt": "Join us at CHI 2025 to explore how AI systems can be used as Tools for Thought as we reimage AI’s role in human thinking. Learn about new research, prototypes, and a workshop on designing AI that supports critical thinking, decision-making, and creativity.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nThe Future of AI in Knowledge Work: Tools for Thought at CHI 2025\n\nPublished April 18, 2025\n\nBy Sean Rintel , Senior Principal Research Manager  Leon Reicherts , Researcher  Lev Tankelevitch , Senior Researcher  Advait Sarkar , Senior Researcher  Pratik Ghosh , Senior Research Designer  Richard Banks , Principal Design Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nCan AI tools do more than streamline workflows—can they actually help us think better? That’s the driving question behind the Microsoft Research Tools for Thought initiative. At this year’s CHI conference, we’re presenting four new research papers and cohosting a workshop that dives deep into this intersection of AI and human cognition.\n\nThis post provides an overview of our latest research, starting with a study on how AI is changing the way we think and work. We also introduce three prototype systems designed to support different cognitive tasks. Finally, through our Tools for Thought workshop, we’re inviting the CHI community to help define AI’s role in supporting human thinking.\n\nAI’s effects on thinking at work\n\nWith a single prompt, AI can generate a wide range of outputs, from documents and meeting agendas to answers and automated workflows. But how are people’s thinking processes affected when they delegate these tasks to AI?\n\nOne of our goals is to understand how knowledge workers use AI, how they perceive its value, and how it affects cognitive effort.\n\nOur study, “The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers,” surveyed 319 professionals using AI across a variety of occupations. Participants shared 936 real-world AI use cases and reflected on how it influenced their critical thinking and mental effort. We summarize these findings below.\n\nDefining and deploying critical thinking. Knowledge workers describe critical thinking as involving activities like setting clear goals, refining prompts, and verifying AI outputs against external sources and their own expertise. They rely on these practices to maintain work quality when using AI—motivated by the need to avoid errors, produce better results, and develop their skills.\n\nFindings\n\nBalancing cognitive effort. Participants’ reports about critical thinking and the effort involved align with longstanding human tendencies to manage cognitive load at work. For high-stakes tasks requiring accuracy, they say they expend more effort in applying critical thinking with AI than they would performing the same tasks without it. In contrast, during routine, for low-stakes tasks under time pressure, they report spending less effort on critical thinking when using AI compared to completing tasks without it. \n\nConfidence effects. The study found that higher confidence in AI was associated with less critical thinking, while higher self-confidence in one’s own abilities was associated with more critical thinking—though at a perceived higher cognitive cost. This suggests a delicate balance between using AI for efficiency and maintaining active critical engagement. \n\nShift in the nature of critical thinking. Participants reported a shift in critical thinking activities, with a greater focus on information verification, response integration, and task stewardship. While AI automates certain aspects of knowledge work, it also demands more effort in evaluating the accuracy and relevance of AI-generated content. \n\nBarriers to critical engagement. The study identified several barriers that inhibit critical thinking when using AI. These include a lack of awareness of the need for critical evaluation, limited motivation due to time pressure or perceived job scope, and difficulty in refining prompts—especially in unfamiliar domains.\n\nRecommendations\n\nTo foster critical thinking at work, we recommend that AI tools actively encourage awareness, motivation, and skill development.\n\nAI tools should enhance motivators for critical thinking (e.g., quality standards, skill-building) and mitigate inhibitors (e.g., time constraints, low awareness). Proactive prompts can surface overlooked tasks, while reactive features can offer on-demand assistance. Motivation can be strengthened by positioning critical reflection as part of professional growth—not just extra work.\n\nAI tools should also support knowledge workers’ ability to think critically by providing reasoning explanations (as some newer AI models now do), guided critiques, and cross-references. This shift must occur in both the design of the technology and in the mindsets of knowledge workers. Rather than treating AI as a tool for delivering answers, we suggest treating it as a thought partner—one that can also act as a provocateur.\n\nBeyond these insights, our other CHI papers explore practical ways to design AI that augments human cognition.\n\nEnhancing decision-making with AI\n\nDecision-making is central to knowledge work, and AI is increasingly being used to help people make decisions in complex fields like healthcare and finance. However, how much agency do knowledge workers retain when AI is involved?\n\nOur study, “AI, Help Me Think—but for Myself: Exploring How LLMs Can Assist People in Complex Decision-Making by Providing Different Forms of Cognitive Support,” conducted in collaboration with University College London, examines this question. We began with a small formative study involving 10 participants, followed by a comparative study with 21 participants using two different AI-supported decision-making systems.\n\nFor a complex financial investment task, we compared two different AI tools (Figure 1): RecommendAI, which provides AI-generated recommendations, and ExtendAI, which encourages users to articulate their reasoning before receiving AI feedback.\n\nFigure 1. Illustrative comparison of the thought process involved when interacting with two types of AI: RecommendAI and ExtendAI.\nFindings\n\nBoth systems were found to offer benefits for augmenting cognition and addressing some of the challenges to critical thinking identified in the knowledge worker survey above, suggesting the potential for a balanced approach. \n\nRecommendAI offered concrete suggestions that inspired users to explore new directions in their decision-making. This often led to fresh insights and reflections. However, the recommendations at times felt disconnected from the user’s own reasoning, reducing the depth of engagement. \n\nIn contrast, ExtendAI encouraged users to reflect more deeply on their decisions by providing feedback on their reasoning. This helped them examine their thought processes and consider alternative perspectives. However, some users found the feedback too general and not actionable enough. \n\nWhen it came to how users integrated the tools into their decision-making process, RecommendAI, introduced perspectives that pushed users to think beyond their usual patterns. By recommending options not based on users’ own reasoning, it encouraged exploration of ideas they might not have considered. However, some users perceived the recommendations as a “black box” solution. This lack of transparency made those recommendations harder to understand, trust, and apply to their own thought processes. \n\nExtendAI, on the other hand, aligned with users’ existing reasoning, making its feedback easier to incorporate. This helped the users maintain a sense of control and continuity. However, because the feedback often echoed their initial thoughts, it sometimes limited new insights and risked reinforcing existing biases.\n\nThese findings suggest that AI tools like ExtendAI, designed to elicit and build on users’ own cognitive processes, may offer a more effective approach to augmentation than simply providing “ready-made solutions” that users must figure out how to interpret and apply.\n\nAre we on track? Making meetings better with AI\n\nMeetings are often criticized for being ineffective. While this is sometimes due to poor practices—such as weak agendas, late starts, and unclear facilitation—we believe the deeper issue is a lack of meeting intentionality: knowing why a meeting is occurring and keeping the discussion focused on that purpose. A key challenge is maintaining goal clarity throughout a meeting.\n\nIn the paper “Are We On Track? AI-Assisted Goal Reflection During Meetings,” we explore how AI tools can improve meetings in real time by encouraging reflection—awareness about the meeting’s goals and how well the current conversation is aligned with those goals.\n\nOur study with 15 knowledge workers examined two AI-driven design paradigms: passive goal assistance through ambient visualization (a live chart displaying how conversational topics relate to meeting objectives) and active goal assistance through interactive questioning (nudging participants to consider whether the current conversation aligns with the meeting objectives). These approaches are illustrated in Figure 2.\n\nFigure 2. Technology prototypes exploring passive and active ways to keep meetings focused on established objectives.\nRecommendations\n\nThe findings highlight AI’s potential to help teams with meeting objectives. We found three key design tradeoffs between passive and active support. Based on these, we offer the following AI design recommendations.\n\nInformation balance. There is a tradeoff between ambient visualizations in the passive approach—which can risk information overload—and interactive questioning in the active approach, which may lack detail. To be effective, AI should deliver the right amount of information at the right time and tailor content to the individuals who need it most—without overwhelming users, while offering meaningful and timely support for reflection.\n\nBalance of engagement versus interruption. When participants are deeply engaged in discussion, significant interruptions can overwhelm and disrupt the flow. Conversely, during moments of confusion or misalignment, subtle cues may be insufficient to get the team back on track. AI systems should dynamically adjust their level of intervention—from ambient and lightweight to more direct—escalating or de-escalating based on timing thresholds, which can be customized for each team.\n\nBalance of team versus individual goal awareness. AI assistance can nudge team action, such as adjusting agendas. These effects were stronger with the active approach, which required group responses, while the passive approach supported individual thinking without directly influencing team behavior. Team-wide engagement depends on both the visibility of AI cues and how they are introduced into the discussion.\n\nThis study helps us understand how AI design choices can support intentionality during meetings and enhance productivity without disrupting natural workflows.\n\nAzure AI Foundry Labs\n\nGet a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.\n\nAzure AI Foundry\nOpens in a new tab\nEncouraging diverse problem-solving brainstorming with AI\n\nDiverse perspectives drive creative problem-solving in organizations, but individuals often lack access to varied viewpoints. In the paper “YES AND: An AI-Powered Problem-Solving Framework for Diversity of Thought,” we build on the idea of “design improv” to explore a multi-agent AI prototype that simulates conversations with persona-based agents representing a range of expertise.\n\nThe agents follow a classic model of conversational turn-taking, combined with a confidence model to determine when to take or respond to a turn. This allows both the agents and the user to organically build on each others’ ideas and ask clarifying questions. The system enables free-flowing, multi-party idea generation while avoiding common pitfalls of group brainstorming—such as social loafing, production blocking, and groupthink (Figure 3).\n\nFigure 3. The YES AND system supports conversational turn-taking among agents and the user to generate ideas around a problem.\n\nAt the end of a session, an AI agent called Sage distills the discussion, leaving it to the user to develop a conclusive approach to the problem. In this way, YES AND helps unblock forward momentum in problem-solving while preserving the agency of knowledge workers to shape their own ideas.\n\nNext steps: Expanding the Tools for Thought community\n\nWe believe the best way to advance next-generation tools for thought is by bringing together a wide range of perspectives and approaches. In addition to our four papers, we are also conducting a workshop at CHI on April 26, co-organized with collaborators from industry and academia: Tools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI.  \n\nIn this session, over 60 researchers, designers, practitioners, and provocateurs will gather to examine what it means to understand and shape the impact of AI on human cognition. Together, we’ll explore how AI is changing workflows, the opportunities and challenges for design, and which theories, perspectives, and methods are increasingly relevant—or still need to be developed. \n\nThe enthusiastic response to this workshop highlights the growing interest in AI’s role in human thought. Our goal is to foster a multidisciplinary community dedicated to ensuring that AI not only accelerates work but also strengthens our ability to think critically, creatively, and strategically. \n\nWe look forward to ongoing discussions, new collaborations, and the next wave of innovations in AI-assisted cognition at CHI 2025.  \n\nOpens in a new tab\nRelated publications\nAI, Help Me Think—but for Myself: Assisting People in Complex Decision-Making by Providing Different Kinds of Cognitive Support\nAre We On Track? AI-Assisted Active and Passive Goal Reflection During Meetings\nYES AND: A Generative AI Multi-Agent Framework for Enhancing Diversity of Thought in Individual Ideation for Problem-Solving Through Confidence-Based Agent Turn-Taking\nThe Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers\nTools for Thought: Research and Design for Understanding, Protecting, and Augmenting Human Cognition with Generative AI\nMeet the authors\nSean Rintel\n\nSenior Principal Research Manager\n\nLearn more\nLeon Reicherts\n\nResearcher\n\nLearn more\nLev Tankelevitch\n\nSenior Researcher\n\nLearn more\nAdvait Sarkar\n\nSenior Researcher\n\nLearn more\nPratik Ghosh\n\nSenior Research Designer\n\nLearn more\nRichard Banks\n\nPrincipal Design Manager\n\nLearn more\nContinue reading\nApril 23, 2025\nResearch Focus: Week of April 21, 2025 \nMay 23, 2024\nIdeas: Designing AI for people with Abigail Sellen \nMay 15, 2024\nMicrosoft at CHI 2024: Innovations in human-centered design \nFebruary 29, 2024\nAbstracts: February 29, 2024 \nSee all blog posts\nResearch Areas\nArtificial intelligence\nHuman-computer interaction\nRelated projects\nTools for Thought\nRelated labs\nMicrosoft Research Lab - Cambridge\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Engagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project ",
    "link": "https://www.microsoft.com/en-us/research/blog/engagement-user-expertise-and-satisfaction-key-insights-from-the-semantic-telemetry-project/",
    "excerpt": "Semantic Telemetry Project data show that people who use AI for more professional and complex tasks are more likely to keep using the tool and to use it more often. Novice AI users engage in simpler tasks, but their usage is becoming more complex.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nEngagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project\n\nPublished April 14, 2025\n\nBy Amber Hoak , Senior Software Development Engineer  Scott Counts , Senior Principal Research Manager  Kate Lytvynets , Software Development Engineer  David Tittsworth , Software Engineer  Siddharth Suri , Senior Principal Researcher  Nirupama Chandrasekaran , Principal Research Software Engineer  Ben Cutler , Senior Director  Weiwei Yang , Principal SDE Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nThe Semantic Telemetry Project aims to better understand complex, turn-based human-AI interactions in Microsoft Copilot using a new data science approach. \n\nThis understanding is crucial for recognizing how individuals utilize AI systems to address real-world tasks. It provides actionable insights, enhances key use cases, and identifies opportunities for system improvement.\n\nIn a recent blog post, we shared our approach for classifying chat log data using large language models (LLMs), which allows us to analyze these interactions at scale and in near real time. We also introduced two of our LLM-generated classifiers: Topics and Task Complexity. \n\nThis blog post will examine how our suite of LLM-generated classifiers can serve as early indicators for user engagement and highlight how usage and satisfaction varies based on AI and user expertise.\n\nThe key findings from our research are: \n\nWhen users engage in more professional, technical, and complex tasks, they are more likely to continue utilizing the tool and increase their level of interaction with it. \nNovice users currently engage in simpler tasks, but their work is gradually becoming more complex over time. \nMore expert users are satisfied with AI responses only where AI expertise is on par with their own expertise on the topic, while novice users had low satisfaction rates regardless of AI expertise. \n\nRead on for more information on these findings. Note that all analyses were conducted on anonymous Copilot in Bing interactions containing no personal information. \n\nClassifiers mentioned in article: \n\nKnowledge work classifier: Tasks that involve creating artifacts related to information work typically requiring creative and analytical thinking. Examples include strategic business planning, software design, and scientific research. \n\nTask complexity classifier: Assesses the cognitive complexity of a task if a user performs it without the use of AI. We group into two categories: low complexity and high complexity. \n\nTopics classifier: A single label for the primary topic of the conversation.\n\nUser expertise: Labels the user’s expertise on the primary topic within the conversation as one of the following categories: Novice (no familiarity with the topic), Beginner (little prior knowledge or experience), Intermediate (some basic knowledge or familiarity with the topic), Proficient (can apply relevant concepts from conversation), and Expert (deep and comprehensive understanding of the topic). \n\nAI expertise: Labels the AI agent expertise based on the same criteria as user expertise above. \n\nUser satisfaction: A 20-question satisfaction/dissatisfaction rubric that the LLM evaluates to create an aggregate score for overall user satisfaction. \n\nWhat keeps Bing Chat users engaged? \n\nWe conducted a study of a random sample of 45,000 anonymous Bing Chat users during May 2024. The data was grouped into three cohorts based on user activity over the course of the month: \n\nLight (1 active chat session per week) \nMedium (2-3 active chat sessions per week) \nHeavy (4+ active chat sessions per week) \n\nThe key finding is that heavy users are doing more professional, complex work. \n\nWe utilized our knowledge work classifier to label the chat log data as relating to knowledge work tasks. What we found is knowledge work tasks were higher in all cohorts, with the highest percentage in heavy users. \n\nFigure 1: Knowledge work based on engagement cohort\n\nAnalyzing task complexity, we observed that users with higher engagement frequently perform the highest number of tasks with high complexity, while users with lower engagement performed more tasks with low complexity. \n\nFigure 2: High complexity and low complexity tasks by engagement cohort+ \n\nLooking at the overall data, we can filter on heavy users and see higher numbers of chats where the user was performing knowledge work tasks. Based on task complexity, we see that most knowledge work tasks seek to apply a solution to an existing problem, primarily within programming and scripting. This is in line with our top overall topic, technology, which we discussed in the previous post. \n\nFigure 3: Heavy users tree diagram \n\nIn contrast, light users tended to do more low complexity tasks (“Remember”), using Bing Chat like a traditional search engine and engaging more in topics like business and finance and computers and electronics.\n\nFigure 4: Light users tree diagram \nNovice queries are becoming more complex \n\nWe looked at Bing Chat data from January through August 2024 and we classified chats using our User Expertise classifier. When we looked at how the different user expertise groups were using the tool for professional tasks, we discovered that proficient and expert users tend to do more professional tasks with high complexity in topics like programming and scripting, professional writing and editing, and physics and chemistry. \n\nFigure 5: Top topics for proficient/expert users \nFigure 6: Task complexity for proficient/expert \nFigure 7: Top topics for novices \n\nIn contrast, novice users engaged more in professional tasks relating to business and finance and education and learning, mainly using the tool to recall information.\n\nFigure 8: Task complexity for novices \n\nHowever, novices are targeting increasingly more complex tasks over time. Over the eight-month period, we see the percentage of high complexity tasks rise from about 36% to 67%, revealing that novices are learning and adapting quickly (see Figure 9). \n\nFigure 9: High complexity for novices Jan-Aug 2024 \nHow does user satisfaction vary according to expertise? \n\nWe classified both the user expertise and AI agent expertise for anonymous interactions in Copilot in Bing. We compared the level of user and AI agent expertise with our user satisfaction classifier. \n\nThe key takeaways are: \n\nExperts and proficient users are only satisfied with AI agents with similar expertise (expert/proficient). \nNovices are least satisfied, regardless of the expertise of the AI agent. \nFigure 10: Copilot in Bing satisfaction intersection of AI expertise and User expertise (August-September 2024) \nConclusion\n\nUnderstanding these metrics is vital for grasping user behavior over time and relating it to real-world business indicators. Users are finding value from complex professional knowledge work tasks, and novices are quickly adapting to the tool and finding these high value use-cases. By analyzing user satisfaction in conjunction with expertise levels, we can tailor our tools to better meet the needs of different user groups. Ultimately, these insights can help improve user understanding across a variety of tasks.  \n\nIn our next post, we will examine the engineering processes involved in LLM-generated classification.\n\nOpens in a new tab\nMeet the authors\nAmber Hoak\n\nSenior Software Development Engineer\n\nLearn more\nScott Counts\n\nSenior Principal Research Manager\n\nLearn more\nKate Lytvynets\n\nSoftware Development Engineer\n\nLearn more\nDavid Tittsworth\n\nSoftware Engineer\n\nLearn more\nSiddharth Suri\n\nSenior Principal Researcher\n\nLearn more\nNirupama Chandrasekaran\n\nPrincipal Research Software Engineer\n\nLearn more\nBen Cutler\n\nSenior Director\n\nLearn more\nWeiwei Yang\n\nPrincipal SDE Manager\n\nLearn more\nContinue reading\nMarch 10, 2025\nSemantic Telemetry: Understanding how users interact with AI systems \nJuly 15, 2024\nRUBICON: Evaluating conversations between humans and AI systems \nMarch 27, 2024\nLearning from interaction with Microsoft Copilot (web) \nSeptember 25, 2023\nAutoGen: Enabling next-generation large language model applications \nSee all blog posts\nResearch Areas\nArtificial intelligence\nHuman-computer interaction\nRelated projects\nSemantic Telemetry\nRelated labs\nMicrosoft Research Lab - Redmond\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Debug-gym: an environment for AI coding tools to learn how to debug code like programmers ",
    "link": "https://www.microsoft.com/en-us/research/blog/debug-gym-an-environment-for-ai-coding-tools-to-learn-how-to-debug-code-like-programmers/",
    "excerpt": "Developers spend a lot of time debugging code. Learn how debug-gym can equip AI agents to help, enabling them to set breakpoints, navigate the codebase, and print runtime variable values on demand, so they better understand the code and its execution flow.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nDebug-gym: an environment for AI coding tools to learn how to debug code like programmers\n\nPublished April 10, 2025\n\nBy Eric Yuan , Senior Researcher  Morgane Moss , Intern  Charbel Feghali , Student  Chinmay Singh , Principal Research Software Development Engineer  Darya Moldavskaya , Senior Technical Program Manager  Drew MacPhee , R&I Service Manager  Lucas Caccia , Senior Researcher  Matheus Pereira , Senior Software Development Engineer  Minseon Kim , Post Doc Researcher  Alessandro Sordoni , Principal Researcher  Marc-Alexandre Côté , Principal Researcher\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nThe ongoing proliferation of AI coding tools is not only boosting developers’ efficiency, it also signals a future where AI will generate a growing share of all new code. GitHub CEO Thomas Dohmke\n(opens in new tab)\n predicted as much in 2023, when he said that “sooner than later, 80% of the code is going to be written by Copilot.”  \n\nBoth large and small software companies are already heavily using AI to generate code. Y Combinator’s Garry Tan\n(opens in new tab)\n noted that 95% of code for a quarter of Y Combinator’s latest batch of startups was written by large language models.\n\nIn fact, most developers spend the majority of their time debugging code, not writing it. As maintainers of popular open-source repositories, this resonates with us. But what if an AI tool could propose fixes for hundreds of open issues, and all we had to do was approve them before merging? This was what motivated us to maximize the potential time savings from AI coding tools by teaching them to debug code. \n\nBy debugging we mean the interactive, iterative process to fix code. Developers typically hypothesize why their code crashed, then gather evidence by stepping through the program and examining variable values. They often use debugging tools like pdb (Python debugger) to assist in gathering information. This process is repeated until the code is fixed.\n\nToday’s AI coding tools boost productivity and excel at suggesting solutions for bugs based on available code and error messages. However, unlike human developers, these tools don’t seek additional information when solutions fail, leaving some bugs unaddressed, as you can see in this simple demo of how a mislabeled column stumps today’s coding tools\n(opens in new tab)\n. This may leave users feeling like AI coding tools don’t understand the full context of the issues they are trying to solve. \n\nIntroducing debug-gym\n\nA natural research question emerges: to what degree can LLMs use interactive debugging tools such as pdb? To explore this question, we released debug-gym\n(opens in new tab)\n – an environment that allows code-repairing agents to access tools for active information-seeking behavior. Debug-gym expands an agent’s action and observation space with feedback from tool usage, enabling setting breakpoints, navigating code, printing variable values, and creating test functions. Agents can interact with tools to investigate code or rewrite it, if confident. We believe interactive debugging with proper tools can empower coding agents to tackle real-world software engineering tasks and is central to LLM-based agent research. The fixes proposed by a coding agent with debugging capabilities, and then approved by a human programmer, will be grounded in the context of the relevant codebase, program execution and documentation, rather than relying solely on guesses based on previously seen training data.\n\nFigure 1: Diagram demonstrating the code-repairing process in outline. In most existing approaches (shown in black), an agent rewrites its code conditioned on error messages obtained from executing the code. debug-gym equips the agent with additional tools such as pdb (shown in red), so it can interactively seek necessary information from the semantic space hidden behind the code and therefore have better code-repairing performance.\n\nDebug-gym is designed and developed to:\n\nHandle repository-level information: the full repository is available to agents in debug-gym, allowing them to navigate and edit files.\nBe robust and safe: to safeguard both the system and the development process, debug-gym runs code within sandbox Docker containers. This isolates the runtime environment, preventing harmful actions while still allowing thorough testing and debugging.  \nBe easily extensible: debug-gym was conceived with extensibility in mind and provides practitioners with the possibility of easily adding new tools.  \nBe text-based: debug-gym represents observation information in structured text (e.g., JSON format) and defines a simple syntax for text actions, making the environment fully compatible with modern LLM-based agents.\n\nWith debug-gym, researchers and developers can specify a folder path to work with any custom repository to evaluate their debugging agent’s performance. Additionally, debug-gym includes three coding benchmarks to measure LLM-based agents’ performance in interactive debugging: Aider for simple function-level code generation, Mini-nightmare for short, hand-crafted buggy code examples, and SWE-bench for real-world coding problems requiring a comprehensive understanding of a large codebase and a solution in the format of a GitHub pull request.\n\nTo learn more about debug-gym and start using it to train your own debugging agents, please refer to the technical report\n(opens in new tab)\n and GitHub\n(opens in new tab)\n. \n\nEarly experimentation: promising signal\n\nFor our initial attempt to validate that LLMs perform better on coding tests when they have access to debugging tools, we built a simple prompt-based agent and provided it with access to the following debug tools: eval, view, pdb, rewrite, and listdir. We used nine different LLMs as the backbone for our agent. Detailed results can be found in the technical report\n(opens in new tab)\n.\n(opens in new tab)\n\nEven with debugging tools, our simple prompt-based agent rarely solves more than half of the SWE-bench \n(opens in new tab)\nLite issues. We believe this is due to the scarcity of data representing sequential decision-making behavior (e.g., debugging traces) in the current LLM training corpus. However, the significant performance improvement (as shown in the most promising results in the graph below) validates that this is a promising research direction. \n\nFigure 2: The success rate represents the percentage of the 300 SWE-bench Lite issues resolved. The green bars indicate the performance of the agent with debugging tools, while the gray bars show the performance of the agent without debugging tools. Note that both agents use the same backbone LLM to make decisions and propose code edits.\n\nMICROSOFT RESEARCH PODCAST\n\nIdeas: AI and democracy with Madeleine Daepp and Robert Osazuwa Ness\n\nAs the “biggest election year in history” comes to an end, researchers Madeleine Daepp and Robert Osazuwa Ness and Democracy Forward GM Ginny Badanes discuss AI’s impact on democracy, including the tech’s use in Taiwan and India.\n\nListen now\nOpens in a new tab\nFuture work\n\nWe believe that training or fine-tuning LLMs can enhance their interactive debugging abilities. This requires specialized data, such as trajectory data that records agents interacting with a debugger to gather information before suggesting a fix. Unlike conventional reasoning problems, interactive debugging involves generating actions at each step that trigger feedback from the environment. This feedback helps the agent make new decisions, requiring dense data like the problem description and the sequence of actions leading to the solution. \n\nOur plan is to fine-tune an info-seeking model specialized in gathering the necessary information to resolve bugs. The goal is to use this model to actively build relevant context for a code generation model. If the code generation model is large, there is an opportunity to build a smaller info-seeking model that can provide relevant information to the larger one, e.g., a generalization of retrieval augmented generation (RAG), thus saving AI inference costs. The data collected during the reinforcement learning loop to train the info-seeking model can also be used to fine-tune larger models for interactive debugging.\n\nWe are open-sourcing debug-gym to facilitate this line of research. We encourage the community to help us advance this research towards building interactive debugging agents and, more generally, agents that can seek information by interacting with the world on demand.\n\nAcknowledgements\n\nWe thank Ruoyao Wang for their insightful discussion on building interactive debugging agents, Chris Templeman and Elaina Maffeo for their team coaching, Jessica Mastronardi and Rich Ciapala for their kind support in project management and resource allocation, and Peter Jansen for providing valuable feedback for the technical report.\n\nOpens in a new tab\nRelated publications\ndebug-gym: A Text-Based Environment for Interactive Debugging\nMeet the authors\nEric Yuan\n\nSenior Researcher\n\nLearn more\nMorgane Moss\n\nIntern\n\nLearn more\nCharbel Feghali\n\nStudent\n\nMcGill\n\nLearn more\nChinmay Singh\n\nPrincipal Research Software Development Engineer\n\nLearn more\nDarya Moldavskaya\n\nSenior Technical Program Manager\n\nLearn more\nDrew MacPhee\n\nR&I Service Manager\n\nLearn more\nLucas Caccia\n\nSenior Researcher\n\nLearn more\nMatheus Pereira\n\nSenior Software Development Engineer\n\nLearn more\nMinseon Kim\n\nPost Doc Researcher\n\nLearn more\nAlessandro Sordoni\n\nPrincipal Researcher\n\nLearn more\nMarc-Alexandre Côté\n\nPrincipal Researcher\n\nLearn more\nContinue reading\nDecember 20, 2024\nAIOpsLab: Building AI agents for autonomous clouds \nJuly 15, 2024\nRUBICON: Evaluating conversations between humans and AI systems \nMarch 20, 2024\nResearch Focus: Week of March 18, 2024 \nFebruary 7, 2024\nAI Controller Interface: Generative AI with a lightweight, LLM-integrated VM \nSee all blog posts\nResearch Areas\nArtificial intelligence\nProgramming languages and software engineering\nResearch Groups\nDeep Learning & Language | Montréal\nLanguage for Learning and Interaction | Montréal\nRobust, adaptive, modular ML | Montreal\nRelated labs\nMicrosoft Research Lab - New York City\nMicrosoft Research Lab – Montréal\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Research Focus: Week of April 7, 2025 ",
    "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-april-7-2025/",
    "excerpt": "In this issue: We introduce a new dataset designed to assist renewable energy infrastructure planners, a new method for denoising MRI imagery, and an AI tool for analyzing distant galaxies. Check out our latest research and other updates. ",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nResearch Focus: Week of April 7, 2025\n\nPublished April 9, 2025\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn this issue:\n\nWe introduce a new dataset designed to assist renewable energy infrastructure planners, a new method for denoising MRI imagery, and an AI tool for analyzing distant galaxies. Check out our latest research and other updates. \n\nNEW RESEARCH\nGlobal Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery\n\nSiting renewable energy infrastructure requires careful consideration of the potential impact on ecosystems, cultural and historical resources, agriculture, and scenic landscapes. To help policymakers, researchers, and other stakeholders assess strategies for deployment, researchers from Microsoft, The Nature Conservancy\n(opens in new tab)\n, and Planet\n(opens in new tab)\n present a comprehensive global temporal dataset of commercial solar photovoltaic (PV) farms and onshore wind turbines.\n\nThe researchers built the dataset by training deep learning-based segmentation models on high-resolution satellite imagery and then deploying them on over 13 trillion pixels of images covering the world. The final spatial dataset includes 375,197 individual wind turbines and 86,410 solar photovoltaic installations. For each detected feature, they estimate the construction date and the preceding land use type, and aggregate their findings to the country level, along with estimates of total power capacity.\n\nRead the paper\nNEW RESEARCH\nSNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation\n\nThis research proposes a new training method, SNRAware, to improve the ability of deep learning models to denoise—or remove unwanted random variations—from MRI images. MRI images can suffer from high levels of noise when scanning is accelerated with parallel imaging or when data are acquired using lower cost, low-field MRI systems.  \n\nThe researchers tested SNRAware on 14 different models, including ones based on transformer and convolutional architectures. The proposed training scheme improved the performance of all the tested models. This broad applicability means that the method is flexible and can be applied to different kinds of models without redesigning them. The testing showed SNRAware significantly improves the quality and clinical utility of MRI images while preserving important diagnostic details.\n\nRead the paper\nNEW RESEARCH\nCan AI unlock the mysteries of the universe?\n\nAnalyzing the physical properties of individual galaxies is a fundamental skill in astronomy. It requires a thorough understanding of galaxy formation theories and the ability to interpret vast amounts of observational data. However, even for seasoned astronomers, this process can be time-consuming and labor-intensive. To help astronomers accelerate this fundamental process, researchers from Microsoft and external colleagues introduce Mephisto, research designed to analyze extremely distant galaxies observed by the James Webb Space Telescope (JWST).\n\nMephisto analyzes photometric data from distant galaxies, proposing physical models and interacting with Code Investigating Galaxy Emission\n(opens in new tab)\n, a commonly used galaxy spectral simulation program. Mephisto can detect discrepancies between models and observational data, identifies potential instrumental errors or limitations in the models, iteratively adjusts parameters, and generates multiple explanations for the observational data.\n\nRead the article\nAPPLIED AI\nJapan Airlines’ new AI app will make it easier for cabin attendants to report inflight events with Microsoft’s Phi-4 small language model\n\nJapan Airlines (JAL) is using technology developed by Microsoft Research to deploy an AI app that helps flight crews communicate more effectively with ground staff when something unexpected comes up during a flight.\n\nThe JAL-AI Report is being developed using Microsoft’s Phi-4 small language model (SLM), which requires less computing power than the large language models (LLMs) most generative AI tools run on, so it can be used offline on a device for specific tasks.\n\nCabin attendants who have tried it say it can slash the time for writing operation reports by up to two thirds, say, from one hour to 20 minutes, or from 30 minutes to 10 for simpler cases.\n\nRead the story\nMicrosoft Research | In case you missed it\nAI weather forecast project eyes access through desktop computers \n\nFinancial Times | March 20, 2025\n\nAardvark Weather uses AI to deliver accurate forecasts in just minutes from a desktop computer. Developed by scientists at the University of Cambridge, with support from the Alan Turing Institute, Microsoft Research, and the European Centre for Medium-Range Weather Forecasts, this technology is tens of times faster than existing methods and requires only a fraction of the computing power.\n\nDirector of Microsoft Research talks AI for science (what it really means) \n\nThe Deep View | March 11, 2025\n\nChris Bishop, Director, AI for Science, Microsoft Research, discusses what AI is doing for science. This interview dives into how AI is accelerating discovery of new techniques and findings, the benefits of foundation models like Aurora, MatterGen’s capabilities, and AI’s impact on scientists.\n\nMicrosoft’s Christopher Bishop: Scientific discovery is AI’s killer application \n\nFinancial Times | April 3, 2025\n\nChristopher Bishop runs Microsoft’s AI for Science research unit, which applies the powerful technology to the natural sciences. Bishop sees the mission of the lab, which was founded in 2022, as accelerating scientific discovery using the technology.\n\nIn this conversation with the Financial Times’ AI editor Madhumita Murgia, he explains why he believes scientific discovery will prove to be the single most important application of the technology.\n\nInnovation to Impact (ft. Dr M – DGTL Voices with Ed Marx) \n\nDGTL Voices with Ed Marx | March 12, 2025\n\nMatthew Lungren, Chief Scientific Officer, Microsoft Health and Life Sciences, and Jonathan Carlson, Managing Director, Microsoft Health Futures, discuss AI’s transformative impact on radiology and the importance of collaboration in research and product development. They highlight how healthcare organizations can leverage Microsoft’s resources for innovation, emphasizing Microsoft’s progress in developing radiology-specific multimodal models and its broader work in healthcare.\n\nTech Life – The doctor will see you now \n\nBBC Sounds | March 4, 2025\n\nAn update from the live trials in Ghana of Microsoft Research’s Holoportation 3D telemedicine technology. BBC’s Tech Life speaks to lead researcher Spencer Fowers, as well as a patient and doctor benefiting from the portable kit.\n\nRelated video: 3D telemedicine offers help to sick Ghanaians in remote locations\n\nMicrosoft Unveils New AI Model to Edit Video Games \n\nIEEE Spectrum | March 11, 2025\n\nLead researcher Katja Hoffman discusses Microsoft’s Muse, a transformer model with 1.6 billion parameters trained on 500,000 hours of player data that can generate gameplay examples from a single screenshot.\n\nNational University of Singapore collaborates with Microsoft Research Asia to advance AI research and cultivate computing talent \n\nNUS News | April 2, 2025\n\nThe National University of Singapore (NUS) has signed a five-year collaboration agreement with Microsoft Research Asia for a Joint PhD Supervision Program, bringing together NUS’s academic and research excellence with Microsoft Research Asia’s global leadership in AI, computing research, and industrial applications to cultivate talent. As part of this collaboration, NUS and Microsoft Research Asia will nurture PhD students through the Industrial Postgraduate Program, supported by the Singapore Economic Development Board (EDB). This initiative will help to cultivate interdisciplinary, high-caliber tech professionals and drive the integration of AI technology across industries.\n\nHow Microsoft made it through 50 years \n\nThe Verge | April 4, 2025\n\nA lot has changed since Microsoft was founded, but in many ways, the company’s core business model and ethos remain the same: make software that everyone needs and get it installed everywhere. Adapting to change, including the ongoing AI transformation, has always played an important role in the company’s success.\n\nView more news and awards\nOpens in a new tab\nRelated publications\nInterpreting Multi-band Galaxy Observations with Large Language Model-Based Agents\nGlobal Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery\nSNRAware: Improved Deep Learning MRI Denoising with SNR Unit Training and G-factor Map Augmentation\nContinue reading\nMay 7, 2025\nResearch Focus: Week of May 7, 2025 \nApril 23, 2025\nResearch Focus: Week of April 21, 2025 \nMarch 26, 2025\nResearch Focus: Week of March 24, 2025 \nJanuary 31, 2025\nResearch Focus: Week of January 27, 2025 \nSee all blog posts\nResearch Areas\nArtificial intelligence\nComputer vision\nEcology and environment\nHuman-computer interaction\nMedical, health and genomics\nResearch Groups\nAI For Good Lab\nRelated projects\nConnected Imaging Instrument\nRelated labs\nMicrosoft Research Lab - Asia\nMicrosoft Health Futures\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "VidTok introduces compact, efficient tokenization to enhance AI video processing ",
    "link": "https://www.microsoft.com/en-us/research/blog/vidtok-introduces-compact-efficient-tokenization-to-enhance-ai-video-processing/",
    "excerpt": "The VidTok method can enable AI systems to process and generate videos more effectively. Compact tokenization reduces computational costs while maintaining video quality across a potentially diverse set of applications.",
    "content": "Take the power of Copilot on the go with the free mobile app\nCreate images and get tailored answers based on your interests and needs anytime, anywhere\nNo, thanks\nGet the Copilot app\nSkip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nVidTok introduces compact, efficient tokenization to enhance AI video processing\n\nPublished April 2, 2025\n\nBy Tianyu He , Senior Researcher  Junliang Guo , Senior Researcher  Jiang Bian , Partner Research Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nEvery day, countless videos are uploaded and processed online, putting enormous strain on computational resources. The problem isn’t just the sheer volume of data—it’s how this data is structured. Videos consist of raw pixel data, where neighboring pixels often store nearly identical information. This redundancy wastes resources, making it harder for systems to process visual content effectively and efficiently.\n\nTo tackle this, we’ve developed a new approach to compress visual data into a more compact and manageable form. In our paper “VidTok: A Versatile and Open-Source Video Tokenizer,” we introduce a method that converts video data into smaller, structured units, or tokens. This technique provides researchers and developers in visual world modeling—a field dedicated to teaching machines to interpret images and videos—with a flexible and efficient tool for advancing their work. \n\nHow VidTok works\n\nVidTok is a technique that converts raw video footage into a format that AI can easily work with and understand, a process called video tokenization. This process converts complex visual information into compact, structured tokens, as shown in Figure 1.\n\nFigure 1. An overview of how video tokenizers work, which form the basis of VidTok.\n\nBy simplifying videos into manageable chunks, VidTok can enable AI systems to learn from, analyze, and generate video content more efficiently. VidTok offers several potential advantages over previous solutions:\n\nSupports both discrete and continuous tokens. Not all AI models use the same “language” for video generation. Some perform best with continuous tokens—ideal for high-quality diffusion models—while others rely on discrete tokens, which are better suited for step-by-step generation, like language models for video. VidTok is a tokenizer that has demonstrated seamless support for both, making it adaptable across a range of AI applications.\n\nOperates in both causal and noncausal modes. In some scenarios, video understanding depends solely on past frames (causal), while in others, it benefits from access to both past and future frames (noncausal). VidTok can accommodate both modes, making it suitable for real-time use cases like robotics and video streaming, as well as for high-quality offline video generation.\n\nEfficient training with high performance. AI-powered video generation typically requires substantial computational resources. VidTok can reduce training costs by half through a two-stage training process—delivering high performance and lowering costs.\n\nSPOTLIGHT: EVENT SERIES\n\nMicrosoft Research Forum\n\nJoin us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.\n\nWatch on-demand\nOpens in a new tab\nArchitecture\n\nThe VidTok framework builds on a classic 3D encoder-decoder structure but introduces 2D and 1D processing techniques to handle spatial and temporal information more efficiently. Because 3D architectures are computationally intensive, VidTok combines them with less resource-intensive 2D and 1D methods to reduce computational costs while maintaining video quality.\n\nSpatial processing. Rather than treating video frames solely as 3D volumes, VidTok applies 2D convolutions—pattern-recognition operations commonly used in image processing—to handle spatial information within each frame more efficiently.\n\nTemporal processing. To model motion over time, VidTok introduces the AlphaBlender operator, which blends frames smoothly using a learnable parameter. Combined with 1D convolutions—similar operations applied over sequences—this approach captures temporal dynamics without abrupt transitions.\n\nFigure 2 illustrates VidTok’s architecture in detail.\n\nFigure 2. VidTok’s architecture. It uses a combination of 2D and 1D operations instead of solely relying on 3D techniques, improving efficiency. For smooth frame transitions, VidTok employs the AlphaBlender operator in its temporal processing modules. This approach strikes a balance between computational speed and high-quality video output.\nQuantization\n\nTo efficiently compress video data, AI systems often use quantization to reduce the amount of information that needs to be stored or transmitted. A traditional method for doing this is vector quantization (VQ), which groups values together and matches them to a fixed set of patterns (known as a codebook). However, this can lead to an inefficient use of patterns and lower video quality.\n\nFor VidTok, we use an approach called finite scalar quantization (FSQ). Instead of grouping values, FSQ treats each value separately. This makes the compression process more flexible and accurate, helping preserve video quality while keeping the file size small. Figure 3 shows the difference between the VQ and FSQ approaches.\n\nFigure 3. VQ (left) relies on learning a codebook, while FSQ (right) simplifies the process by independently grouping values into fixed sets, making optimization easier. VidTok adopts FSQ to enhance training stability and reconstruction quality.\nTraining\n\nTraining video tokenizers requires significant computing power. VidTok uses a two-stage process:\n\nIt first trains the full model on low-resolution videos.\nThen, it fine-tunes only the decoder using high-resolution videos.\n\nThis approach cuts training costs in half—from 3,072 to 1,536 GPU hours—while maintaining video quality. Older tokenizers, trained on full-resolution videos from the start, were slower and more computationally intensive. \n\nVidTok’s method allows the model to quickly adapt to new types of videos without affecting its token distribution. Additionally, it trains on lower-frame-rate data to better capture motion, improving how it represents movement in videos.\n\nEvaluating VidTok\n\nVidTok’s performance evaluation using the MCL-JCV benchmark—a comprehensive video quality assessment dataset—and an internal dataset demonstrates its superiority over existing state-of-the-art models in video tokenization. The assessment, which covered approximately 5,000 videos of various types, employed four standard metrics to measure video quality:\n\nPeak Signal-to-Noise Ratio (PSNR)\nStructural Similarity Index Measure (SSIM)\nLearned Perceptual Image Patch Similarity (LPIPS)\nFréchet Video Distance (FVD)\n\nThe following table and Figure 4 illustrate VidTok’s performance:\n\nTable 1\n\nThe results indicate that VidTok outperforms existing models in both discrete and continuous tokenization scenarios. This improved performance is achieved even when using a smaller model or a more compact set of reference patterns, highlighting VidTok’s efficiency.\n\nFigure 4. Quantitative comparison of discrete and continuous tokenization performance in VidTok and state-of-the-art methods, evaluated using four metrics: PSNR, SSIM, LPIPS, and FVD. Larger chart areas indicate better overall performance.\nLooking ahead\n\nVidTok represents a significant development in video tokenization and processing. Its innovative architecture and training approach enable improved performance across various video quality metrics, making it a valuable tool for video analysis and compression tasks. Its capacity to model complex visual dynamics could improve the efficiency of video systems by enabling AI processing on more compact units rather than raw pixels.\n\nVidTok serves as a promising foundation for further research in video processing and representation. The code for VidTok is available on GitHub\n(opens in new tab)\n, and we invite the research community to build on this work and help advance the broader field of video modeling and generation.\n\nOpens in a new tab\nRelated publications\nVidTok: A Versatile and Open-Source Video Tokenizer\nMeet the authors\nTianyu He\n\nSenior Researcher\n\nLearn more\nJunliang Guo\n\nSenior Researcher\n\nJiang Bian\n\nPartner Research Manager\n\nLearn more\nContinue reading\nMarch 18, 2025\nIntroducing KBLaM: Bringing plug-and-play external knowledge to LLMs \nFebruary 25, 2025\nMagma: A foundation model for multimodal AI agents across digital and physical worlds \nFebruary 19, 2025\nIntroducing Muse: Our first generative AI model designed for gameplay ideation \nFebruary 7, 2024\nAI Controller Interface: Generative AI with a lightweight, LLM-integrated VM \nSee all blog posts\nResearch Areas\nArtificial intelligence\nComputer vision\nGraphics and multimedia\nResearch Groups\nMachine Learning Area\nRelated tools\nVideo Tokenizer\nRelated labs\nMicrosoft Research Lab - Asia\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Research Focus: Week of March 24, 2025 ",
    "link": "https://www.microsoft.com/en-us/research/blog/research-focus-week-of-march-24-2025/",
    "excerpt": "In this issue, we examine a new conversation segmentation method that delivers more coherent and personalized agent conversation, and we review efforts to improve MLLMs’ understanding of geologic maps. Check out the latest research and other updates.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nResearch Focus: Week of March 24, 2025\n\nPublished March 26, 2025\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nIn this issue:\n\nWe examine a new conversation segmentation method that delivers more coherent and personalized agent conversation, and we review efforts to improve MLLMs’ understanding of geologic maps. Check out the latest research and other updates.\n\nNEW RESEARCH\nSeCom: On Memory Construction and Retrieval for Personalized Conversational Agents\n\nResearchers from Microsoft and Tsinghua University propose a new method to help conversational AI agents deliver more coherent and personalized responses during complex long-term dialogue.\n\nLarge language models (LLMs) are widely used to enable more complicated discussions across a broader range of topics than traditional dialogue systems. However, managing excessively long context that contains irrelevant information is a major challenge. Existing solutions typically perform retrieval augmented response generation by constructing memory banks from conversation history at either the turn-level, session-level, or through summarization.\n\nThe proposed new approach, SeCom, constructs the memory bank at segment level by introducing a conversation Segmentation model that partitions long-term conversations into topically coherent segments, while applying Compression based denoising on memory units to enhance memory retrieval. Experimental results show that SeCom exhibits a significant performance advantage over baselines on long-term conversation benchmarks LOCOMO and Long-MT-Bench+. Additionally, the proposed conversation segmentation method demonstrates superior performance on dialogue segmentation datasets such as DialSeg711, TIAGE, and SuperDialSeg. \n\nRead the paper\nNEW RESEARCH\nPEACE: Empowering Geologic Map Holistic Understanding with MLLMs\n\nMicrosoft Researchers and external colleagues introduce GeoMap-Agent, an AI system specifically designed for geologic map understanding and analysis. In the lab, they measure its effectiveness using a new benchmark called GeoMap-Bench, a novel gauge for evaluating multimodal large language models (MLLMs) in geologic map understanding. Geologic maps provide critical insights into the structure and composition of Earth’s surface and subsurface. They are indispensable in fields including disaster detection, resource exploration, and civil engineering.\n\nCurrent MLLMs often fall short in understanding geologic maps, largely due to the challenging nature of cartographic generalization, which involves handling high-resolution maps, managing multiple associated components, and requiring domain-specific knowledge.\n\nThis paper presents results of experiments in which GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming the 0.369 score of GPT-4o. The researchers intend to enable advanced AI applications in geology, powering more efficient and accurate geological investigations.\n\nRead the paper\nNEW RESEARCH\nThe future of the industrial AI edge is cellular\n\nReliable, high-bandwidth wireless connectivity and local processing at the edge are crucial enablers for emerging industrial AI applications. This work proposes that cellular networking is the ideal connectivity solution for these applications, due to its virtualization and support for open APIs. The researchers project the emergence of a converged industrial AI edge encompassing both computing and connectivity, in which application developers leverage the API to implement advanced functionalities. They present a case study showing evidence of the effectiveness of this approach, evaluated on an enterprise-grade 5G testbed.\n\nRead the paper\nNEW RESEARCH\nRE#: High Performance Derivative-Based Regex Matching with Intersection, Complement, and Restricted Lookarounds\n\nA regular expression (regex or RE) is a sequence of characters used to match, search, and manipulate strings in text based on specific criteria. REs are used in programming languages for data validation, text parsing, and search operations.\n\nThis paper presents a tool and theory built on symbolic derivatives that does not use backtracking, while supporting both classical operators and complement, intersection, and restricted lookarounds. The researchers show that the main matching algorithm has input-linear complexity both in theory as well as experimentally. They apply thorough evaluation on popular benchmarks that show that RE# is over 71% faster than the next fastest regex engine in Rust on the baseline, and outperforms all state-of-the-art engines on extensions of the benchmarks, often by several orders of magnitude. \n\nThis work could potentially enable new applications in LLM prompt engineering frameworks, new applications in medical research and bioinformatics, and new opportunities in access and resource policy language design by web service providers.\n\nRead the paper\nNEW RESEARCH\nToward deep learning sequence–structure co-generation for protein design\n\nResearchers review recent advances in deep generative models for protein design, with a focus on sequence-structure co-generation methods. They describe the key methodological and evaluation principles underlying these methods, highlight recent advances from the literature, and discuss opportunities for continued development of sequence-structure co-generation approaches.\n\nDeep generative models that learn from the distribution of natural protein sequences and structures may enable the design of new proteins with valuable functions. While most of today’s models focus on generating either sequences or structures, emerging co-generation methods promise more accurate and controllable protein design, ideally achieved by modeling both modalities simultaneously. \n\nRead the paper\nAbout Microsoft Research\n\nAdvancing science and technology to benefit humanity\n\nView our story\nOpens in a new tab\nPODCAST\nNew Series: The AI Revolution in Medicine, Revisited\n\nTwo years ago, OpenAI’s GPT-4 kick-started a new era in AI. In the months leading up to its public release, Peter Lee, president of Microsoft Research, cowrote The AI Revolution in Medicine: GPT-4 and Beyond, a book full of optimism for the potential of advanced AI models to transform the world of healthcare. In this special Microsoft Research Podcast series, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.\n\nWatch the series\nPODCAST\nThe future of generative AI for scientific discovery\n\nMost of us think of generative AI in the context of text or image generation, but it’s also a powerful tool for scientific discovery. In this episode of the Leading the Shift podcast\n(opens in new tab)\n, host Susan Etlinger speaks with Ade Famoti, a senior leader on the Microsoft Research Accelerator team. Ade discusses what he calls “AI’s physics moment,” and why he believes generative AI feels fundamentally different from past platform shifts. Ade shares examples of the work Microsoft Research is doing to uncover the opportunities of generative AI for materials discovery—to improve energy efficiency and carbon capture, and for drug discovery, to fight disease. Ade also highlights the role of culture in building trust, informing priorities and driving adoption of emerging technologies.\n\nVIDEO\nMicrosoft Research’s Chris Bishop talks AI for Science (what it really means)\n\nIn this interview, the director of Microsoft Research AI for Science, Chris Bishop, discusses how AI is unlocking new scientific outcomes, from drug creation to materials generation to improved climate modeling.\n\nMicrosoft Research | In case you missed it\nTech Life – The doctor will see you now \n\nBBC Sounds | March 4, 2025\n\nAn update on live trials in Ghana of 3D telemedicine technology, developed by Microsoft Research and external collaborators. Using portable equipment and holoportation technology, patients in remote locations can connect with a doctor many miles away. The BBC speaks to Spencer Fowers, who is the lead engineer on the project, as well as a patient and a doctor benefiting from the program.\n\nKatja Hofmann: Why we're training AI on video games \n\nTED Talk | October 2024\n\nIn a recent TED Talk: Why we’re training AI on video games, Microsoft researcher Katja Hofmann discusses the work the Game Intelligence team at Microsoft Research is doing to develop AI that can transform video games. Using AI trained on years of human gameplay data, the team built World and Human Action Model, which can learn to think, play and innovate alongside humans, enabling video game creators to build more robust games. Hoffmann was also interviewed in a related article: Microsoft’s Muse AI Edits Video Games on the Fly.\n\nView more news and awards\nOpens in a new tab\nRelated publications\nRE#: High Performance Derivative-Based Regex Matching with Intersection, Complement, and Restricted Lookarounds\nThe future of the industrial AI edge is cellular\nPEACE: Empowering Geologic Map Holistic Understanding with MLLMs\nToward deep learning sequence–structure co-generation for protein design\nSeCom: On Memory Construction and Retrieval for Personalized Conversational Agents\nContinue reading\nApril 9, 2025\nResearch Focus: Week of April 7, 2025 \nJanuary 31, 2025\nResearch Focus: Week of January 27, 2025 \nJune 26, 2024\nResearch Focus: Week of June 24, 2024 \nMarch 20, 2024\nResearch Focus: Week of March 18, 2024 \nSee all blog posts\nResearch Areas\nAlgorithms\nArtificial intelligence\nComputer vision\nHuman-computer interaction\nMedical, health and genomics\nProgramming languages and software engineering\nSocial sciences\nSystems and networking\nResearch Groups\nResearch in Software Engineering (RiSE)\nBiomedical ML\nEngineering Foundation\nIntelligent Networked Systems (INS)\nRelated projects\nSeCom: On Memory Construction & Retrieval for Personalized Conversational Agents\nProject Janus: Programmable RAN and Platform\nAutomata\nRelated labs\nMicrosoft Research Lab - Asia\nMicrosoft Research Lab - New England\nMicrosoft Research Lab - Redmond\nMicrosoft Health Futures\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Metasurface: Unlocking the future of wireless sensing and communication ",
    "link": "https://www.microsoft.com/en-us/research/blog/metasurface-unlocking-the-future-of-wireless-sensing-and-communication/",
    "excerpt": "Metasurfaces explore engineered 2D materials that manipulate electromagnetic and mechanical waves, offering advances in wireless tech. They can power indoor GPS, extend 5G/6G coverage, and enable wireless sensing and imaging.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nMetasurface: Unlocking the future of wireless sensing and communication\n\nPublished March 19, 2025\n\nBy Lili Qiu , Assistant Managing Director  Hao Pan , Senior Researcher\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nAs the demand for faster, more reliable wireless communication continues to grow, but traditional systems face limitations in efficiency and adaptability. To keep up with evolving needs, researchers are investigating new ways to manipulate electromagnetic waves to improve wireless performance. \n\nTo address these challenges, researchers are exploring new approaches, including metasurfaces—engineered materials that can control wave propagation in unprecedented ways. By dynamically shaping and directing electromagnetic waves, metasurfaces offer a promising path to overcoming the constraints of conventional wireless systems. \n\nBuilding on these capabilities, we are developing metasurfaces for a wide range of wireless applications, such as enhancing Low Earth Orbit satellite communication, optimizing acoustic sensing, and enabling acoustic and millimeter-wave technologies for 5G and 6G communication systems with commercial devices. More recently, our work has focused on enabling indoor access to the Global Navigation Satellite System (GNSS), improving millimeter-wave coverage in targeted environments, optimizing heat distribution in microwave ovens, and providing directional sound projection without headphones.\n\nThese advances, published at leading networking conferences—including MobiCom 2023 and 2024, MobiSys 2024 and 2025, and NSDI 2023—highlight metasurfaces’ potential in wireless communication and sensing. This post explores some of these applications in more detail. \n\nMICROSOFT RESEARCH PODCAST\n\nWhat’s Your Story: Lex Story\n\nModel maker and fabricator Lex Story helps bring research to life through prototyping. He discusses his take on failure; the encouragement and advice that has supported his pursuit of art and science; and the sabbatical that might inspire his next career move.\n\nListen now\nOpens in a new tab\nMetasurfaces optimize GNSS for accurate indoor positioning\n\nWhile GNSS is widely used for outdoor positioning and navigation, its indoor performance is often hindered by signal blockage, reflection, and attenuation caused by physical obstacles. Additional technologies like Wi-Fi and Bluetooth Low Energy (BLE) are often employed to address these issues. However, these solutions require extra infrastructure, are costly, and are complicated to deploy. Accurate positioning also typically depends on specialized hardware and software on mobile devices. \n\nDespite these challenges, GNSS signals hold promise for accurate indoor positioning. By leveraging the vast number of available satellites, GNSS-based solutions eliminate the need for base station deployment and maintenance required by Wi-Fi and BLE systems. This approach also allows seamless integration between indoor and outdoor environments, supporting continuous positioning in scenarios like guiding smart vehicles through indoor and outdoor industrial environments. \n\nTo explore this potential, we conducted indoor measurements and found that GNSS satellite signals can penetrate windows at different angles and reflect or diffract from surfaces like floors and ceilings, resulting in uneven signals. Metasurfaces can control structured arrays of electromagnetic signals, allowing them to capture and redirect more GNSS signals. This allows signals to enter buildings in a path parallel to the ground, achieving broader coverage. Using this capability, we developed a GNSS positioning metasurface system (GPMS) based on passive metasurface technology.\n\nOne limitation of passive metasurfaces is their lack of programmability. To overcome this and enable them to effectively guide signals from different angles and scatter them in parallel, we designed a two-layer metasurface system. As shown in Figure 1, this design ensures that electromagnetic waves from different angles follow similar emission trajectories.  \n\nFigure 1: The GPMS two-layer metasurface structure\n\nTo improve positioning accuracy, we developed new algorithms that allow signals to pass through metasurfaces, using them as anchor points. Traditional GPS positioning requires signals from at least four satellites to decode location information. In the GPMS system, illustrated in Figure 2, each deployed metasurface functions as a virtual satellite. By deploying at least three metasurfaces indoors, we achieved high-precision positioning through a triangulation algorithm.\n\nFigure 2. Diagram of the GPMS system. Passive metasurfaces guide GNSS signals indoors, while enhanced positioning algorithms provide precise indoor positioning on mobile devices. \n\nTo evaluate the system, we deployed the GPMS with six metasurfaces on a 10×50-meter office floor and a 15×20-meter conference hall. The results show significant improvements in signal quality and availability. C/N₀, a measure of signal-to-noise ratio, increased from 9.1 dB-Hz to 32.2 dB-Hz. The number of visible satellites increased from 3.6 to 21.5. Finally, the absolute positioning error decreased from 30.6 meters to 3.2 meters in the office and from 11.2 meters to 2.7 meters in the conference hall. These findings are promising and highlight the feasibility and advantages of GNSS-based metasurfaces for indoor positioning. \n\nMetasurfaces extend millimeter-wave coverage\n\nMillimeter waves enable the high-speed, low-latency performance needed for 5G and 6G communication systems. While commercial products like 60 GHz Wi-Fi routers and mobile devices are becoming popular, their limited coverage and susceptibility to signal obstruction restrict their widespread application. \n\nTraditional solutions include deploying multiple millimeter-wave access points, such as routers or base stations, or placing reflective metal panels in room corners to reflect electromagnetic waves. However, these approaches are both costly and offer limited performance. Metasurfaces offer a promising alternative for improving millimeter-wave applications. Previous research has shown that programmable metasurfaces can enhance signal coverage in blind spots and significantly improve signal quality and efficiency.  \n\nTo maximize the benefits of metasurfaces, we developed the AutoMS automation service framework, shown in Figure 3. This proposed framework can optimize millimeter-wave coverage using low-cost passive metasurface design and strategic placement. \n\nThe three main components of AutoMS can address the limitations of traditional solutions: \n\nAutomated joint optimization: AutoMS determines the optimal network deployment configuration by analyzing phase settings, metasurface placement, and access point positioning. It also refines beam-forming configurations to enhance signal coverage. By iteratively identifying and optimizing the number, size, and placement of metasurfaces, AutoMS adjusts the metasurface phase settings and the access point’s configurations to achieve optimal signal coverage. \nFigure 3. The AutoMS framework generates optimized deployment plans for passive metasurface and access points based on environment scanning results. \nFast 3D ray tracing simulator: Using hardware and software acceleration, our simulator efficiently calculates channel matrices resulting from metasurfaces with tens of thousands of elements. This simulator, capable of tracing 1.3 billion rays in just three minutes on an A100 GPU, significantly accelerates calculations for complex environments.\nLow-cost passive metasurface design: We designed a high-reflectivity passive metasurface with near-2π phase control and broadband compatibility for the millimeter-wave frequency band. This metasurface is compatible with low-precision, cost-effective thermoforming processes. This process enables users to create metasurfaces at minimal cost, significantly reducing deployment expenses.\n\nShown in Figure 4, users can capture the environment using existing 3D scanning apps on mobile devices, generate a 3D layout model, and upload it to the cloud. AutoMS then generates metasurface settings and placement guidelines.  \n\nUsers can print metasurface patterns using hot stamping and customize them without affecting functionality, as millimeter waves penetrate paint and paper. \nFigure 4: The low-cost passive metasurface creation process \n\nEvaluation using publicly available 3D layout datasets and real-world tests shows that AutoMS significantly improves millimeter-wave coverage across various scenarios. Compared to a single router setup, AutoMS increased signal strength by 12.1 dB. Onsite tests further confirmed gains of 11 dB in target areas and over 20 dB in blind spots, with signal throughput increasing from 77 Mbps to 373 Mbps. AutoMS adapts to diverse environments, ensuring reliable and flexible deployment in real-world applications. \n\nMetasurfaces support uniform heating in microwave ovens \n\nMicrowave ovens often heat unevenly, creating cold spots in food. These can allow harmful bacteria and other pathogens to survive, increasing the risk of foodborne illnesses. Uneven heating can cause eggs to burst or create “hot spots” that can scald.\n\nUneven heating is due to the appliance’s heating mechanism. Microwave ovens generate high-power radio frequency (RF) electromagnetic waves through dielectric heating. These waves create nodes with zero amplitude, which prevents heating. They also create antinodes, where heating occurs more rapidly.  \n\nTo address this issue, we developed MicroSurf, a low-cost solution that improves heating by using passive metasurfaces to control electromagnetic energy inside the microwave oven. It uses the resonance effect between the metasurface and electromagnetic waves to modify the standing-wave distribution and achieve more uniform heating. This is shown in Figure 5. \n\nFigure 5: MicroSurf’s working principle: Uneven electric field distribution inside the microwave oven leads to uneven heating. B. Modeling the microwave oven. C. Designing and optimizing a metasurface that can function in a high-power environment to change the standing wave distribution. D. Achieving uniform heating of different foods and selectively heating specific parts. \n\nTests across four different microwave oven brands demonstrate that MicroSurf effectively optimizes heating for various liquids and solids, uniformly heating water, milk, bread, and meat. It concentrates heat on specific areas and adapts to differently shaped foods. MicroSurf offers a promising solution for even heating in microwave ovens, demonstrating the potential of metasurface technology in everyday applications. This innovation paves the way for smarter, more efficient home appliances.  \n\nAdvancing wireless innovation\n\nWireless sensing and communication technologies are evolving rapidly, driving innovation across a wide range of applications. We are continuing to push the boundaries of these technologies—particularly in metasurface development—while working to create practical solutions for a variety of use cases. \n\nOpens in a new tab\nRelated publications\nGPMS: Enabling Indoor GNSS Positioning using Passive Metasurfaces\nAutoMS: Automated Service for mmWave Coverage Optimization using Low-cost Metasurfaces\nMicroSurf: Guiding Energy Distribution inside Microwave Oven with Metasurfaces\nMeet the authors\nLili Qiu\n\nAssistant Managing Director\n\nLearn more\nHao Pan\n\nSenior Researcher\n\nLearn more\nContinue reading\nMay 14, 2024\nRASCAL: Novel robotics for scalable and highly available automated storage and retrieval \nMarch 19, 2024\nIntelligent monitoring: Towards AI-assisted monitoring for cloud services \nOctober 26, 2023\nProject Silica: Sustainable cloud archival storage in glass \nSeptember 14, 2023\nMicrosoft at ACM SIGCOMM 2023: Innovating the future of networking \nSee all blog posts\nResearch Areas\nSystems and networking\nResearch Groups\nMicrosoft Research Asia - Shanghai\nRelated labs\nMicrosoft Research Lab - Asia\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Claimify: Extracting high-quality claims from language model outputs ",
    "link": "https://www.microsoft.com/en-us/research/blog/claimify-extracting-high-quality-claims-from-language-model-outputs/",
    "excerpt": "Claimify, created by Microsoft Research, is a novel LLM-based claim-extraction method that outperforms prior solutions to produce more accurate, comprehensive, and substantiated claims from LLM outputs.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nClaimify: Extracting high-quality claims from language model outputs\n\nPublished March 19, 2025\n\nBy Dasha Metropolitansky , Research Data Scientist\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\nWatch Dasha’s Claimify Explainer\n\nThis research was accepted by the 63rd annual meeting of the Association for Computational Linguistics (ACL 2025), the premier conference on natural language processing.\n\nWhile large language models (LLMs) are capable of synthesizing vast amounts of information, they sometimes produce inaccurate or unsubstantiated content. To mitigate this risk, tools like Azure AI’s Groundedness Detection\n(opens in new tab)\n can be used to verify LLM outputs. \n\nA common strategy for fact-checking LLM-generated texts – especially complex, highly detailed outputs – is claim extraction: instead of evaluating the entire text at once, it’s broken down into simple factual statements that can be verified independently. However, the effectiveness of this approach depends on the quality of the extracted claims: if they are inaccurate or incomplete, the fact-checking results may be compromised. \n\nOur paper “Towards Effective Extraction and Evaluation of Factual Claims” proposes a framework for evaluating claim extraction and introduces Claimify, a novel LLM-based method that outperforms prior solutions. In this blog post, we discuss common claim extraction issues and explore Claimify’s approach.\n\nKey issues in claim extraction\n\nAs a case study, we prompted OpenAI’s GPT-4o model to “provide an overview of challenges in emerging markets” based on a collection of news articles. Here is its output:\n\n# Emerging market challenges\nEmerging markets face a myriad of challenges that span economic, social, and environmental dimensions. These challenges are often interconnected, exacerbating the difficulties faced by these regions.\n\n## Economic instability and inflation\nSeveral emerging markets are grappling with severe economic instability. For instance, Argentina’s rampant inflation, with monthly rates reaching as high as 25.5%, has made many goods unobtainable and plunged the value of the currency, causing severe economic hardship. Some experts estimate that the annual inflation rate could potentially double to 300%, while others predict even higher rates.\n\n## Food insecurity and agricultural challenges\nFood insecurity is another critical issue in emerging markets. Nigeria, for example, is striving to become self-sufficient in wheat production but is hindered by climate change and violence, exacerbated by high grain prices due to the suspension of the Black Sea Grain Initiative. Climate change has played a pivotal role in creating food insecurity and economic instability in farming-dependent economies, such as Zambia and Mozambique.\n\n## Natural disasters and public health emergencies\nPublic health crises, as demonstrated by the experience of Derna, Libya, remain a significant concern in emerging markets. Catastrophic flooding caused by the collapse of two dams has led to significant destruction, complicating access to healthcare. The U.N. found that the resulting contaminated water caused many residents to fall ill, highlighting the need for improved water management. Countries like Afghanistan and Sudan have experienced similar challenges to those of Libya.\n\n## Conclusion\nAddressing emerging market challenges will require comprehensive strategies that consider economic stability, food security, and public health. International cooperation and targeted interventions are crucial in fostering sustainable development in emerging markets.\n\nWe then applied a simple prompt[1] that extracted the following claims from the answer:\n\n1. Emerging markets face economic challenges.\n2. Emerging markets face social challenges.\n3. Emerging markets face environmental challenges.\n4. Argentina experiences severe economic instability.\n5. Argentina has a monthly inflation rate as high as 25.5%.\n6. Argentina’s inflation has made many goods unobtainable.\n7. Argentina’s currency value has plunged.\n8. Some experts estimate Argentina’s annual inflation rate could reach 300%.\n9. Food insecurity is a critical issue in emerging markets.\n10. Nigeria is striving to become self-sufficient in wheat production.\n11. Nigeria’s wheat production is hindered by climate change.\n12. Nigeria’s wheat production is hindered by violence.\n13. High grain prices affect Nigeria due to the suspension of the Black Sea Grain Initiative.\n14. Climate change creates food insecurity in Zambia.\n15. Climate change creates food insecurity in Mozambique.\n16. Climate change causes economic instability in farming-dependent economies.\n17. Public health crises are a concern in emerging markets.\n18. Derna, Libya, experienced catastrophic flooding.\n19. The collapse of two dams caused flooding in Derna, Libya.\n20. Flooding in Derna, Libya, complicated access to healthcare.\n21. The U.N. found contaminated water in Derna, Libya.\n22. Contaminated water in Derna, Libya, caused many residents to fall ill.\n23. Afghanistan has experienced challenges similar to those in Libya.\n24. Sudan has experienced challenges similar to those in Libya.\n25. Addressing emerging market challenges requires comprehensive strategies.\n26. Comprehensive strategies should consider economic stability.\n27. Comprehensive strategies should consider food security.\n28. Comprehensive strategies should consider public health.\n29. International cooperation is crucial for sustainable development in emerging markets.\n30. Targeted interventions are crucial for sustainable development in emerging markets.\n\nThese claims appear to reflect the answer, but a closer look reveals four critical issues:\n\n#\tIssue\tExample\n1\tSome claims are not factual statements that can be verified as true or false.\tExcerpt: “Addressing emerging market challenges will require comprehensive strategies that consider economic stability, food security, and public health.”\n\nClaims:\nAddressing emerging market challenges requires comprehensive strategies.\nComprehensive strategies should consider economic stability.\nComprehensive strategies should consider food security.\nComprehensive strategies should consider public health.\nExplanation: These claims are not verifiable because they are opinions.\n2\tSome claims are missing or incomplete.\tExcerpt: “Argentina’s rampant inflation, with monthly rates reaching as high as 25.5%, has made many goods unobtainable and plunged the value of the currency, causing severe economic hardship. Some experts estimate that the annual inflation rate could potentially double to 300%, while others predict even higher rates.”\n\nClaims:\nArgentina has a monthly inflation rate as high as 25.5%.\nArgentina’s inflation has made many goods unobtainable.\nArgentina’s currency value has plunged.\nSome experts estimate Argentina’s annual inflation rate could reach 300%.\nExplanation: The phrases “causing severe economic hardship” and “others predict even higher rates” are not reflected in any of the claims. The third claim also omits the fact that inflation caused the currency depreciation.\n3\tSome claims are inaccurate.\tExcerpt: “The U.N. found that the resulting contaminated water caused many residents to fall ill, highlighting the need for improved water management.”\n\nClaims:\nThe U.N. found contaminated water in Derna, Libya.\nContaminated water in Derna, Libya, caused many residents to fall ill.\nExplanation: The first claim is inaccurate because the U.N. found the link between contaminated water and illness, not the contaminated water itself. The second claim also misrepresents the sentence since it shifts the meaning from a viewpoint of a specific entity (the U.N.) to a general assertion about the effects of contaminated water in Derna, Libya.\n4\tSome claims cannot be understood without additional context.\tExcerpt: “Countries like Afghanistan and Sudan have experienced similar challenges to those of Libya.”\n\nClaims:\nAfghanistan has experienced challenges similar to those in Libya.\nSudan has experienced challenges similar to those in Libya.\nExplanation: These claims cannot be understood on their own because “those” is not defined.\nIntroducing Claimify\n\nThe case study highlights that claim extraction is surprisingly error-prone. Our paper demonstrates that the issues identified above are common across LLM-based claim extraction methods. To minimize these errors, we created a system called Claimify[2].\n\nCore principles\n\nClaimify is an LLM-based claim extraction system built on the following principles:\n\n#\tPrinciple\tExample\n1\tThe claims should capture all verifiable content in the source text and exclude unverifiable content.\tIn the sentence “The partnership between John and Jane illustrates the importance of collaboration,” the only verifiable content is the existence of a partnership between John and Jane. The rest is subjective interpretation.\n2\tEach claim should be entailed (i.e., fully supported) by the source text.\tConsider the sentence “Governments are curtailing emissions from cars and trucks, which are the largest source of greenhouse gases from transportation.” The following claims are incorrect:\n\n\nCars are the largest source of greenhouse gases from transportation.\nTrucks are the largest source of greenhouse gases from transportation.\nThe sentence attributes the highest emissions to cars and trucks collectively, not individually.\n3\tEach claim should be understandable on its own, without additional context.\tThe claim “They will update the policy next year” is not understandable on its own because it’s unclear what “They,” “the policy,” and “next year” refer to.\n4\tEach claim should minimize the risk of excluding critical context.\tSuppose the claim “The World Trade Organization has supported trade barriers” was extracted from the sentence “An exception to the World Trade Organization’s open-market philosophy is its history of supporting trade barriers when member countries have failed to comply with their obligations.” A fact-checking system would likely classify the claim as false, since there is extensive evidence that the WTO aims to reduce trade barriers. However, if the claim had specified that the WTO has supported trade barriers “when member countries have failed to comply with their obligations,” it would likely have been classified as true. This example demonstrates that missing context can distort the fact-checking verdict.\n5\tThe system should flag cases where ambiguity cannot be resolved.\tThe sentence “AI has advanced renewable energy and sustainable agriculture at Company A and Company B” has two mutually exclusive interpretations:\n\n\nAI has advanced renewable energy and sustainable agriculture at both Company A and Company B.\nAI has advanced renewable energy at Company A and sustainable agriculture at Company B.\nIf the context does not clearly indicate that one of these interpretations is correct, the system should flag the ambiguity instead of picking one interpretation arbitrarily.\nImplementation\n\nClaimify accepts a question-answer pair as input and performs claim extraction in four stages, illustrated in Figure 1:\n\n#\tStage\tDescription\n1\tSentence splitting and context creation\tThe answer is split into sentences, with “context” – a configurable combination of surrounding sentences and metadata (e.g., the header hierarchy in a Markdown-style answer) – created for each sentence.\n2\tSelection\tAn LLM identifies sentences that do not contain verifiable content. These sentences are labeled “No verifiable claims” and excluded from subsequent stages. When sentences contain verifiable and unverifiable components, the LLM rewrites the sentence, retaining only the verifiable components.\n3\tDisambiguation\tFor sentences that passed the Selection stage, an LLM detects ambiguity and determines if it can be resolved using the context. If all ambiguity is resolvable, the LLM returns a disambiguated version of the sentence. Otherwise, the sentence is labeled “Cannot be disambiguated” and excluded from the Decomposition stage.\n4\tDecomposition\tFor sentences that are unambiguous or were disambiguated, an LLM creates standalone claims that preserve critical context. If no claims are extracted, the sentence is labeled “No verifiable claims.”\nFigure 1: Overview of Claimify’s stages\nResults\n\nIn our paper, we demonstrate that Claimify outperforms existing LLM-based methods[3]. Specifically, we show that: (1) 99% of claims extracted by Claimify are entailed by their source sentence, (2) Claimify strikes the best balance between including verifiable content and excluding unverifiable content, and (3) Claimify is least likely to omit context critical to the fact-checking verdict.\n\nFor the above case study on challenges in emerging markets, here are Claimify’s outputs, with source sentences preceded by a letter and claims numbered[4]:\n\nA. Several emerging markets are grappling with severe economic instability.\n1. Several emerging markets are grappling with severe economic instability.\n\nB. For instance, Argentina’s rampant inflation, with monthly rates reaching as high as 25.5%, has made many goods unobtainable and plunged the value of the currency, causing severe economic hardship.\n1. Argentina has rampant inflation.\n2. The monthly inflation rates in Argentina have reached as high as 25.5%.\n3. Inflation has made many goods unobtainable in Argentina.\n4. Inflation has plunged the value of the currency in Argentina.\n5. Inflation has caused severe economic hardship in Argentina.\n\nC. Some experts estimate that the annual inflation rate could potentially double to 300%, while others predict even higher rates.\n1. Some experts estimate that Argentina’s annual inflation rate could double to 300% in the future.\n2. Some experts predict that Argentina’s annual inflation rate could be higher than 300% in the future.\n\nD. Nigeria, for example, is striving to become self-sufficient in wheat production but is hindered by climate change and violence, exacerbated by high grain prices due to the suspension of the Black Sea Grain Initiative.\n1. Nigeria is striving to become self-sufficient in wheat production.\n2. Nigeria is hindered by climate change in becoming self-sufficient in wheat production.\n3. Nigeria is hindered by violence in becoming self-sufficient in wheat production.\n4. High grain prices exacerbate the hindrance to Nigeria’s efforts to become self-sufficient in wheat production.\n5. The suspension of the Black Sea Grain Initiative is a reason for high grain prices.\n\nE. Climate change has played a pivotal role in creating food insecurity and economic instability in farming-dependent economies, such as Zambia and Mozambique.\n1. Climate change has played a role in creating food insecurity in farming-dependent economies.\n2. Zambia is a farming-dependent economy where climate change has played a role in creating food insecurity.\n3. Mozambique is a farming-dependent economy where climate change has played a role in creating food insecurity.\n4. Climate change has played a role in creating economic instability in farming-dependent economies.\n5. Zambia is a farming-dependent economy where climate change has played a role in creating economic instability.\n6. Mozambique is a farming-dependent economy where climate change has played a role in creating economic instability.\n\nF. Public health crises, as demonstrated by the experience of Derna, Libya, remain a significant concern in emerging markets.\n1. Public health crises are a concern in emerging markets.\n2. Derna, Libya, is an example of a public health crisis in emerging markets.\n\nG. Catastrophic flooding caused by the collapse of two dams has led to significant destruction, complicating access to healthcare.\n1. There was catastrophic flooding in Derna, Libya.\n2. The flooding in Derna, Libya, was caused by the collapse of two dams.\n3. The flooding in Derna, Libya, has led to significant destruction.\n4. The flooding in Derna, Libya, has complicated access to healthcare.\n\nH. Countries like Afghanistan and Sudan have experienced similar challenges to those of Libya.\n1. Afghanistan has experienced challenges related to public health crises.\n2. Afghanistan has experienced challenges related to catastrophic flooding.\n3. Afghanistan has experienced challenges related to contaminated water.\n4. Sudan has experienced challenges related to public health crises.\n5. Sudan has experienced challenges related to catastrophic flooding.\n6. Sudan has experienced challenges related to contaminated water.\n\nNote that the baseline prompt extracted several claims from the sentence “The U.N. found that the resulting contaminated water caused many residents to fall ill, highlighting the need for improved water management,” but it ignored the phrase “highlighting the need for improved water management.” It also failed to capture that the contaminated water resulted from flooding, as implied by “resulting” in the original sentence.\n\nClaimify took a different approach. First, it found two instances of ambiguity – “resulting contaminated water” and “many residents” – that it determined could be resolved using the context. Here’s an excerpt from its reasoning: “…the context specifies that the contaminated water is a result of the catastrophic flooding in Derna, Libya, and the residents are those of Derna, Libya.”\n\nHowever, it also found an instance of ambiguity – “highlighting the need for improved water management” – where it concluded that the context does not definitively support a single interpretation: “The sentence could be interpreted as: (1) The U.N. found that the contaminated water caused illness and also highlighted the need for improved water management, (2) The U.N. only found that the contaminated water caused illness, while the need for improved water management is an implication or conclusion drawn by the writer. Readers … would likely fail to reach consensus about the correct interpretation of this ambiguity.” As a result, Claimify labeled the sentence “Cannot be disambiguated” at the Disambiguation stage and did not proceed to the Decomposition stage. \n\nTo the best of our knowledge, Claimify is the first claim extraction system that identifies when the source text has multiple possible interpretations and extracts claims only when there is high confidence in the correct interpretation.\n\nNext steps\n\nWe’re currently working on new methods for evaluating LLM-generated texts. We anticipate that the high-quality claims extracted by Claimify will help not only in verifying the veracity of LLM outputs, but also in assessing their overall quality – especially when gold-standard references are difficult to create (e.g., long-form texts where people may disagree on what defines “good” content). For example, we recently used Claimify to evaluate the comprehensiveness and diversity of answers generated by GraphRAG, showing that GraphRAG outperforms traditional Retrieval Augmented Generation (RAG) in these areas.\n\nFor an in-depth discussion of Claimify and our evaluation framework, please see our paper “Towards Effective Extraction and Evaluation of Factual Claims.”\n\n[1]\n(opens in new tab)\n We used the “proposition chunking” prompt from NirDiamant’s RAG Techniques repository\n(opens in new tab)\n. We generated multiple responses using GPT-4o, then picked the response that was most representative of the samples.\n\n[2] Claimify is currently used for research purposes only and is not available commercially.\n\n[3]\n(opens in new tab)\n We benchmarked Claimify against VeriScore\n(opens in new tab)\n, DnD\n(opens in new tab)\n, SAFE\n(opens in new tab)\n, AFaCTA\n(opens in new tab)\n, and Factcheck-GPT\n(opens in new tab)\n.\n\n[4] The outputs were generated using GPT-4o. Sentences not shown were either labeled “No verifiable claims” or “Cannot be disambiguated.”\n\nOpens in a new tab\nRelated publications\nFrom Local to Global: A Graph RAG Approach to Query-Focused Summarization\nTowards Effective Extraction and Evaluation of Factual Claims\nMeet the authors\nDasha Metropolitansky\n\nResearch Data Scientist\n\nLearn more\nContinue reading\nMay 22, 2025\nAbstracts: Zero-shot models in single-cell biology with Alex Lu \nDecember 5, 2024\nIdeas: Economics and computation with Nicole Immorlica \nNovember 25, 2024\nLazyGraphRAG: Setting a new standard for quality and cost \nNovember 20, 2023\nOrca 2: Teaching Small Language Models How to Reason \nSee all blog posts\nResearch Areas\nArtificial intelligence\nHuman language technologies\nResearch Groups\nMicrosoft Research Special Projects\nRelated projects\nProject GraphRAG\nRelated labs\nMicrosoft Research Lab - Redmond\nRelated videos\nClaimify: Extracting high-quality claims from language model outputs\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Introducing KBLaM: Bringing plug-and-play external knowledge to LLMs ",
    "link": "https://www.microsoft.com/en-us/research/blog/introducing-kblam-bringing-plug-and-play-external-knowledge-to-llms/",
    "excerpt": "Introducing KBLaM, an approach that encodes and stores structured knowledge within an LLM itself. By integrating knowledge without retraining, it offers a scalable alternative to traditional methods.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nIntroducing KBLaM: Bringing plug-and-play external knowledge to LLMs\n\nPublished March 18, 2025\n\nBy Taketomo Isazawa , Researcher  Xi Wang , PhD Student  Liana Mikaelyan , Senior Applied Scientist  Mathew Salvaris , Principal Applied Scientist  James Hensman , Sr Principal Researcher\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nLarge language models (LLMs) have demonstrated remarkable capabilities in reasoning, language understanding, and even creative tasks. Yet, a key challenge persists: how to efficiently integrate external knowledge.\n\nTraditional methods such as fine-tuning and Retrieval-Augmented Generation (RAG) come with trade-offs—fine-tuning demands costly retraining, while RAG introduces separate retrieval modules that increase complexity and prevent seamless, end-to-end training. In-context learning, on the other hand, becomes increasingly inefficient as knowledge bases grow, facing quadratic computational scaling that hinders its ability to handle large repositories. A comparison of these approaches can be seen in Figure 1.\n\nA new way to integrate knowledge\n\nTo address these challenges, we introduce the Knowledge Base-Augmented Language Model (KBLaM) —a novel approach that integrates structured knowledge bases into pre-trained LLMs. Instead of relying on external retrieval modules or costly fine-tuning, KBLaM encodes knowledge into continuous key-value vector pairs, efficiently embedding them within the model’s attention layers using a specialized rectangular attention mechanism, which implicitly performs retrieval in an integrated manner.\n\nWe use structured knowledge bases to represent the data, allowing us to consolidate knowledge and leverage structure. This design allows it to scale linearly with the size of the knowledge base while maintaining dynamic updates without retraining, making it far more efficient than existing methods.\n\nSPOTLIGHT: MICROSOFT RESEARCH NEWSLETTER\n\nMicrosoft Research Newsletter\n\nStay connected to the research community at Microsoft.\n\nSubscribe today\nOpens in a new tab\nScalable, efficient, and future-ready\n\nAt its core, KBLaM is designed to integrate structured knowledge into LLMs, making them more efficient and scalable. It achieves this by converting external knowledge bases—collections of facts structured as triples consisting of an entity, a property, and a value—into a format that LLMs can process naturally.  Such knowledge bases allow for consolidated, reliable sources of knowledge.\n\nTo create these knowledge bases, we first extract structured data in JSON format using small language models. We then apply Project Alexandria’s probabilistic clustering. Once we have this structured knowledge base, KBLaM follows a three-step pipeline:\n\nKnowledge Encoding: Each knowledge triple is mapped into a key-value vector pair using a pre-trained sentence encoder with lightweight linear adapters. The key vector, derived from the entity name and property, encodes “index information,” while the value vector captures the corresponding property value. This allows us to create continuous, learnable key-value representations.\nIntegration with LLMs: These key-value pairs, or knowledge tokens, are augmented into the model’s attention layers using a specialized rectangular attention structure. Unlike traditional transformer models that process all tokens equally and come with quadratic cost—such as GPT-4, Phi, and Llama—rectangular attention enables the model to attend over knowledge with linear cost, as illustrated in Figure 2. Compared to standard attention mechanisms in generative language models, where each token attends to all preceding tokens, our approach introduces a more efficient structure. In this setup, language tokens (such as those from a user’s question) attend to all knowledge tokens. However, knowledge tokens do not attend to one another, nor do they attend back to the language tokens. This selective attention pattern significantly reduces computational cost while preserving the model’s ability to incorporate external knowledge effectively.\n\nThis linear cost, which is crucial for the efficiency of KBLaM, effectively amounts to treating each fact independently—an assumption that holds for most facts. For example, the model’s name, KBLaM, and the fact that the research was conducted at Microsoft Research are very weakly correlated. This rectangular attention is implemented as an extension of standard attention. During training, we keep the base model’s weights frozen, ensuring that when no knowledge tokens are provided, the model functions exactly as it did originally.\nEfficient Knowledge Retrieval: Through this rectangular attention, the model learns to dynamically retrieve relevant knowledge tokens during inference, eliminating the need for separate retrieval steps.\nFigure 1: KBLaM allows for attention over the entire knowledge base instead of having an external retriever.\nFigure 2: By having the user’s question attend to the knowledge base, while treating facts in the knowledge base independently, KBLaM scales efficiently and linearly with the size of the knowledge base.\n\nUnlike RAG, which appends retrieved document chunks to prompts, KBLaM allows for direct integration of knowledge into the model. Compared to in-context learning,  KBLaM’s rectangular attention maintains a linear memory footprint, making it vastly more scalable for large knowledge bases. \n\nIts efficiency is a game-changer. While traditional in-context learning methods struggle with quadratic memory growth due to self-attention overhead, KBLaM’s linear overhead means we can store much more knowledge in the context. In practice, this means KBLaM can store and process over 10,000 knowledge triples, the equivalent of approximately 200,000 text tokens on a single GPU—a feat that would be computationally prohibitive with conventional in-context learning. The results across a wide range of triples and can be seen in Figure 3. Remarkably, it achieves this while extending a base model that has a context length of only 8K tokens. Additionally, KBLaM enables dynamic updates: modifying a single knowledge triple does not require retraining or re-computation of the entire knowledge base. \n\nFigure 3: KBLaM is much faster and uses much less memory than adding the equivalent number of triples in the context using conventional RAG-like approaches. In particular, we have lower time to first token with 4,096 tripes in the context with KBLaM than we would with 5 triples in the context.\nEnhancing interpretability and reliability\n\nAnother major benefit of KBLaM is its interpretability. Unlike in-context learning, where knowledge injection is opaque, KBLAM’s attention weights provide clear insights into how the model utilizes knowledge tokens. Experiments show that KBLaM assigns high attention scores to relevant knowledge triples, effectively mimicking a soft retrieval process.\n\nFurthermore, KBLaM enhances model reliability by learning through its training examples when not to answer a question if the necessary information is missing from the knowledge base. In particular, with knowledge bases larger than approximately 200 triples, we found that the model refuses to answer questions it has no knowledge about more precisely than a model given the information as text in context. This feature helps reduce hallucinations, a common problem in LLMs that rely on internal knowledge alone, making responses more accurate and trustworthy.\n\nThe future of knowledge-augmented AI\n\nKBLaM represents a major step forward in integrating structured knowledge into LLMs. By offering a scalable, efficient, and interpretable alternative to existing techniques, it paves the way for AI systems that can stay up to date and provide reliable, knowledge-driven responses. In fields where accuracy and trust are critical—such as medicine, finance, and scientific research—this approach has the potential to transform how language models interact with real-world information.\n\nAs AI systems increasingly rely on dynamic knowledge rather than static model parameters, we hope KBLaM will serve as a bridge between raw computational power and real-world understanding.\n\nHowever, there is still work to be done before it can be deployed at scale. Our current model has been trained primarily on factual question-answer pairs, and further research is needed to expand its capabilities across more complex reasoning tasks and diverse knowledge domains.\n\nTo accelerate progress, we are releasing KBLaM’s code and datasets\n(opens in new tab)\n to the research community, and we are planning integrations with the Hugging Face transformers library. By making these resources available, we hope to inspire further research and adoption of scalable, efficient knowledge augmentation for LLMs. The future of AI isn’t just about generating text—it’s about generating knowledge that is accurate, adaptable, and deeply integrated with the evolving world. KBLaM is a step in that direction.\n\nOpens in a new tab\nRelated publications\nKBLaM: Knowledge Base augmented Language Model\nMeet the authors\nTaketomo Isazawa\n\nResearcher\n\nLearn more\nXi Wang\n\nPhD Student\n\nLearn more\nLiana Mikaelyan\n\nSenior Applied Scientist\n\nMicrosoft\n\nLearn more\nMathew Salvaris\n\nPrincipal Applied Scientist\n\nMicrosoft\n\nLearn more\nJames Hensman\n\nSr Principal Researcher\n\nLearn more\nContinue reading\nAugust 28, 2024\nResearch Focus: Week of August 26, 2024 \nJuly 29, 2024\nAbstracts: July 29, 2024 \nFebruary 27, 2024\nStructured knowledge from LLMs improves prompt learning for visual language models \nDecember 7, 2023\nLLMLingua: Innovating LLM efficiency with prompt compression \nSee all blog posts\nResearch Areas\nArtificial intelligence\nRelated tools\nKBLaM: Knowledge Base augmented Language Model\nRelated labs\nMicrosoft Research Lab - Cambridge\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Semantic Telemetry: Understanding how users interact with AI systems ",
    "link": "https://www.microsoft.com/en-us/research/blog/semantic-telemetry-understanding-how-users-interact-with-ai-systems/",
    "excerpt": "AI interactions can be iterative and complex. Learn how the Semantic Telemetry project at Microsoft Research is developing a new data science approach to understand human-AI interactions and their value.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nSemantic Telemetry: Understanding how users interact with AI systems\n\nPublished March 10, 2025\n\nBy Amber Hoak , Senior Software Development Engineer  Scott Counts , Senior Principal Research Manager  Kate Lytvynets , Software Development Engineer  David Tittsworth , Software Engineer  Siddharth Suri , Senior Principal Researcher  Ben Cutler , Senior Director  Weiwei Yang , Principal SDE Manager\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\n\nAI tools are proving useful across a range of applications, from helping to drive the new era of business transformation to helping artists craft songs. But which applications are providing the most value to users? We’ll dig into that question in a series of blog posts that introduce the Semantic Telemetry project at Microsoft Research. In this initial post, we will introduce a new data science approach that we will use to analyze topics and task complexity of Copilot in Bing usage.\n\nHuman-AI interactions can be iterative and complex, requiring a new data science approach to understand user behavior to build and support increasingly high value use cases. Imagine the following chat:\n\nHere we see that chats can be complex and span multiple topics, such as event planning, team building, and logistics. Generative AI has ushered in a two-fold paradigm shift. First, LLMs give us a new thing to measure, that is, how people interact with AI systems. Second, they give us a new way to measure those interactions, that is, they give us the capability to understand and make inferences on these interactions, at scale. The Semantic Telemetry project has created new measures to classify human-AI interactions and understand user behavior, contributing to efforts in developing new approaches for measuring generative AI\n(opens in new tab)\n across various use cases.\n\nSemantic Telemetry is a rethink of traditional telemetry–in which data is collected for understanding systems–designed for analyzing chat-based AI. We employ an innovative data science methodology that uses a large language model (LLM) to generate meaningful categorical labels, enabling us to gain insights into chat log data.\n\nFigure 1: Prompting an LLM to classify a conversation based on LLM generated label taxonomy\n\nThis process begins with developing a set of classifications and definitions. We create these classifications by instructing an LLM to generate a short summary of the conversation, and then iteratively prompting the LLM to generate, update, and review classification labels on a batched set of summaries. This process is outlined in the paper: TnT-LLM: Text Mining at Scale with Large Language Models. We then prompt an LLM with these generated classifiers to label new unstructured (and unlabeled) chat log data.\n\nDescription of LLM generated label taxonomy process\n\nWith this approach, we have analyzed how people interact with Copilot in Bing. In this blog, we examine insights into how people are using Copilot in Bing, including how that differs from traditional search engines. Note that all analyses were conducted on anonymous Copilot interactions containing no personal information.\n\nTopics\n\nTo get a clear picture of how people are using Copilot in Bing, we need to first classify sessions into topical categories. To do this, we developed a topic classifier. We used the LLM classification approach described above to label the primary topic (domain) for the entire content of the chat. Although a single chat can cover multiple topics, for this analysis, we generated a single label for the primary topic of the conversation. We sampled five million anonymized Copilot in Bing chats during August and September 2024, and found that globally, 21% of all chats were about technology, with a high concentration of these chats in programming and scripting and computers and electronics.\n\nFigure 2: Top Copilot in Bing topics based on anonymized data (August-September 2024)\nFigure 3: Frequent topic summaries in Technology\nFigure 4: Frequent topic summaries in Entertainment\n\nDiving into the technology category, we find a lot of professional tasks in programming and scripting, where users request problem-specific assistance such as fixing a SQL query syntax error. In computers and electronics, we observe users getting help with tasks like adjusting screen brightness and troubleshooting internet connectivity issues. We can compare this with our second most common topic, entertainment, in which we see users seeking information related to personal activities like hiking and game nights.\n\nWe also note that top topics differ by platform. The figure below depicts topic popularity based on mobile and desktop usage. Mobile device users tend to use the chat for more personal-related tasks such as helping to plant a garden or understanding medical symptoms whereas desktop users conduct more professional tasks like revising an email.\n\nFigure 5: Top topics for desktop users and mobile users\n\nSPOTLIGHT: BLOG POST\n\nMedFuzz: Exploring the robustness of LLMs on medical challenge problems\n\nMedfuzz tests LLMs by breaking benchmark assumptions, exposing vulnerabilities to bolster real-world accuracy.\n\nRead more\nOpens in a new tab\nSearch versus Copilot\n\nBeyond analyzing topics, we compared Copilot in Bing usage to that of traditional search. Chat extends beyond traditional online search by enabling users to summarize, generate, compare, and analyze information. Human-AI interactions are conversational and more complex than traditional search (Figure 6).\n\nFigure 6: Bing Search Query compared to Copilot in Bing Conversation\n\nA major differentiation between search and chat is the ability to ask more complex questions, but how can we measure this? We think of complexity as a scale ranging from simply asking chat to look up information to evaluating several ideas. We aim to understand the difficulty of a task if performed by a human without the assistance of AI. To achieve this, we developed the task complexity classifier, which assesses task difficulty using Anderson and Krathwohl’s Taxonomy of Learning Objectives\n(opens in new tab)\n. For our analysis, we have grouped the learning objectives into two categories: low complexity and high complexity. Any task more complicated than information lookup is classified as high complexity. Note that this would be very challenging to classify using traditional data science techniques.\n\nDescription of task complexity and 6 categories of the Anderson and Krathwohl’s Taxonomy of Learning Objectives\n\nComparing low versus high complexity tasks, most chat interactions were categorized as high complexity (78.9%), meaning that they were more complex than looking up information. Programming and scripting, marketing and sales, and creative and professional writing are topics in which users engage in higher complexity tasks (Figure 7) such as learning a skill, troubleshooting a problem, or writing an article.\n\nFigure 7: Most and least complex topics based on percentage of high complexity tasks.\n\nTravel and tourism and history and culture scored lowest in complexity, with users looking up information like flight times and latest news updates.\n\nDemo of task complexity and topics on anonymous Copilot interactions\n\nWhen should you use chat instead of search? A 2024 Microsoft Research study: The Use of Generative Search Engines for Knowledge Work and Complex Tasks, suggests that people are seeing value in technical, complex tasks such as web development and data analysis. Bing Search contained more queries with lower complexity focused on non-professional areas, like gaming and entertainment, travel and tourism, and fashion and beauty, while chat had a greater distribution of complex technical tasks. (Figure 8).\n\nFigure 8: Comparison of Bing Search and Copilot in Bing for anonymized sample data (May-June 2023)\nConclusion\n\nLLMs have enabled a new era of high-quality human-AI interaction, and with it, the capability to analyze those same interactions with high fidelity, at scale, and in near real-time. We are now able to obtain actionable insight from complex data that is not possible with traditional data science pattern-matching methods. LLM-generated classifications are pushing research into new directions that will ultimately improve user experience and satisfaction when using chat and other user-AI interaction tools.\n\nThis analysis indicates that Copilot in Bing is enabling users to do more complex work, specifically in areas such as technology. In our next post, we will explore how Copilot in Bing is supporting professional knowledge work and how we can use these measures as indicators for retention and engagement.\n\nFOOTNOTE: This research was conducted at the time the feature Copilot in Bing was available as part of the Bing service; since October 2024 Copilot in Bing has been deprecated in favor of the standalone Microsoft Copilot service.\n\nReferences:\n\nKrathwohl, D. R. (2002). A Revision of Bloom’s Taxonomy: An Overview. Theory Into Practice, 41(4), 212–218. https://doi.org/10.1207/s15430421tip4104_2\n(opens in new tab)\nOpens in a new tab\nRelated publications\nTnT-LLM: Text Mining at Scale with Large Language Models\nThe Use of Generative Search Engines for Knowledge Work and Complex Tasks\nMeet the authors\nAmber Hoak\n\nSenior Software Development Engineer\n\nLearn more\nScott Counts\n\nSenior Principal Research Manager\n\nLearn more\nKate Lytvynets\n\nSoftware Development Engineer\n\nLearn more\nDavid Tittsworth\n\nSoftware Engineer\n\nLearn more\nSiddharth Suri\n\nSenior Principal Researcher\n\nLearn more\nBen Cutler\n\nSenior Director\n\nLearn more\nWeiwei Yang\n\nPrincipal SDE Manager\n\nLearn more\nContinue reading\nApril 14, 2025\nEngagement, user expertise, and satisfaction: Key insights from the Semantic Telemetry Project \nJuly 15, 2024\nRUBICON: Evaluating conversations between humans and AI systems \nMarch 27, 2024\nLearning from interaction with Microsoft Copilot (web) \nSeptember 25, 2023\nAutoGen: Enabling next-generation large language model applications \nSee all blog posts\nResearch Areas\nArtificial intelligence\nSearch and information retrieval\nRelated projects\nSemantic Telemetry\nRelated labs\nMicrosoft Research Lab - Redmond\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  },
  {
    "title": "Advancing biomedical discovery: Overcoming data challenges in precision medicine ",
    "link": "https://www.microsoft.com/en-us/research/blog/advancing-biomedical-discovery-overcoming-data-challenges-in-precision-medicine/",
    "excerpt": "Our recent study in Nature Scientific Reports identified key challenges in the biomedical data lifecycle and offered 7 actionable recommendations.",
    "content": "Skip to main content\nMicrosoft\nResearch\nOur research Programs & events Connect & learn About Register: Research Forum\nAll Microsoft\n Return to Blog Home\nMicrosoft Research Blog\nAdvancing biomedical discovery: Overcoming data challenges in precision medicine\n\nPublished March 5, 2025\n\nBy Mandi Hall , Senior UX/CX Researcher\n\nShare this page\n\nShare on Facebook\nShare on X\nShare on LinkedIn\nShare on Reddit\nSubscribe to our RSS feed\nIntroduction\n\nModern biomedical research is driven by the promise of precision medicine—tailored treatments for individual patients through the integration of diverse, large-scale datasets. Yet, the journey from raw data to actionable insights is fraught with challenges. Our team of researchers at Microsoft Research in the Health Futures group, in collaboration with the Perelman School of Medicine at the University of Pennsylvania\n(opens in new tab)\n, conducted an in-depth exploration of these challenges in a study published in Nature Scientific Reports. The goal of this research was to identify pain points in the biomedical data lifecycle and offer actionable recommendations to enable secure data-sharing, improved interoperability, robust analysis, and foster collaboration across the biomedical research community.\n\nStudy at a glance\n\nA deep understanding of the biomedical discovery process is crucial for advancing modern precision medicine initiatives. To explore this, our study involved in-depth, semi-structured interviews with biomedical research professionals spanning various roles including bench scientists, computational biologists, researchers, clinicians, and data curators. Participants provided detailed insights into their workflows, from data acquisition and curation to analysis and result dissemination. We used an inductive-deductive thematic analysis to identify key challenges occurring at each stage of the data lifecycle—from raw data collection to the communication of data-driven findings.\n\nSome key challenges identified include:\nData procurement and validation: Researchers struggle to identify and secure the right datasets for their research questions, often battling inconsistent quality and manual data validation.\nComputational hurdles: The integration of multiomic data requires navigating disparate computational environments and rapidly evolving toolsets, which can hinder reproducible analysis.\nData distribution and collaboration: The absence of a unified data workflow and secure sharing infrastructure often leads to bottlenecks when coordinating between stakeholders across university labs, pharmaceutical companies, clinical settings, and third-party vendors.\nMain takeaways and recommendations:\nEstablishing a unified biomedical data lifecycle \n\nThis study highlights the need for a unified process that spans all phases of the biomedical discovery process—from data-gathering and curation to analysis and dissemination. Such a data jobs-to-be-done framework would streamline standardized quality checks, reduce manual errors such as metadata reformatting, and ensure that the flow of data across different research phases remains secure and consistent. This harmonization is essential to accelerate research and build more robust, reproducible models that propel precision medicine forward.\nEmpowering stakeholder collaboration and secure data sharing \n\nEffective biomedical discovery requires collaboration across multiple disciplines and institutions. A key takeaway from our interviews was the critical importance of collaboration and trust among stakeholders. Secure, user-friendly platforms that enable real-time data sharing and open communication among clinical trial managers, clinicians, computational scientists, and regulators can bridge the gap between isolated research silos. As a possible solution, by implementing centralized cloud-based infrastructures and democratizing data access, organizations can dramatically reduce data handoff issues and accelerate scientific discovery.\nAdopting actionable recommendations to address data pain points \n\nBased on the insights from this study, the authors propose a list of actionable recommendations such as:\nCreating user-friendly platforms to transition from manual (bench-side) data collection to electronic systems.\nStandardizing analysis workflows to facilitate reproducibility, including version control and the seamless integration of notebooks into larger workflows.\nLeveraging emerging technologies such as generative AI and transformer models for automating data ingestion and processing of unstructured text.\n\nIf implemented, the recommendations from this study would help forge a reliable, scalable infrastructure for managing the complexity of biomedical data, ultimately advancing research and clinical outcomes.\n\nLooking ahead\n\nAt Microsoft Research, we believe in the power of interdisciplinarity and innovation. This study not only identifies the critical pain points that have slowed biomedical discovery but also illustrates a clear path toward improved data integrity, interoperability, and collaboration. By uniting diverse stakeholders around a common, secure, and scalable data research lifecycle, we edge closer to realizing individualized therapeutics for every patient.\n\nWe encourage our colleagues, partners, and the broader research community to review the full study and consider these insights as key steps toward a more integrated biomedical data research infrastructure. The future of precision medicine depends on our ability to break down data silos and create a research data lifecycle that is both robust and responsive to the challenges of big data.\n\nExplore the full paper\n(opens in new tab)\n in Nature Scientific Reports to see how these recommendations were derived, and consider how they might integrate into your work. Let’s reimagine biomedical discovery together—where every stakeholder contributes to a secure, interoperable, and innovative data ecosystem that transforms patient care.\n\nWe look forward to engaging with the community on these ideas as we continue to push the boundaries of biomedical discovery at Microsoft Research.\n\nAccess the full paper\nOpens in a new tab\nRelated publications\nAddressing biomedical data challenges and opportunities to inform a large-scale data lifecycle for enhanced data sharing, interoperability, analysis, and collaboration across stakeholders\nMeet the authors\nMandi Hall\n\nSenior UX/CX Researcher\n\nLearn more\nContinue reading\nNovember 18, 2024\nBiomedParse: A foundation model for smarter, all-in-one biomedical image analysis \nSeptember 30, 2024\nStress-testing biomedical vision models with RadEdit: A synthetic data approach for robust model deployment \nJanuary 16, 2024\nGHDDI and Microsoft Research use AI technology to achieve significant progress in discovering new drugs to treat global infectious diseases \nAugust 10, 2023\nMicrosoft at KDD 2023: Advancing health at the speed of AI \nSee all blog posts\nResearch Areas\nArtificial intelligence\nMedical, health and genomics\nRelated labs\nMicrosoft Health Futures\n\nFollow us:\n\nFollow on X\nLike on Facebook\nFollow on LinkedIn\nSubscribe on Youtube\nFollow on Instagram\nSubscribe to our RSS feed\n\nShare this page:\n\nShare on X\nShare on Facebook\nShare on LinkedIn\nShare on Reddit\nWhat's new\nSurface Pro\nSurface Laptop\nSurface Laptop Studio 2\nSurface Laptop Go 3\nMicrosoft Copilot\nAI in Windows\nExplore Microsoft products\nWindows 11 apps\nMicrosoft Store\nAccount profile\nDownload Center\nMicrosoft Store support\nReturns\nOrder tracking\nCertified Refurbished\nMicrosoft Store Promise\nFlexible Payments\nEducation\nMicrosoft in education\nDevices for education\nMicrosoft Teams for Education\nMicrosoft 365 Education\nHow to buy for your school\nEducator training and development\nDeals for students and parents\nAI for education\nBusiness\nMicrosoft Cloud\nMicrosoft Security\nDynamics 365\nMicrosoft 365\nMicrosoft Power Platform\nMicrosoft Teams\nMicrosoft 365 Copilot\nSmall Business\nDeveloper & IT\nAzure\nMicrosoft Developer\nMicrosoft Learn\nSupport for AI marketplace apps\nMicrosoft Tech Community\nAzure Marketplace\nAppSource\nVisual Studio\nCompany\nCareers\nAbout Microsoft\nCompany news\nPrivacy at Microsoft\nInvestors\nDiversity and inclusion\nAccessibility\nSustainability\nYour Privacy Choices\nConsumer Health Privacy\nSitemap Contact Microsoft Privacy Terms of use Trademarks Safety & eco Recycling About our ads © Microsoft 2025",
    "date": "N/A",
    "authors": []
  }
]